---
id: boomerang
title: Boomerang
sidebar_label: Boomerang
---

import {Config} from '@site/docs/definitions.md';

Boomerang is an advanced embedding and retrieval model designed by Vectara to 
significantly improve the performance of semantic search and 
Retrieval-Augmented Generation (RAG) systems. Boomerang introduces substantial 
advancements in multilingual capabilities, retrieval accuracy, and overall 
performance. For information, check out [this blog](https://www.vectara.com/blog/introducing-boomerang-vectaras-new-and-improved-retrieval-model).

## Multilingual capabilities

Boomerang supports text embedding in hundreds of languages, enabling 
cross-lingual semantic search. This broad language support allows users to 
query and retrieve information effectively across diverse language datasets, 
enhancing global accessibility and usability.

## Optimized for production use

Boomerang supports real-time applications with low-latency performance, making 
it suitable for demanding production environments. The modelâ€™s embedding size 
of 768 dimensions strikes an effective balance between high precision and 
storage efficiency, ensuring optimal operational deployment.

### Minimizing hallucinations

In RAG systems, Boomerang helps reduce hallucinations by focusing on the 
retrieval of contextually relevant information. This leads to more accurate 
and reliable outputs from generative AI systems, strengthening user confidence 
in automated responses.
