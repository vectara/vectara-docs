---
id: create-chat-turn
title: "Create a new turn in the chat"
description: "Create a new turn in the chat. Each conversation has a series of `turn` objects, which are the sequence of message and response pairs that make up the dialog."
sidebar_label: "Create a new turn in the chat"
hide_title: true
hide_table_of_contents: true
api: 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
sidebar_class_name: "post api-method"
info_path: docs/rest-api/vectara-rest-api-v-2
custom_edit_url: null
---

import MethodEndpoint from "@theme/ApiExplorer/MethodEndpoint";
import ParamsDetails from "@theme/ParamsDetails";
import RequestSchema from "@theme/RequestSchema";
import StatusCodes from "@theme/StatusCodes";
import OperationTabs from "@theme/OperationTabs";
import TabItem from "@theme/TabItem";
import Heading from "@theme/Heading";

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Create a new turn in the chat"}
>
</Heading>

<MethodEndpoint
  method={"post"}
  path={"/v2/chats/{chat_id}/turns"}
  context={"endpoint"}
>
  
</MethodEndpoint>



Create a new turn in the chat. Each conversation has a series of `turn` objects, which are the sequence of message and response pairs that make up the dialog.

<Heading
  id={"request"}
  as={"h2"}
  className={"openapi-tabs__heading"}
  children={"Request"}
>
</Heading>

<ParamsDetails
  parameters={[{"in":"header","name":"Request-Timeout","description":"The API will make a best effort to complete the request in the specified seconds or time out.","schema":{"type":"integer","minimum":1},"required":false},{"in":"header","name":"Request-Timeout-Millis","description":"The API will make a best effort to complete the request in the specified milliseconds or time out.","schema":{"type":"integer","minimum":1}},{"in":"path","name":"chat_id","description":"The ID of the chat.","required":true,"schema":{"type":"string","pattern":"cht_.+$"}}]}
>
  
</ParamsDetails>

<RequestSchema
  title={"Body"}
  body={{"content":{"application/json":{"schema":{"type":"object","properties":{"query":{"description":"The chat message or question.","type":"string","example":"How can I use the Vectara platform?"},"search":{"description":"The parameters to search one or more corpora.","allOf":[{"type":"object","properties":{"corpora":{"description":"The corpora that you want to search.","type":"array","items":{"allOf":[{"type":"object","properties":{"custom_dimensions":{"description":"The custom dimensions as additional weights.","type":"object","additionalProperties":{"type":"number","format":"double"},"title":"CustomDimensions"},"metadata_filter":{"description":"The filter string used to narrow the search based on metadata attributes. The query against this\ncorpus will be confined to document parts that match the `metadata_filter`. Only metadata fields\nset as `filter_attributes` on the corpus can be filtered. Filter syntax is similar to\na SQL WHERE clause. See [metadata filters documentation](https://docs.vectara.com/docs/learn/metadata-search-filtering/filter-overview)\nfor more information.\n","type":"string","example":"doc.title = 'Charlotte''s Web'"},"lexical_interpolation":{"description":"How much to weigh lexical scores compared to the embedding score. 0 means lexical search is not used at all, and 1 means only lexical search is used.","type":"number","format":"float","minimum":0,"maximum":1,"example":0.025},"semantics":{"description":"Indicates whether to consider a query against this corpus as a query or a response.","type":"string","enum":["default","query","response"],"default":"default","title":"SearchSemantics"}},"title":"SearchCorpus"},{"type":"object","properties":{"corpus_key":{"description":"A user-provided key for a corpus.","type":"string","example":"my-corpus","pattern":"[a-zA-Z0-9_\\=\\-]+$","maxLength":50,"title":"CorpusKey"},"query":{"description":"Query for a particular corpus that will override the overall query if present.","type":"string"}}}],"required":["corpus_key"],"title":"KeyedSearchCorpus"},"minItems":1}}},{"type":"object","description":"Search parameters to retrieve knowledge for the query.","properties":{"offset":{"description":"Specifies how many results into the result to skip. This is useful for pagination.","type":"integer","format":"int32","default":0,"minimum":0},"limit":{"description":"The maximum number of results returned.","type":"integer","format":"int32","minimum":1,"default":10},"context_configuration":{"type":"object","description":"Configuration on the presentation of each document part in the result set.","properties":{"characters_before":{"description":"The number of characters that are shown before the matching document part.\nThis is useful to show the context of the document part in the wider document.\nIgnored if `sentences_before` is set.\nVectara will capture the full sentence that contains the captured characters,\nto not lose the meaning caused by a truncated word or sentence.\n","type":"integer","format":"int32","default":0,"minimum":0,"example":30},"characters_after":{"description":"The number of characters that are shown after the matching document part. \nThis is useful to show the context of the document part in the wider document.\nIgnored if `sentences_after` is set.\nVectara will capture the full sentence that contains the captured characters,\nto not lose the meaning caused by a truncated word or sentence.\n","type":"integer","format":"int32","default":0,"minimum":0,"example":30},"sentences_before":{"description":"The number of sentences that are shown before the matching document part.\nThis is useful to show the context of the document part in the wider document.\n","type":"integer","format":"int32","default":0,"minimum":0,"example":3},"sentences_after":{"description":"The number of sentences that are shown after the matching document part. \nThis is useful to show the context of the document part in the wider document.\n","type":"integer","format":"int32","default":0,"minimum":0,"example":3},"start_tag":{"description":"The tag that wraps the document part at the start. This is often used to \nprovide a start HTML/XML tag or some other delimiter you can use in an \napplication to understand where to provide highlighting in your UI and \nunderstand where the context before ends and the document part begins.\n","type":"string","example":"<em>"},"end_tag":{"description":"The tag that wraps the document part at the end. This is often used to \nprovide a start HTML/XML tag or some other delimiter you can use in an \napplication to understand where to provide highlighting in your UI and \nunderstand where the context before ends and the document part begins.\n","type":"string","example":"</em>"}},"title":"ContextConfiguration"},"reranker":{"type":"object","description":"Rerank results of the search. Rerankers are very powerful tools to improve the order of search results.\nBy default the search will use the most powerful reranker available to the customer's plan.\nTo disable reranking, set the reranker `type` to `\"none\"`.\n","discriminator":{"propertyName":"type","mapping":{"customer_reranker":{"description":"Reranker that is specific to the customer.","type":"object","properties":{"type":{"description":"When the type is `customer_reranker`, you can specify the `reranker_name` of a reranker. `reranker_id` is deprecated.\nThe retrieval engine will then rerank results using that reranker.\n","type":"string","default":"customer_reranker"},"reranker_id":{"description":"The ID of the reranker. The multilingual reranker that may be specified is rnk_272725719.\nDo not specify the MMR reranker ID here, and instead, use the MMR reranker object type.\n**Deprecated**: Use `reranker_name` instead.\n","type":"string","pattern":"rnk_(?!272725718)\\d+","example":"rnk_272725719","deprecated":true},"reranker_name":{"description":"The name of the reranker. Do not specify the MMR reranker name here. Instead, use the MMR reranker object type.\n","type":"string","example":"Rerank_Multilingual_v1"},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. \nWhen a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, \neach reranker can have its own limit, potentially reducing the number of \nresults at each stage.\n","format":"int32","minimum":1},"cutoff":{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process.\nWhen a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Applies the cutoff, removing any results with scores below the specified threshold.\n3. Returns the remaining results, sorted by their new scores.\n\nNote: This cutoff is applied per reranking stage. In a chain of rerankers,\neach reranker can have its own cutoff, potentially further reducing the number of\nresults at each stage. If both 'limit' and 'cutoff' are specified, the cutoff\nis applied first, followed by the limit.\n","format":"float"}},"x-vectaraParents":["SearchReranker"],"title":"CustomerSpecificReranker"},"userfn":{"type":"object","properties":{"type":{"description":"When the type is `userfn`, you can define custom reranking functions using document-level metadata,\npart-level metadata, or scores generated from the request-level metadata.\n","type":"string","default":"userfn"},"user_function":{"description":"The user defined function.","type":"string","example":"get('$.score') * get('$.document_metadata.boost')"},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. \nWhen a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, \neach reranker can have its own limit, potentially reducing the number of \nresults at each stage.\n","format":"int32","minimum":1},"cutoff":{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process.\nWhen a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Applies the cutoff, removing any results with scores below the specified threshold.\n3. Returns the remaining results, sorted by their new scores.\n\nNote: This cutoff is applied per reranking stage. In a chain of rerankers,\neach reranker can have its own cutoff, potentially further reducing the number of\nresults at each stage. If both 'limit' and 'cutoff' are specified, the cutoff\nis applied first, followed by the limit.\n","format":"float"}},"x-vectaraParents":["SearchReranker"],"title":"UserFunctionReranker"},"mmr":{"type":"object","properties":{"type":{"description":"When the type is `mmr`, you can specify the `diversity_bias`, and the\nretrieval engine will use the MMR reranker.\n","type":"string","default":"mmr"},"diversity_bias":{"description":"The diversity bias. Higher values indicate more diversity.","type":"number","format":"float","example":0.3},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. \nWhen a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, \neach reranker can have its own limit, potentially reducing the number of \nresults at each stage.\n","format":"int32","minimum":1},"cutoff":{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process.\nWhen a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Applies the cutoff, removing any results with scores below the specified threshold.\n3. Returns the remaining results, sorted by their new scores.\n\nNote: This cutoff is applied per reranking stage. In a chain of rerankers,\neach reranker can have its own cutoff, potentially further reducing the number of\nresults at each stage. If both 'limit' and 'cutoff' are specified, the cutoff\nis applied first, followed by the limit.\n","format":"float"}},"x-vectaraParents":["SearchReranker"],"title":"MMRReranker"},"chain":{"type":"object","properties":{"type":{"description":"When the type is `chain`, you can then chain re-rankers together.\n","type":"string","default":"chain"},"rerankers":{"type":"array","description":"Specify an array of rerankers to apply to search results consecutively.\n","items":"circular(SearchReranker)","maxItems":50}},"required":["rerankers"],"x-vectaraParents":["SearchReranker"],"title":"ChainReranker"},"none":{"type":"object","properties":{"type":{"description":"When the type is `none`, no reranking will be done.\n","type":"string","default":"none"},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. \nWhen a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, \neach reranker can have its own limit, potentially reducing the number of \nresults at each stage.\n","format":"int32","minimum":1}},"x-vectaraParents":["SearchReranker"],"title":"NoneReranker"}}},"oneOf":[{"description":"Reranker that is specific to the customer.","type":"object","properties":{"type":{"description":"When the type is `customer_reranker`, you can specify the `reranker_name` of a reranker. `reranker_id` is deprecated.\nThe retrieval engine will then rerank results using that reranker.\n","type":"string","default":"customer_reranker"},"reranker_id":{"description":"The ID of the reranker. The multilingual reranker that may be specified is rnk_272725719.\nDo not specify the MMR reranker ID here, and instead, use the MMR reranker object type.\n**Deprecated**: Use `reranker_name` instead.\n","type":"string","pattern":"rnk_(?!272725718)\\d+","example":"rnk_272725719","deprecated":true},"reranker_name":{"description":"The name of the reranker. Do not specify the MMR reranker name here. Instead, use the MMR reranker object type.\n","type":"string","example":"Rerank_Multilingual_v1"},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. \nWhen a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, \neach reranker can have its own limit, potentially reducing the number of \nresults at each stage.\n","format":"int32","minimum":1},"cutoff":{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process.\nWhen a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Applies the cutoff, removing any results with scores below the specified threshold.\n3. Returns the remaining results, sorted by their new scores.\n\nNote: This cutoff is applied per reranking stage. In a chain of rerankers,\neach reranker can have its own cutoff, potentially further reducing the number of\nresults at each stage. If both 'limit' and 'cutoff' are specified, the cutoff\nis applied first, followed by the limit.\n","format":"float"}},"x-vectaraParents":["SearchReranker"],"title":"CustomerSpecificReranker"},{"type":"object","properties":{"type":{"description":"When the type is `userfn`, you can define custom reranking functions using document-level metadata,\npart-level metadata, or scores generated from the request-level metadata.\n","type":"string","default":"userfn"},"user_function":{"description":"The user defined function.","type":"string","example":"get('$.score') * get('$.document_metadata.boost')"},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. \nWhen a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, \neach reranker can have its own limit, potentially reducing the number of \nresults at each stage.\n","format":"int32","minimum":1},"cutoff":{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process.\nWhen a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Applies the cutoff, removing any results with scores below the specified threshold.\n3. Returns the remaining results, sorted by their new scores.\n\nNote: This cutoff is applied per reranking stage. In a chain of rerankers,\neach reranker can have its own cutoff, potentially further reducing the number of\nresults at each stage. If both 'limit' and 'cutoff' are specified, the cutoff\nis applied first, followed by the limit.\n","format":"float"}},"x-vectaraParents":["SearchReranker"],"title":"UserFunctionReranker"},{"type":"object","properties":{"type":{"description":"When the type is `mmr`, you can specify the `diversity_bias`, and the\nretrieval engine will use the MMR reranker.\n","type":"string","default":"mmr"},"diversity_bias":{"description":"The diversity bias. Higher values indicate more diversity.","type":"number","format":"float","example":0.3},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. \nWhen a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, \neach reranker can have its own limit, potentially reducing the number of \nresults at each stage.\n","format":"int32","minimum":1},"cutoff":{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process.\nWhen a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Applies the cutoff, removing any results with scores below the specified threshold.\n3. Returns the remaining results, sorted by their new scores.\n\nNote: This cutoff is applied per reranking stage. In a chain of rerankers,\neach reranker can have its own cutoff, potentially further reducing the number of\nresults at each stage. If both 'limit' and 'cutoff' are specified, the cutoff\nis applied first, followed by the limit.\n","format":"float"}},"x-vectaraParents":["SearchReranker"],"title":"MMRReranker"},{"type":"object","properties":{"type":{"description":"When the type is `chain`, you can then chain re-rankers together.\n","type":"string","default":"chain"},"rerankers":{"type":"array","description":"Specify an array of rerankers to apply to search results consecutively.\n","items":"circular(SearchReranker)","maxItems":50}},"required":["rerankers"],"x-vectaraParents":["SearchReranker"],"title":"ChainReranker"},{"type":"object","properties":{"type":{"description":"When the type is `none`, no reranking will be done.\n","type":"string","default":"none"},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. \nWhen a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, \neach reranker can have its own limit, potentially reducing the number of \nresults at each stage.\n","format":"int32","minimum":1}},"x-vectaraParents":["SearchReranker"],"title":"NoneReranker"}],"title":"SearchReranker"}},"title":"SearchParameters"}],"required":["corpora"],"title":"SearchCorporaParameters"},"generation":{"description":"The parameters to control generation.","type":"object","properties":{"generation_preset_name":{"description":"The preset values to use to feed the query results and other context to the model.\n\nA `generation_preset` is an object with a bundle of properties that specifies:\n  * The `prompt_template` that is rendered and then sent to the LLM.\n  * The LLM used.\n  * `model_parameter`s such as temperature.\n \nAll of these properties except the model can be overridden by setting them in this\nobject. Even when a `prompt_template` is set, the `generation_preset_name` is used to set \nthe model used. See `model_parameters.model` if you want to set the model explicitly.\n\nIf `generation_preset_name` is not set, the Vectara platform will use the default model and\nprompt.\n","type":"string","minLength":1,"example":"vectara-summary-ext-v1.2.0"},"prompt_name":{"description":"Use `generation_preset_name` instead of `prompt_name`.\n","type":"string","minLength":1,"example":"vectara-summary-ext-v1.2.0","deprecated":true},"max_used_search_results":{"description":"The maximum number of search results to be available to the prompt.","type":"integer","format":"int32","minimum":0,"default":5},"prompt_template":{"description":"Vectara manages both system and user roles and prompts for the generative\nLLM out of the box by default. However, users can override the\n`prompt_template` via this variable. The `prompt_template` is in the form of an\nApache Velocity template. For more details on how to configure the\n`prompt_template`, see the [long-form documentation](https://docs.vectara.com/docs/prompts/vectara-prompt-engine).\n","type":"string","example":"[\n  {\"role\": \"system\", \"content\": \"You are a helpful search assistant.\"},\n  #foreach ($qResult in $vectaraQueryResults)\n     {\"role\": \"user\", \"content\": \"Given the $vectaraIdxWord[$foreach.index] search result.\"},\n     {\"role\": \"assistant\", \"content\": \"${qResult.getText()}\" },\n  #end\n  {\"role\": \"user\", \"content\": \"Generate a summary for the query '${vectaraQuery}' based on the above results.\"}\n]\n"},"prompt_text":{"description":"This property is deprecated in favor of clearer naming. Use `prompt_template`. This property will be\nignored if `prompt_template` is set.\n","type":"string","example":"[\n  {\"role\": \"system\", \"content\": \"You are a helpful search assistant.\"},\n  #foreach ($qResult in $vectaraQueryResults)\n     {\"role\": \"user\", \"content\": \"Given the $vectaraIdxWord[$foreach.index] search result.\"},\n     {\"role\": \"assistant\", \"content\": \"${qResult.getText()}\" },\n  #end\n  {\"role\": \"user\", \"content\": \"Generate a summary for the query '${vectaraQuery}' based on the above results.\"}\n]\n","deprecated":true},"max_response_characters":{"description":"Controls the length of the generated output.\nThis is a rough estimate and not a hard limit: the end output can be longer or shorter\nthan this value. This is generally implemented by including the `max_response_characters` in the\nprompt, and the LLM's instruction following capability dictates how closely the generated output\nis limited.\n","type":"integer","format":"int32","example":300,"minimum":0},"response_language":{"description":"Languages that the Vectara platform supports.","type":"string","enum":["auto","eng","deu","fra","zho","kor","ara","rus","tha","nld","ita","por","spa","jpn","pol","tur","vie","ind","ces","ukr","ell","heb","fas","hin","urd","swe","ben","msa","ron"],"default":"auto","title":"Language"},"model_parameters":{"title":"ModelParameters","description":"The parameters for the model.\nWARNING: This is an experimental feature, and breakable at any point with virtually no\nnotice. It is meant for experimentation to converge on optimal parameters that can then\nbe set in the prompt definitions.\n","type":"object","properties":{"llm_name":{"description":"The model (e.g., `gpt-4`) to use for summarization. If specified, it will override the model behind\n`generation_preset_name`.\n","type":"string","example":"gpt4"},"max_tokens":{"description":"The maximum number of tokens to be returned by the model.","type":"integer","format":"int32","minimum":1},"temperature":{"description":"The sampling temperature to use. Higher values make the output more random, while lower\nvalues make it more focused and deterministic.\n","type":"number","format":"float"},"frequency_penalty":{"description":"Higher values penalize new tokens based on their existing frequency in the text so far,\ndecreasing the model's likelihood to repeat the same line verbatim.\n","type":"number","format":"float"},"presence_penalty":{"description":"Higher values penalize new tokens based on whether they appear in the text so far,\nincreasing the model's likelihood to talk about new topics.\n","type":"number","format":"float"}}},"citations":{"description":"Style the generator should use when making citations.","type":"object","properties":{"style":{"description":"The citation style to be used in summary.\nCan be one of:\n* `numeric` - Citations formatted as simple numerals: \\[1\\], \\[2\\] ...\n* `none` - Citations removed from text.\n* `html` - Citation formatted as a URL like `<a href=\"url_pattern\">text_pattern</a>`.\n* `markdown` - Formatted as `[text_pattern](url_pattern)`.\n","type":"string","enum":["none","numeric","html","markdown"]},"url_pattern":{"description":"The URL pattern if the citation_style is set to `html` or `markdown`.\nThe pattern can access metadata attributes in the document or part.\ne.g. `https://my.doc/foo/{doc.id}/{part.id}`\n\nThe default `url_pattern` is an empty string.\n","type":"string","example":"https://vectara.com/documents/{doc.id}"},"text_pattern":{"description":"The text pattern if the citation_style is set to `html` or `markdown`.\nThis pattern sets the href for HTML or the text within `[]` in markdown,\nand defaults to N being the index of result if it is not set.\n\nThe default citation style looks like `[N](<url_pattern>)` for markdown.\n\nYou can use metadata attributes in the `text_pattern`. For example,\nthe pattern `{doc.title}` with citation style `markdown` would result\nin final citation output like `[Title](<url_pattern>)` when\nthe document's metadata includes `{\"title\":\"Title\"}`.\n","type":"string","example":"{doc.title}"}},"title":"CitationParameters"},"enable_factual_consistency_score":{"description":"Enable returning the factual consistency score with query results.","type":"boolean","default":true}},"title":"GenerationParameters"},"chat":{"type":"object","description":"Parameters to control chat behavior.","properties":{"store":{"description":"Indicates whether to store chat messages and response messages.","type":"boolean","default":true}},"title":"ChatParameters"},"save_history":{"description":"Indicates whether to save the chat in both the chat and query history. This overrides `chat.store`.","type":"boolean","default":true},"intelligent_query_rewriting":{"description":"Indicates whether to enable intelligent query rewriting. When enabled, the platform will attempt to\nextract metadata filter and rewrite the query to improve search results.\n","type":"boolean","default":false},"stream_response":{"description":"Indicates whether the response should be streamed or not.","type":"boolean","default":false}},"required":["query","search"],"title":"ChatRequest"}}}}}
>
  
</RequestSchema>

<StatusCodes
  id={undefined}
  label={undefined}
  responses={{"200":{"description":"A response to a chat request.","content":{"application/json":{"schema":{"description":"Full response to a chat question when the result is not streamed.","type":"object","properties":{"chat_id":{"description":"If the chat response was stored, the ID of the chat.","type":"string"},"turn_id":{"description":"If the chat response was stored, the ID of the turn.","type":"string"},"answer":{"description":"The message from the chat model for the chat message.","type":"string"},"response_language":{"description":"Languages that the Vectara platform supports.","type":"string","enum":["auto","eng","deu","fra","zho","kor","ara","rus","tha","nld","ita","por","spa","jpn","pol","tur","vie","ind","ces","ukr","ell","heb","fas","hin","urd","swe","ben","msa","ron"],"default":"auto","title":"Language"},"search_results":{"description":"The ranked search results that the chat model used.","type":"array","items":{"description":"An individual ranked search result from a query.","type":"object","properties":{"text":{"description":"The document part altered by the context configuration that matches the query.","type":"string"},"score":{"description":"The score of the individual result.","type":"number","format":"double"},"part_metadata":{"description":"The metadata for the document part.","type":"object","additionalProperties":true},"document_metadata":{"description":"The metadata for the document that contains the document part.","type":"object","additionalProperties":true},"document_id":{"description":"The ID of the document that contains the document part.","type":"string"},"table":{"description":"The table that the document part is from.","type":"object","properties":{"id":{"description":"The unique ID of the table within the document.","type":"string","example":"table_1"},"title":{"description":"The title of the table.","type":"string"},"data":{"description":"The data of the table.","type":"object","properties":{"headers":{"description":"The headers of the table.","type":"array","items":{"description":"The header of a table.","type":"array","items":{"description":"A cell in a table.","type":"object","properties":{"text_value":{"description":"A text value.","type":"string"},"int_value":{"description":"A signed 64-bit integer value.","type":"integer","format":"int64"},"float_value":{"description":"A floating-point value with double precision.","type":"number","format":"double"},"bool_value":{"description":"A boolean value.","type":"boolean"},"colspan":{"description":"(Optional) The number of columns the cell spans. Default is 1. Must be greater than 0.","type":"integer","format":"int32"},"rowspan":{"description":"(Optional) The number of rows the cell spans. Default is 1. Must be greater than 0.","type":"integer","format":"int32"}},"title":"Cell"},"title":"Header"}},"rows":{"description":"The rows in the data.","type":"array","items":{"description":"A row in a table.","type":"array","items":{"description":"A cell in a table.","type":"object","properties":{"text_value":{"description":"A text value.","type":"string"},"int_value":{"description":"A signed 64-bit integer value.","type":"integer","format":"int64"},"float_value":{"description":"A floating-point value with double precision.","type":"number","format":"double"},"bool_value":{"description":"A boolean value.","type":"boolean"},"colspan":{"description":"(Optional) The number of columns the cell spans. Default is 1. Must be greater than 0.","type":"integer","format":"int32"},"rowspan":{"description":"(Optional) The number of rows the cell spans. Default is 1. Must be greater than 0.","type":"integer","format":"int32"}},"title":"Cell"},"title":"Row"}}},"title":"Data"},"description":{"description":"The description of the table.","type":"string"}},"title":"Table"},"request_corpora_index":{"description":"A query request can search over multiple corpora at a time. This property \nis set to the index in the list of corpora in the original search request that this\nsearch result originated from.\n\nIf the query request is only over one corpus, this property is 0.\n","type":"integer","format":"int32","example":0,"minimum":0}},"title":"IndividualSearchResult"}},"factual_consistency_score":{"description":"Indicates the probability that the summary is factually consistent with the results.\nThe system excludes this property if it encounters excessively large outputs or search\nresults.\n","type":"number","format":"float"},"rendered_prompt":{"description":"The rendered prompt sent to the LLM. Useful when creating customer `prompt_template` templates. \n","type":"string"},"warnings":{"description":"Non-fatal warnings that occurred during request processing","type":"array","items":{"type":"string","description":"Non-fatal warnings that occurred during query processing.\n *  `exceeded_max_input_length_fcs`: The input to the Factual Consistency Score model exceeded the maximum allowed length, so no score is being returned\n *  `intelligent_query_rewriting_failed`: Intelligent query rewriting failed due to an internal error\n","enum":["exceeded_max_input_length_fcs","intelligent_query_rewriting_failed"],"title":"QueryWarning"}},"rephrased_query":{"description":"View the actual query made to backend that was rephrased \nby the LLM from the input query.\n","type":"string"},"rewritten_queries":{"description":"The rewritten queries for the corpora that were searched. Only populated when \nintelligent_query_rewriting is enabled.\n","type":"array","items":{"description":"The rewritten query for a corpus that was searched.","type":"object","properties":{"corpus_key":{"description":"The corpus key that the query was made on.","type":"string"},"filter_extraction":{"type":"object","description":"The result of query filter extraction.","properties":{"query":{"description":"The query rephrased from the input query and executed.","type":"string"},"metadata_filter":{"description":"The metadata filter extracted from the input query.","type":"string"}},"title":"FilterExtraction"}},"title":"RewrittenQuery"}}},"title":"ChatFullResponse"}},"text/event-stream":{"schema":{"description":"An individual event when the response is streamed.","type":"object","discriminator":{"propertyName":"type","mapping":{"search_results":{"description":"The search response results.","type":"object","properties":{"type":{"description":"When the streaming event has the search results, the\ntype will be `search_results`.\n","type":"string","default":"search_results"},"search_results":{"description":"The ranked search results.","type":"array","items":{"description":"An individual ranked search result from a query.","type":"object","properties":{"text":{"description":"The document part altered by the context configuration that matches the query.","type":"string"},"score":{"description":"The score of the individual result.","type":"number","format":"double"},"part_metadata":{"description":"The metadata for the document part.","type":"object","additionalProperties":true},"document_metadata":{"description":"The metadata for the document that contains the document part.","type":"object","additionalProperties":true},"document_id":{"description":"The ID of the document that contains the document part.","type":"string"},"table":{"description":"The table that the document part is from.","type":"object","properties":{"id":{"description":"The unique ID of the table within the document.","type":"string","example":"table_1"},"title":{"description":"The title of the table.","type":"string"},"data":{"description":"The data of the table.","type":"object","properties":{"headers":{"description":"The headers of the table.","type":"array","items":{"description":"The header of a table.","type":"array","items":{"description":"A cell in a table.","type":"object","properties":{"text_value":{"description":"A text value.","type":"string"},"int_value":{"description":"A signed 64-bit integer value.","type":"integer","format":"int64"},"float_value":{"description":"A floating-point value with double precision.","type":"number","format":"double"},"bool_value":{"description":"A boolean value.","type":"boolean"},"colspan":{"description":"(Optional) The number of columns the cell spans. Default is 1. Must be greater than 0.","type":"integer","format":"int32"},"rowspan":{"description":"(Optional) The number of rows the cell spans. Default is 1. Must be greater than 0.","type":"integer","format":"int32"}},"title":"Cell"},"title":"Header"}},"rows":{"description":"The rows in the data.","type":"array","items":{"description":"A row in a table.","type":"array","items":{"description":"A cell in a table.","type":"object","properties":{"text_value":{"description":"A text value.","type":"string"},"int_value":{"description":"A signed 64-bit integer value.","type":"integer","format":"int64"},"float_value":{"description":"A floating-point value with double precision.","type":"number","format":"double"},"bool_value":{"description":"A boolean value.","type":"boolean"},"colspan":{"description":"(Optional) The number of columns the cell spans. Default is 1. Must be greater than 0.","type":"integer","format":"int32"},"rowspan":{"description":"(Optional) The number of rows the cell spans. Default is 1. Must be greater than 0.","type":"integer","format":"int32"}},"title":"Cell"},"title":"Row"}}},"title":"Data"},"description":{"description":"The description of the table.","type":"string"}},"title":"Table"},"request_corpora_index":{"description":"A query request can search over multiple corpora at a time. This property \nis set to the index in the list of corpora in the original search request that this\nsearch result originated from.\n\nIf the query request is only over one corpus, this property is 0.\n","type":"integer","format":"int32","example":0,"minimum":0}},"title":"IndividualSearchResult"}},"rewritten_queries":{"description":"The rewritten queries for the corpora that were searched. Only populated when \nintelligent_query_rewriting is enabled.\n","type":"array","items":{"description":"The rewritten query for a corpus that was searched.","type":"object","properties":{"corpus_key":{"description":"The corpus key that the query was made on.","type":"string"},"filter_extraction":{"type":"object","description":"The result of query filter extraction.","properties":{"query":{"description":"The query rephrased from the input query and executed.","type":"string"},"metadata_filter":{"description":"The metadata filter extracted from the input query.","type":"string"}},"title":"FilterExtraction"}},"title":"RewrittenQuery"}}},"x-vectaraParents":["QueryStreamedResponse","ChatStreamedResponse"],"title":"StreamSearchResponse"},"chat_info":{"description":"Information about the chat.","type":"object","properties":{"type":{"description":"This will be `chat_info` when the stream event contains information\nabout how the chat is stored.\n","type":"string","default":"chat_info"},"chat_id":{"description":"ID of the chat.","type":"string","pattern":"cht_.+$"},"turn_id":{"description":"ID of the turn.","type":"string","pattern":"trn_.+$"}},"x-vectaraParents":["ChatStreamedResponse"],"title":"ChatInfoResponse"},"generation_chunk":{"description":"The chunk response from the generation, which may be a partial generation.","type":"object","properties":{"type":{"description":"When the streaming event contains the next chunk of generator output, the\ntype will be `generation_chunk`.\n","type":"string","default":"generation_chunk"},"generation_chunk":{"description":"Part of the message from the generator. All summary chunks must be appended together in order\nto get the full summary.\n","type":"string"}},"x-vectaraParents":["QueryStreamedResponse","ChatStreamedResponse","SummarizeDocumentStreamedResponse"],"title":"StreamGenerationChunk"},"generation_end":{"description":"The end of generation. There may still be more information such as the\nfactual consistency score, but generation has stopped.\n","type":"object","properties":{"type":{"description":"Then end of generation will be denoted with an object\nwith the type `generation_end`.\n","type":"string","default":"generation_end"}},"x-vectaraParents":["QueryStreamedResponse","ChatStreamedResponse","SummarizeDocumentStreamedResponse"],"title":"StreamGenerationEnd"},"generation_info":{"description":"Event containing information on how the generation was accomplished.","type":"object","properties":{"type":{"description":"When the streaming event contains the generation information\ntype will be `generation_info`.\n","type":"string","default":"generation_info"},"rendered_prompt":{"description":"The rendered prompt sent to the LLM. Useful when creating customer `prompt_template` templates.\n","type":"string"},"rephrased_query":{"description":"View the actual query made to backend that was rephrased \nby the LLM from the input query.\n","type":"string"}},"x-vectaraParents":["QueryStreamedResponse","ChatStreamedResponse","SummarizeDocumentStreamedResponse"],"title":"GenerationInfo"},"factual_consistency_score":{"description":"Event containing the factual consistency score.","type":"object","properties":{"type":{"description":"When the streaming event contains the factual consistency score, the\ntype will be `factual_consistency_score`.\n","type":"string","default":"factual_consistency_score"},"factual_consistency_score":{"description":"The probability that the summary is factually consistent with the results.","type":"number","format":"float"}},"x-vectaraParents":["QueryStreamedResponse","ChatStreamedResponse"],"title":"FactualConsistencyScore"},"end":{"description":"The end of a query response stream.","type":"object","properties":{"type":{"description":"Then end of stream will be denoted with an object\nwith the type `end`.\n","type":"string","default":"end"}},"x-vectaraParents":["QueryStreamedResponse","ChatStreamedResponse","SummarizeDocumentStreamedResponse"],"title":"StreamResponseEnd"},"error":{"description":"Event signaling there was an error with the request.\n","properties":{"type":{"description":"If the stream errors, an event with type `error` will\nbe sent.\n","type":"string","default":"error"},"messages":{"description":"The error messages.","type":"array","items":{"type":"string"}}},"x-vectaraParents":["QueryStreamedResponse","ChatStreamedResponse","SummarizeDocumentStreamedResponse"],"title":"StreamError"}}},"oneOf":[{"description":"The search response results.","type":"object","properties":{"type":{"description":"When the streaming event has the search results, the\ntype will be `search_results`.\n","type":"string","default":"search_results"},"search_results":{"description":"The ranked search results.","type":"array","items":{"description":"An individual ranked search result from a query.","type":"object","properties":{"text":{"description":"The document part altered by the context configuration that matches the query.","type":"string"},"score":{"description":"The score of the individual result.","type":"number","format":"double"},"part_metadata":{"description":"The metadata for the document part.","type":"object","additionalProperties":true},"document_metadata":{"description":"The metadata for the document that contains the document part.","type":"object","additionalProperties":true},"document_id":{"description":"The ID of the document that contains the document part.","type":"string"},"table":{"description":"The table that the document part is from.","type":"object","properties":{"id":{"description":"The unique ID of the table within the document.","type":"string","example":"table_1"},"title":{"description":"The title of the table.","type":"string"},"data":{"description":"The data of the table.","type":"object","properties":{"headers":{"description":"The headers of the table.","type":"array","items":{"description":"The header of a table.","type":"array","items":{"description":"A cell in a table.","type":"object","properties":{"text_value":{"description":"A text value.","type":"string"},"int_value":{"description":"A signed 64-bit integer value.","type":"integer","format":"int64"},"float_value":{"description":"A floating-point value with double precision.","type":"number","format":"double"},"bool_value":{"description":"A boolean value.","type":"boolean"},"colspan":{"description":"(Optional) The number of columns the cell spans. Default is 1. Must be greater than 0.","type":"integer","format":"int32"},"rowspan":{"description":"(Optional) The number of rows the cell spans. Default is 1. Must be greater than 0.","type":"integer","format":"int32"}},"title":"Cell"},"title":"Header"}},"rows":{"description":"The rows in the data.","type":"array","items":{"description":"A row in a table.","type":"array","items":{"description":"A cell in a table.","type":"object","properties":{"text_value":{"description":"A text value.","type":"string"},"int_value":{"description":"A signed 64-bit integer value.","type":"integer","format":"int64"},"float_value":{"description":"A floating-point value with double precision.","type":"number","format":"double"},"bool_value":{"description":"A boolean value.","type":"boolean"},"colspan":{"description":"(Optional) The number of columns the cell spans. Default is 1. Must be greater than 0.","type":"integer","format":"int32"},"rowspan":{"description":"(Optional) The number of rows the cell spans. Default is 1. Must be greater than 0.","type":"integer","format":"int32"}},"title":"Cell"},"title":"Row"}}},"title":"Data"},"description":{"description":"The description of the table.","type":"string"}},"title":"Table"},"request_corpora_index":{"description":"A query request can search over multiple corpora at a time. This property \nis set to the index in the list of corpora in the original search request that this\nsearch result originated from.\n\nIf the query request is only over one corpus, this property is 0.\n","type":"integer","format":"int32","example":0,"minimum":0}},"title":"IndividualSearchResult"}},"rewritten_queries":{"description":"The rewritten queries for the corpora that were searched. Only populated when \nintelligent_query_rewriting is enabled.\n","type":"array","items":{"description":"The rewritten query for a corpus that was searched.","type":"object","properties":{"corpus_key":{"description":"The corpus key that the query was made on.","type":"string"},"filter_extraction":{"type":"object","description":"The result of query filter extraction.","properties":{"query":{"description":"The query rephrased from the input query and executed.","type":"string"},"metadata_filter":{"description":"The metadata filter extracted from the input query.","type":"string"}},"title":"FilterExtraction"}},"title":"RewrittenQuery"}}},"x-vectaraParents":["QueryStreamedResponse","ChatStreamedResponse"],"title":"StreamSearchResponse"},{"description":"Information about the chat.","type":"object","properties":{"type":{"description":"This will be `chat_info` when the stream event contains information\nabout how the chat is stored.\n","type":"string","default":"chat_info"},"chat_id":{"description":"ID of the chat.","type":"string","pattern":"cht_.+$"},"turn_id":{"description":"ID of the turn.","type":"string","pattern":"trn_.+$"}},"x-vectaraParents":["ChatStreamedResponse"],"title":"ChatInfoResponse"},{"description":"The chunk response from the generation, which may be a partial generation.","type":"object","properties":{"type":{"description":"When the streaming event contains the next chunk of generator output, the\ntype will be `generation_chunk`.\n","type":"string","default":"generation_chunk"},"generation_chunk":{"description":"Part of the message from the generator. All summary chunks must be appended together in order\nto get the full summary.\n","type":"string"}},"x-vectaraParents":["QueryStreamedResponse","ChatStreamedResponse","SummarizeDocumentStreamedResponse"],"title":"StreamGenerationChunk"},{"description":"The end of generation. There may still be more information such as the\nfactual consistency score, but generation has stopped.\n","type":"object","properties":{"type":{"description":"Then end of generation will be denoted with an object\nwith the type `generation_end`.\n","type":"string","default":"generation_end"}},"x-vectaraParents":["QueryStreamedResponse","ChatStreamedResponse","SummarizeDocumentStreamedResponse"],"title":"StreamGenerationEnd"},{"description":"Event containing the factual consistency score.","type":"object","properties":{"type":{"description":"When the streaming event contains the factual consistency score, the\ntype will be `factual_consistency_score`.\n","type":"string","default":"factual_consistency_score"},"factual_consistency_score":{"description":"The probability that the summary is factually consistent with the results.","type":"number","format":"float"}},"x-vectaraParents":["QueryStreamedResponse","ChatStreamedResponse"],"title":"FactualConsistencyScore"},{"description":"The end of a query response stream.","type":"object","properties":{"type":{"description":"Then end of stream will be denoted with an object\nwith the type `end`.\n","type":"string","default":"end"}},"x-vectaraParents":["QueryStreamedResponse","ChatStreamedResponse","SummarizeDocumentStreamedResponse"],"title":"StreamResponseEnd"},{"description":"Event containing information on how the generation was accomplished.","type":"object","properties":{"type":{"description":"When the streaming event contains the generation information\ntype will be `generation_info`.\n","type":"string","default":"generation_info"},"rendered_prompt":{"description":"The rendered prompt sent to the LLM. Useful when creating customer `prompt_template` templates.\n","type":"string"},"rephrased_query":{"description":"View the actual query made to backend that was rephrased \nby the LLM from the input query.\n","type":"string"}},"x-vectaraParents":["QueryStreamedResponse","ChatStreamedResponse","SummarizeDocumentStreamedResponse"],"title":"GenerationInfo"},{"description":"Event signaling there was an error with the request.\n","properties":{"type":{"description":"If the stream errors, an event with type `error` will\nbe sent.\n","type":"string","default":"error"},"messages":{"description":"The error messages.","type":"array","items":{"type":"string"}}},"x-vectaraParents":["QueryStreamedResponse","ChatStreamedResponse","SummarizeDocumentStreamedResponse"],"title":"StreamError"}],"title":"ChatStreamedResponse"}}}},"400":{"description":"Turn creation request was malformed.","content":{"application/json":{"schema":{"type":"object","properties":{"field_errors":{"description":"The errors that relate to specific fields in the request.","type":"object","additionalProperties":{"type":"string"}},"messages":{"type":"array","items":{"title":"message","type":"string"}},"request_id":{"description":"The ID of the request that can be used to help Vectara support debug what went wrong.","type":"string"}},"title":"BadRequestError"}}}},"403":{"description":"Permissions do not allow creating a turn in the chat.","content":{"application/json":{"schema":{"type":"object","properties":{"messages":{"description":"The messages describing why the error occurred.","type":"array","items":{"title":"message","type":"string","example":"Internal server error."}},"request_id":{"description":"The ID of the request that can be used to help Vectara support debug what went wrong.","type":"string"}},"title":"Error"}}}},"404":{"description":"Corpus or chat not found.","content":{"application/json":{"schema":{"type":"object","properties":{"id":{"description":"The ID cannot be found.","type":"string"},"messages":{"type":"array","items":{"title":"message","type":"string"}},"request_id":{"description":"ID of the request that can be used to help Vectara support debug what went wrong.","type":"string"}},"title":"NotFoundError"}}}}}}
>
  
</StatusCodes>


      