---
id: create-chat
title: "Start a chat"
description: "Create a chat while specifying the default retrieval parameters used by the prompt."
sidebar_label: "Start a chat"
hide_title: true
hide_table_of_contents: true
api: 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
sidebar_class_name: "post api-method"
info_path: docs/rest-api/vectara-rest-api-v-2
custom_edit_url: null
---

import MethodEndpoint from "@theme/ApiExplorer/MethodEndpoint";
import ParamsDetails from "@theme/ParamsDetails";
import RequestSchema from "@theme/RequestSchema";
import StatusCodes from "@theme/StatusCodes";
import OperationTabs from "@theme/OperationTabs";
import TabItem from "@theme/TabItem";
import Heading from "@theme/Heading";

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Start a chat"}
>
</Heading>

<MethodEndpoint
  method={"post"}
  path={"/v2/chats"}
  context={"endpoint"}
>
  
</MethodEndpoint>



Create a chat while specifying the default retrieval parameters used by the prompt.

<Heading
  id={"request"}
  as={"h2"}
  className={"openapi-tabs__heading"}
  children={"Request"}
>
</Heading>

<ParamsDetails
  parameters={[{"in":"header","name":"Request-Timeout","description":"The API will make a best effort to complete the request in the specified seconds or time out.","schema":{"type":"integer","minimum":1},"required":false},{"in":"header","name":"Request-Timeout-Millis","description":"The API will make a best effort to complete the request in the specified milliseconds or time out.","schema":{"type":"integer","minimum":1}}]}
>
  
</ParamsDetails>

<RequestSchema
  title={"Body"}
  body={{"content":{"application/json":{"schema":{"description":"Request to start or continue a chat conversation with a large language model.","type":"object","properties":{"query":{"description":"The chat message or question.","type":"string","example":"How can I use the Vectara platform?"},"search":{"description":"The parameters to search one or more corpora.","allOf":[{"type":"object","properties":{"corpora":{"description":"The corpora that you want to search.","type":"array","items":{"description":"A corpus with its identifying key for use in search operations within a customer account.","allOf":[{"description":"Configuration for search parameters specific to a single corpus within a customer account, including filters and semantics.","type":"object","properties":{"custom_dimensions":{"description":"The custom dimensions as additional weights.","type":"object","additionalProperties":{"type":"number","format":"double","nullable":false},"title":"CustomDimensions"},"metadata_filter":{"description":"The filter string used to narrow the search based on metadata attributes. The query against this corpus will be confined to document parts that match the `metadata_filter`. Only metadata fields set as `filter_attributes` on the corpus can be filtered. Filter syntax is similar to a SQL WHERE clause. See [metadata filters documentation](https://docs.vectara.com/docs/learn/metadata-search-filtering/filter-overview) for more information.","type":"string","example":"doc.title = 'Charlotte''s Web'"},"lexical_interpolation":{"description":"How much to weigh lexical scores compared to the embedding score. 0 means lexical search is not used at all, and 1 means only lexical search is used.","type":"number","format":"float","minimum":0,"maximum":1,"example":0.025},"semantics":{"description":"Indicates whether to consider a query against this corpus as a query or a response.","type":"string","enum":["default","query","response"],"default":"default","title":"SearchSemantics"}},"title":"SearchCorpus"},{"type":"object","properties":{"corpus_key":{"description":"A user-provided key for a corpus.","type":"string","example":"my-corpus","pattern":"[a-zA-Z0-9_\\=\\-]+$","maxLength":50,"title":"CorpusKey"},"query":{"description":"Query for a particular corpus that will override the overall query if present.","type":"string"}}}],"required":["corpus_key"],"title":"KeyedSearchCorpus"},"minItems":1}}},{"type":"object","description":"Search parameters to retrieve knowledge for the query.","properties":{"offset":{"description":"Specifies how many results into the result to skip. This is useful for pagination.","type":"integer","format":"int32","default":0,"minimum":0},"limit":{"description":"The maximum number of results returned.","type":"integer","format":"int32","minimum":1,"default":10},"context_configuration":{"type":"object","description":"Configuration on the presentation of each document part in the result set.","properties":{"characters_before":{"description":"The number of characters that are shown before the matching document part. This is useful to show the context of the document part in the wider document. Ignored if `sentences_before` is set. Vectara will capture the full sentence that contains the captured characters, to not lose the meaning caused by a truncated word or sentence.","type":"integer","format":"int32","default":0,"minimum":0,"example":30},"characters_after":{"description":"The number of characters that are shown after the matching document part. This is useful to show the context of the document part in the wider document. Ignored if `sentences_after` is set. Vectara will capture the full sentence that contains the captured characters, to not lose the meaning caused by a truncated word or sentence.","type":"integer","format":"int32","default":0,"minimum":0,"example":30},"sentences_before":{"description":"The number of sentences that are shown before the matching document part. This is useful to show the context of the document part in the wider document.","type":"integer","format":"int32","default":0,"minimum":0,"example":3},"sentences_after":{"description":"The number of sentences that are shown after the matching document part. This is useful to show the context of the document part in the wider document.","type":"integer","format":"int32","default":0,"minimum":0,"example":3},"start_tag":{"description":"The tag that wraps the document part at the start. This is often used to provide a start HTML/XML tag or some other delimiter you can use in an application to understand where to provide highlighting in your UI and understand where the context before ends and the document part begins.","type":"string","example":"<em>"},"end_tag":{"description":"The tag that wraps the document part at the end. This is often used to provide a start HTML/XML tag or some other delimiter you can use in an application to understand where to provide highlighting in your UI and understand where the context before ends and the document part begins.","type":"string","example":"</em>"}},"title":"ContextConfiguration"},"reranker":{"type":"object","description":"Rerank results of the search. Rerankers are very powerful tools to improve the order of search results. By default the search will use the most powerful reranker available to the customer's plan. To disable reranking, set the reranker `type` to `\"none\"`.","discriminator":{"propertyName":"type","mapping":{"customer_reranker":{"description":"Reranker that is specific to the customer.","type":"object","properties":{"type":{"description":"When the type is `customer_reranker`, you can specify the `reranker_name` of a reranker. `reranker_id` is deprecated. The retrieval engine will then rerank results using that reranker.","type":"string","default":"customer_reranker"},"reranker_id":{"description":"The ID of the reranker. The multilingual reranker that may be specified is rnk_272725719. Do not specify the MMR reranker ID here, and instead, use the MMR reranker object type. **Deprecated**: Use `reranker_name` instead.","type":"string","pattern":"rnk_(?!272725718)\\d+","example":"rnk_272725719","deprecated":true},"reranker_name":{"description":"The name of the reranker. Do not specify the MMR reranker name here. Instead, use the MMR reranker object type.","type":"string","example":"Rerank_Multilingual_v1"},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. When a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1},"cutoff":{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process. When a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm. 2. Applies the cutoff, removing any results with scores below the specified threshold. 3. Returns the remaining results, sorted by their new scores.\nNote: This cutoff is applied per reranking stage. In a chain of rerankers, each reranker can have its own cutoff, potentially further reducing the number of results at each stage. If both 'limit' and 'cutoff' are specified, the cutoff is applied first, followed by the limit.","format":"float"},"include_context":{"type":"boolean","default":true,"description":"If true, the reranker will use text with context (see \"context_configuration\") for scoring."}},"x-vectaraParents":["SearchReranker"],"title":"CustomerSpecificReranker"},"userfn":{"description":"A reranker that uses user-defined functions to reorder search results.","type":"object","properties":{"type":{"description":"When the type is `userfn`, you can define custom reranking functions using document-level metadata, part-level metadata, or scores generated from the request-level metadata.","type":"string","default":"userfn"},"user_function":{"description":"The user defined function.","type":"string","example":"get('$.score') * get('$.document_metadata.boost')"},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. \nWhen a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1},"cutoff":{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process. When a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm. 2. Applies the cutoff, removing any results with scores below the specified threshold. 3. Returns the remaining results, sorted by their new scores.\nNote: This cutoff is applied per reranking stage. In a chain of rerankers, each reranker can have its own cutoff, potentially further reducing the number of results at each stage. If both 'limit' and 'cutoff' are specified, the cutoff is applied first, followed by the limit.","format":"float"}},"x-vectaraParents":["SearchReranker"],"title":"UserFunctionReranker"},"mmr":{"description":"A reranker that uses Maximal Marginal Relevance to balance relevance and diversity in search results.","type":"object","properties":{"type":{"description":"When the type is `mmr`, you can specify the `diversity_bias`, and the retrieval engine will use the MMR reranker.","type":"string","default":"mmr"},"diversity_bias":{"description":"The diversity bias. Higher values indicate more diversity.","type":"number","format":"float","example":0.3},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. \nWhen a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1},"cutoff":{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process. When a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm. 2. Applies the cutoff, removing any results with scores below the specified threshold. 3. Returns the remaining results, sorted by their new scores.\nNote: This cutoff is applied per reranking stage. In a chain of rerankers, each reranker can have its own cutoff, potentially further reducing the number of results at each stage. If both 'limit' and 'cutoff' are specified, the cutoff is applied first, followed by the limit.","format":"float"}},"x-vectaraParents":["SearchReranker"],"title":"MMRReranker"},"chain":{"description":"A reranker that applies multiple rerankers in sequence to produce the final search results.","type":"object","properties":{"type":{"description":"When the type is `chain`, you can then chain re-rankers together.","type":"string","default":"chain"},"rerankers":{"type":"array","description":"Specify an array of rerankers to apply to search results consecutively.","items":"circular(SearchReranker)","maxItems":50}},"required":["rerankers"],"x-vectaraParents":["SearchReranker"],"title":"ChainReranker"},"none":{"description":"A placeholder reranker that does not modify the original search results ordering.","type":"object","properties":{"type":{"description":"When the type is `none`, no reranking will be done.","type":"string","default":"none"},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. When a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1}},"x-vectaraParents":["SearchReranker"],"title":"NoneReranker"}}},"oneOf":[{"description":"Reranker that is specific to the customer.","type":"object","properties":{"type":{"description":"When the type is `customer_reranker`, you can specify the `reranker_name` of a reranker. `reranker_id` is deprecated. The retrieval engine will then rerank results using that reranker.","type":"string","default":"customer_reranker"},"reranker_id":{"description":"The ID of the reranker. The multilingual reranker that may be specified is rnk_272725719. Do not specify the MMR reranker ID here, and instead, use the MMR reranker object type. **Deprecated**: Use `reranker_name` instead.","type":"string","pattern":"rnk_(?!272725718)\\d+","example":"rnk_272725719","deprecated":true},"reranker_name":{"description":"The name of the reranker. Do not specify the MMR reranker name here. Instead, use the MMR reranker object type.","type":"string","example":"Rerank_Multilingual_v1"},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. When a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1},"cutoff":{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process. When a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm. 2. Applies the cutoff, removing any results with scores below the specified threshold. 3. Returns the remaining results, sorted by their new scores.\nNote: This cutoff is applied per reranking stage. In a chain of rerankers, each reranker can have its own cutoff, potentially further reducing the number of results at each stage. If both 'limit' and 'cutoff' are specified, the cutoff is applied first, followed by the limit.","format":"float"},"include_context":{"type":"boolean","default":true,"description":"If true, the reranker will use text with context (see \"context_configuration\") for scoring."}},"x-vectaraParents":["SearchReranker"],"title":"CustomerSpecificReranker"},{"description":"A reranker that uses user-defined functions to reorder search results.","type":"object","properties":{"type":{"description":"When the type is `userfn`, you can define custom reranking functions using document-level metadata, part-level metadata, or scores generated from the request-level metadata.","type":"string","default":"userfn"},"user_function":{"description":"The user defined function.","type":"string","example":"get('$.score') * get('$.document_metadata.boost')"},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. \nWhen a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1},"cutoff":{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process. When a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm. 2. Applies the cutoff, removing any results with scores below the specified threshold. 3. Returns the remaining results, sorted by their new scores.\nNote: This cutoff is applied per reranking stage. In a chain of rerankers, each reranker can have its own cutoff, potentially further reducing the number of results at each stage. If both 'limit' and 'cutoff' are specified, the cutoff is applied first, followed by the limit.","format":"float"}},"x-vectaraParents":["SearchReranker"],"title":"UserFunctionReranker"},{"description":"A reranker that uses Maximal Marginal Relevance to balance relevance and diversity in search results.","type":"object","properties":{"type":{"description":"When the type is `mmr`, you can specify the `diversity_bias`, and the retrieval engine will use the MMR reranker.","type":"string","default":"mmr"},"diversity_bias":{"description":"The diversity bias. Higher values indicate more diversity.","type":"number","format":"float","example":0.3},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. \nWhen a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1},"cutoff":{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process. When a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm. 2. Applies the cutoff, removing any results with scores below the specified threshold. 3. Returns the remaining results, sorted by their new scores.\nNote: This cutoff is applied per reranking stage. In a chain of rerankers, each reranker can have its own cutoff, potentially further reducing the number of results at each stage. If both 'limit' and 'cutoff' are specified, the cutoff is applied first, followed by the limit.","format":"float"}},"x-vectaraParents":["SearchReranker"],"title":"MMRReranker"},{"description":"A reranker that applies multiple rerankers in sequence to produce the final search results.","type":"object","properties":{"type":{"description":"When the type is `chain`, you can then chain re-rankers together.","type":"string","default":"chain"},"rerankers":{"type":"array","description":"Specify an array of rerankers to apply to search results consecutively.","items":"circular(SearchReranker)","maxItems":50}},"required":["rerankers"],"x-vectaraParents":["SearchReranker"],"title":"ChainReranker"},{"description":"A placeholder reranker that does not modify the original search results ordering.","type":"object","properties":{"type":{"description":"When the type is `none`, no reranking will be done.","type":"string","default":"none"},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. When a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1}},"x-vectaraParents":["SearchReranker"],"title":"NoneReranker"}],"title":"SearchReranker"}},"title":"SearchParameters"}],"required":["corpora"],"title":"SearchCorporaParameters"},"generation":{"description":"The parameters to control generation.","type":"object","properties":{"generation_preset_name":{"description":"The preset values to use to feed the query results and other context to the model.\nA `generation_preset` is an object with a bundle of properties that specifies: * The `prompt_template` that is rendered and then sent to the LLM. * The LLM used. * `model_parameter`s such as temperature.\nAll of these properties except the model can be overridden by setting them in this object. Even when a `prompt_template` is set, the `generation_preset_name` is used to set the model used. See `model_parameters.model` if you want to set the model explicitly.\nIf `generation_preset_name` is not set, the Vectara platform will use the default model and prompt.","type":"string","minLength":1,"example":"vectara-summary-ext-v1.2.0"},"prompt_name":{"description":"Use `generation_preset_name` instead of `prompt_name`.","type":"string","minLength":1,"example":"vectara-summary-ext-v1.2.0","deprecated":true},"max_used_search_results":{"description":"The maximum number of search results to be available to the prompt.","type":"integer","format":"int32","minimum":0,"default":5},"prompt_template":{"description":"Vectara manages both system and user roles and prompts for the generative LLM out of the box by default. However, users can override the `prompt_template` via this variable. The `prompt_template` is in the form of an Apache Velocity template. For more details on how to configure the `prompt_template`, see the [long-form documentation](https://docs.vectara.com/docs/prompts/vectara-prompt-engine).","type":"string","example":"[\n  {\"role\": \"system\", \"content\": \"You are a helpful search assistant.\"},\n  #foreach ($qResult in $vectaraQueryResults)\n     {\"role\": \"user\", \"content\": \"Given the $vectaraIdxWord[$foreach.index] search result.\"},\n     {\"role\": \"assistant\", \"content\": \"${qResult.getText()}\" },\n  #end\n  {\"role\": \"user\", \"content\": \"Generate a summary for the query '${vectaraQuery}' based on the above results.\"}\n]\n"},"prompt_text":{"description":"This property is deprecated in favor of clearer naming. Use `prompt_template`. This property will be ignored if `prompt_template` is set.","type":"string","example":"[\n  {\"role\": \"system\", \"content\": \"You are a helpful search assistant.\"},\n  #foreach ($qResult in $vectaraQueryResults)\n     {\"role\": \"user\", \"content\": \"Given the $vectaraIdxWord[$foreach.index] search result.\"},\n     {\"role\": \"assistant\", \"content\": \"${qResult.getText()}\" },\n  #end\n  {\"role\": \"user\", \"content\": \"Generate a summary for the query '${vectaraQuery}' based on the above results.\"}\n]\n","deprecated":true},"max_response_characters":{"description":"Controls the length of the generated output. This is a rough estimate and not a hard limit: the end output can be longer or shorter than this value. This is generally implemented by including the `max_response_characters` in the prompt, and the LLM's instruction following capability dictates how closely the generated output is limited.","type":"integer","format":"int32","example":300,"minimum":0},"response_language":{"description":"Languages that the Vectara platform supports.","type":"string","enum":["auto","eng","deu","fra","zho","kor","ara","rus","tha","nld","ita","por","spa","jpn","pol","tur","vie","ind","ces","ukr","ell","heb","fas","hin","urd","swe","ben","msa","ron"],"default":"auto","title":"Language"},"model_parameters":{"title":"ModelParameters","description":"The parameters for the model. WARNING: This is an experimental feature, and breakable at any point with virtually no notice. It is meant for experimentation to converge on optimal parameters that can then be set in the prompt definitions.","type":"object","properties":{"llm_name":{"description":"The model (e.g., `gpt-4`) to use for summarization. If specified, it will override the model behind `generation_preset_name`.","type":"string","example":"gpt4"},"max_tokens":{"description":"The maximum number of tokens to be returned by the model.","type":"integer","format":"int32","minimum":1},"temperature":{"description":"The sampling temperature to use. Higher values make the output more random, while lower values make it more focused and deterministic.","type":"number","format":"float"},"frequency_penalty":{"description":"Higher values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.","type":"number","format":"float"},"presence_penalty":{"description":"Higher values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.","type":"number","format":"float"}}},"citations":{"description":"Style the generator should use when making citations.","type":"object","properties":{"style":{"description":"The citation style to be used in summary. Can be one of: * `numeric` - Citations formatted as simple numerals: \\[1\\], \\[2\\] ... * `none` - Citations removed from text. * `html` - Citation formatted as a URL like `<a href=\"url_pattern\">text_pattern</a>`. * `markdown` - Formatted as `[text_pattern](url_pattern)`.","type":"string","enum":["none","numeric","html","markdown"]},"url_pattern":{"description":"The URL pattern if the citation_style is set to `html` or `markdown`. The pattern can access metadata attributes in the document or part. e.g. `https://my.doc/foo/{doc.id}/{part.id}` The default `url_pattern` is an empty string.","type":"string","example":"https://vectara.com/documents/{doc.id}"},"text_pattern":{"description":"The text pattern if the citation_style is set to `html` or `markdown`. This pattern sets the href for HTML or the text within `[]` in markdown, and defaults to N being the index of result if it is not set. The default citation style looks like `[N](<url_pattern>)` for markdown. You can use metadata attributes in the `text_pattern`. For example, the pattern `{doc.title}` with citation style `markdown` would result in final citation output like `[Title](<url_pattern>)` when the document's metadata includes `{\"title\":\"Title\"}`.","type":"string","example":"{doc.title}"}},"title":"CitationParameters"},"enable_factual_consistency_score":{"description":"Enable returning the factual consistency score with query results.","type":"boolean","default":true}},"title":"GenerationParameters"},"chat":{"type":"object","description":"Parameters to control chat behavior.","properties":{"store":{"description":"Indicates whether to store chat messages and response messages.","type":"boolean","default":true}},"title":"ChatParameters"},"save_history":{"description":"Indicates whether to save the chat in both the chat and query history. This overrides `chat.store`.","type":"boolean","default":true},"intelligent_query_rewriting":{"description":"[Tech Preview] Indicates whether to enable intelligent query rewriting. When enabled, the platform will attempt to extract metadata filter and rewrite the query to improve search results. Read [here](https://docs.vectara.com/docs/search-and-retrieval/intelligent-query-rewriting) for more details.","type":"boolean","default":false},"stream_response":{"description":"Indicates whether the response should be streamed or not.","type":"boolean","default":false}},"required":["query","search"],"title":"ChatRequest"}}}}}
>
  
</RequestSchema>

<StatusCodes
  id={undefined}
  label={undefined}
  responses={{"200":{"description":"A response to a chat request.","content":{"application/json":{"schema":{"description":"Full response to a chat question when the result is not streamed.","type":"object","properties":{"chat_id":{"description":"If the chat response was stored, the ID of the chat.","type":"string"},"turn_id":{"description":"If the chat response was stored, the ID of the turn.","type":"string"},"answer":{"description":"The message from the chat model for the chat message.","type":"string"},"response_language":{"description":"Languages that the Vectara platform supports.","type":"string","enum":["auto","eng","deu","fra","zho","kor","ara","rus","tha","nld","ita","por","spa","jpn","pol","tur","vie","ind","ces","ukr","ell","heb","fas","hin","urd","swe","ben","msa","ron"],"default":"auto","title":"Language"},"search_results":{"description":"The ranked search results that the chat model used.","type":"array","items":{"description":"An individual ranked search result from a query.","type":"object","properties":{"text":{"description":"The document part altered by the context configuration that matches the query.","type":"string"},"score":{"description":"The score of the individual result.","type":"number","format":"double"},"part_metadata":{"description":"The metadata for the document part.","type":"object","additionalProperties":true},"document_metadata":{"description":"The metadata for the document that contains the document part.","type":"object","additionalProperties":true},"document_id":{"description":"The ID of the document that contains the document part.","type":"string"},"table":{"description":"The table that the document part is from.","type":"object","properties":{"id":{"description":"The unique ID of the table within the document.","type":"string","example":"table_1"},"title":{"description":"The title of the table.","type":"string"},"data":{"description":"The data of the table.","type":"object","properties":{"headers":{"description":"The headers of the table.","type":"array","items":{"description":"The header of a table.","type":"array","items":{"description":"A cell in a table.","type":"object","properties":{"text_value":{"description":"A text value.","type":"string"},"int_value":{"description":"A signed 64-bit integer value.","type":"integer","format":"int64"},"float_value":{"description":"A floating-point value with double precision.","type":"number","format":"double"},"bool_value":{"description":"A boolean value.","type":"boolean"},"colspan":{"description":"The number of columns the cell spans. This field is optional; if not specified, default is 1. Must be greater than 0.","type":"integer","format":"int32"},"rowspan":{"description":"The number of rows the cell spans. This field is optional; if not specified, default is 1. Must be greater than 0.","type":"integer","format":"int32"}},"title":"Cell"},"title":"Header"}},"rows":{"description":"The rows in the data.","type":"array","items":{"description":"A row in a table.","type":"array","items":{"description":"A cell in a table.","type":"object","properties":{"text_value":{"description":"A text value.","type":"string"},"int_value":{"description":"A signed 64-bit integer value.","type":"integer","format":"int64"},"float_value":{"description":"A floating-point value with double precision.","type":"number","format":"double"},"bool_value":{"description":"A boolean value.","type":"boolean"},"colspan":{"description":"The number of columns the cell spans. This field is optional; if not specified, default is 1. Must be greater than 0.","type":"integer","format":"int32"},"rowspan":{"description":"The number of rows the cell spans. This field is optional; if not specified, default is 1. Must be greater than 0.","type":"integer","format":"int32"}},"title":"Cell"},"title":"Row"}}},"title":"Data"},"description":{"description":"The description of the table.","type":"string"}},"title":"Table"},"request_corpora_index":{"description":"A query request can search over multiple corpora at a time. This property is set to the index in the list of corpora in the original search request that this search result originated from. If the query request is only over one corpus, this property is 0.","type":"integer","format":"int32","example":0,"minimum":0}},"title":"IndividualSearchResult"}},"factual_consistency_score":{"description":"Indicates the probability that the summary is factually consistent with the results. The system excludes this property if it encounters excessively large outputs or search results.","type":"number","format":"float"},"rendered_prompt":{"description":"The rendered prompt sent to the LLM. Useful when creating customer `prompt_template` templates.","type":"string"},"warnings":{"description":"Non-fatal warnings that occurred during request processing","type":"array","items":{"type":"string","description":"Non-fatal warnings that occurred during query processing.\n *  `exceeded_max_input_length_fcs`: The input to the Factual Consistency Score model exceeded the maximum allowed length, so no score is being returned\n *  `intelligent_query_rewriting_failed`: Intelligent query rewriting failed due to an internal error","enum":["exceeded_max_input_length_fcs","intelligent_query_rewriting_failed"],"title":"QueryWarning"}},"rephrased_query":{"description":"View the actual query made to backend that was rephrased by the LLM from the input query.","type":"string"},"rewritten_queries":{"description":"The rewritten queries for the corpora that were searched. Only populated when intelligent_query_rewriting is enabled.","type":"array","items":{"description":"The rewritten query for a corpus that was searched.","type":"object","properties":{"corpus_key":{"description":"The corpus key that the query was made on.","type":"string"},"filter_extraction":{"type":"object","description":"The result of query filter extraction.","properties":{"query":{"description":"The query rephrased from the input query and executed.","type":"string"},"metadata_filter":{"description":"The metadata filter extracted from the input query.","type":"string"}},"title":"FilterExtraction"}},"title":"RewrittenQuery"}}},"title":"ChatFullResponse"}},"text/event-stream":{"schema":{"description":"An individual event when the response is streamed.","type":"object","discriminator":{"propertyName":"type","mapping":{"search_results":{"description":"The search response results.","type":"object","properties":{"type":{"description":"When the streaming event has the search results, the type will be `search_results`.","type":"string","default":"search_results"},"search_results":{"description":"The ranked search results.","type":"array","items":{"description":"An individual ranked search result from a query.","type":"object","properties":{"text":{"description":"The document part altered by the context configuration that matches the query.","type":"string"},"score":{"description":"The score of the individual result.","type":"number","format":"double"},"part_metadata":{"description":"The metadata for the document part.","type":"object","additionalProperties":true},"document_metadata":{"description":"The metadata for the document that contains the document part.","type":"object","additionalProperties":true},"document_id":{"description":"The ID of the document that contains the document part.","type":"string"},"table":{"description":"The table that the document part is from.","type":"object","properties":{"id":{"description":"The unique ID of the table within the document.","type":"string","example":"table_1"},"title":{"description":"The title of the table.","type":"string"},"data":{"description":"The data of the table.","type":"object","properties":{"headers":{"description":"The headers of the table.","type":"array","items":{"description":"The header of a table.","type":"array","items":{"description":"A cell in a table.","type":"object","properties":{"text_value":{"description":"A text value.","type":"string"},"int_value":{"description":"A signed 64-bit integer value.","type":"integer","format":"int64"},"float_value":{"description":"A floating-point value with double precision.","type":"number","format":"double"},"bool_value":{"description":"A boolean value.","type":"boolean"},"colspan":{"description":"The number of columns the cell spans. This field is optional; if not specified, default is 1. Must be greater than 0.","type":"integer","format":"int32"},"rowspan":{"description":"The number of rows the cell spans. This field is optional; if not specified, default is 1. Must be greater than 0.","type":"integer","format":"int32"}},"title":"Cell"},"title":"Header"}},"rows":{"description":"The rows in the data.","type":"array","items":{"description":"A row in a table.","type":"array","items":{"description":"A cell in a table.","type":"object","properties":{"text_value":{"description":"A text value.","type":"string"},"int_value":{"description":"A signed 64-bit integer value.","type":"integer","format":"int64"},"float_value":{"description":"A floating-point value with double precision.","type":"number","format":"double"},"bool_value":{"description":"A boolean value.","type":"boolean"},"colspan":{"description":"The number of columns the cell spans. This field is optional; if not specified, default is 1. Must be greater than 0.","type":"integer","format":"int32"},"rowspan":{"description":"The number of rows the cell spans. This field is optional; if not specified, default is 1. Must be greater than 0.","type":"integer","format":"int32"}},"title":"Cell"},"title":"Row"}}},"title":"Data"},"description":{"description":"The description of the table.","type":"string"}},"title":"Table"},"request_corpora_index":{"description":"A query request can search over multiple corpora at a time. This property is set to the index in the list of corpora in the original search request that this search result originated from. If the query request is only over one corpus, this property is 0.","type":"integer","format":"int32","example":0,"minimum":0}},"title":"IndividualSearchResult"}},"rewritten_queries":{"description":"The rewritten queries for the corpora that were searched. Only populated when `intelligent_query_rewriting` is enabled.","type":"array","items":{"description":"The rewritten query for a corpus that was searched.","type":"object","properties":{"corpus_key":{"description":"The corpus key that the query was made on.","type":"string"},"filter_extraction":{"type":"object","description":"The result of query filter extraction.","properties":{"query":{"description":"The query rephrased from the input query and executed.","type":"string"},"metadata_filter":{"description":"The metadata filter extracted from the input query.","type":"string"}},"title":"FilterExtraction"}},"title":"RewrittenQuery"}}},"x-vectaraParents":["QueryStreamedResponse","ChatStreamedResponse"],"title":"StreamSearchResponse"},"chat_info":{"description":"Information about the chat.","type":"object","properties":{"type":{"description":"This will be `chat_info` when the stream event contains information about how the chat is stored.","type":"string","default":"chat_info"},"chat_id":{"description":"ID of the chat.","type":"string","pattern":"cht_.+$"},"turn_id":{"description":"ID of the turn.","type":"string","pattern":"trn_.+$"}},"x-vectaraParents":["ChatStreamedResponse"],"title":"ChatInfoResponse"},"generation_chunk":{"description":"The chunk response from the generation, which may be a partial generation.","type":"object","properties":{"type":{"description":"When the streaming event contains the next chunk of generator output, the type will be `generation_chunk`.","type":"string","default":"generation_chunk"},"generation_chunk":{"description":"Part of the message from the generator. All summary chunks must be appended together in order to get the full summary.","type":"string"}},"x-vectaraParents":["QueryStreamedResponse","ChatStreamedResponse","SummarizeDocumentStreamedResponse"],"title":"StreamGenerationChunk"},"generation_end":{"description":"The end of generation. There may still be more information such as the factual consistency score, but generation has stopped.","type":"object","properties":{"type":{"description":"Then end of generation will be denoted with an object with the type `generation_end`.","type":"string","default":"generation_end"}},"x-vectaraParents":["QueryStreamedResponse","ChatStreamedResponse","SummarizeDocumentStreamedResponse"],"title":"StreamGenerationEnd"},"generation_info":{"description":"Event containing information on how the generation was accomplished.","type":"object","properties":{"type":{"description":"When the streaming event contains the generation information type will be `generation_info`.","type":"string","default":"generation_info"},"rendered_prompt":{"description":"The rendered prompt sent to the LLM. Useful when creating customer `prompt_template` templates.","type":"string"},"rephrased_query":{"description":"View the actual query made to backend that was rephrased by the LLM from the input query.","type":"string"}},"x-vectaraParents":["QueryStreamedResponse","ChatStreamedResponse","SummarizeDocumentStreamedResponse"],"title":"GenerationInfo"},"factual_consistency_score":{"description":"Event containing the factual consistency score.","type":"object","properties":{"type":{"description":"When the streaming event contains the factual consistency score, the type will be `factual_consistency_score`.","type":"string","default":"factual_consistency_score"},"factual_consistency_score":{"description":"The probability that the summary is factually consistent with the results.","type":"number","format":"float"}},"x-vectaraParents":["QueryStreamedResponse","ChatStreamedResponse"],"title":"FactualConsistencyScore"},"end":{"description":"The end of a query response stream.","type":"object","properties":{"type":{"description":"Then end of stream will be denoted with an object with the type `end`.","type":"string","default":"end"}},"x-vectaraParents":["QueryStreamedResponse","ChatStreamedResponse","SummarizeDocumentStreamedResponse"],"title":"StreamResponseEnd"},"error":{"description":"Event signaling there was an error with the request.","properties":{"type":{"description":"If the stream errors, an event with type `error` will be sent.","type":"string","default":"error"},"messages":{"description":"The error messages.","type":"array","items":{"type":"string"}}},"x-vectaraParents":["QueryStreamedResponse","ChatStreamedResponse","SummarizeDocumentStreamedResponse"],"title":"StreamError"}}},"oneOf":[{"description":"The search response results.","type":"object","properties":{"type":{"description":"When the streaming event has the search results, the type will be `search_results`.","type":"string","default":"search_results"},"search_results":{"description":"The ranked search results.","type":"array","items":{"description":"An individual ranked search result from a query.","type":"object","properties":{"text":{"description":"The document part altered by the context configuration that matches the query.","type":"string"},"score":{"description":"The score of the individual result.","type":"number","format":"double"},"part_metadata":{"description":"The metadata for the document part.","type":"object","additionalProperties":true},"document_metadata":{"description":"The metadata for the document that contains the document part.","type":"object","additionalProperties":true},"document_id":{"description":"The ID of the document that contains the document part.","type":"string"},"table":{"description":"The table that the document part is from.","type":"object","properties":{"id":{"description":"The unique ID of the table within the document.","type":"string","example":"table_1"},"title":{"description":"The title of the table.","type":"string"},"data":{"description":"The data of the table.","type":"object","properties":{"headers":{"description":"The headers of the table.","type":"array","items":{"description":"The header of a table.","type":"array","items":{"description":"A cell in a table.","type":"object","properties":{"text_value":{"description":"A text value.","type":"string"},"int_value":{"description":"A signed 64-bit integer value.","type":"integer","format":"int64"},"float_value":{"description":"A floating-point value with double precision.","type":"number","format":"double"},"bool_value":{"description":"A boolean value.","type":"boolean"},"colspan":{"description":"The number of columns the cell spans. This field is optional; if not specified, default is 1. Must be greater than 0.","type":"integer","format":"int32"},"rowspan":{"description":"The number of rows the cell spans. This field is optional; if not specified, default is 1. Must be greater than 0.","type":"integer","format":"int32"}},"title":"Cell"},"title":"Header"}},"rows":{"description":"The rows in the data.","type":"array","items":{"description":"A row in a table.","type":"array","items":{"description":"A cell in a table.","type":"object","properties":{"text_value":{"description":"A text value.","type":"string"},"int_value":{"description":"A signed 64-bit integer value.","type":"integer","format":"int64"},"float_value":{"description":"A floating-point value with double precision.","type":"number","format":"double"},"bool_value":{"description":"A boolean value.","type":"boolean"},"colspan":{"description":"The number of columns the cell spans. This field is optional; if not specified, default is 1. Must be greater than 0.","type":"integer","format":"int32"},"rowspan":{"description":"The number of rows the cell spans. This field is optional; if not specified, default is 1. Must be greater than 0.","type":"integer","format":"int32"}},"title":"Cell"},"title":"Row"}}},"title":"Data"},"description":{"description":"The description of the table.","type":"string"}},"title":"Table"},"request_corpora_index":{"description":"A query request can search over multiple corpora at a time. This property is set to the index in the list of corpora in the original search request that this search result originated from. If the query request is only over one corpus, this property is 0.","type":"integer","format":"int32","example":0,"minimum":0}},"title":"IndividualSearchResult"}},"rewritten_queries":{"description":"The rewritten queries for the corpora that were searched. Only populated when `intelligent_query_rewriting` is enabled.","type":"array","items":{"description":"The rewritten query for a corpus that was searched.","type":"object","properties":{"corpus_key":{"description":"The corpus key that the query was made on.","type":"string"},"filter_extraction":{"type":"object","description":"The result of query filter extraction.","properties":{"query":{"description":"The query rephrased from the input query and executed.","type":"string"},"metadata_filter":{"description":"The metadata filter extracted from the input query.","type":"string"}},"title":"FilterExtraction"}},"title":"RewrittenQuery"}}},"x-vectaraParents":["QueryStreamedResponse","ChatStreamedResponse"],"title":"StreamSearchResponse"},{"description":"Information about the chat.","type":"object","properties":{"type":{"description":"This will be `chat_info` when the stream event contains information about how the chat is stored.","type":"string","default":"chat_info"},"chat_id":{"description":"ID of the chat.","type":"string","pattern":"cht_.+$"},"turn_id":{"description":"ID of the turn.","type":"string","pattern":"trn_.+$"}},"x-vectaraParents":["ChatStreamedResponse"],"title":"ChatInfoResponse"},{"description":"The chunk response from the generation, which may be a partial generation.","type":"object","properties":{"type":{"description":"When the streaming event contains the next chunk of generator output, the type will be `generation_chunk`.","type":"string","default":"generation_chunk"},"generation_chunk":{"description":"Part of the message from the generator. All summary chunks must be appended together in order to get the full summary.","type":"string"}},"x-vectaraParents":["QueryStreamedResponse","ChatStreamedResponse","SummarizeDocumentStreamedResponse"],"title":"StreamGenerationChunk"},{"description":"The end of generation. There may still be more information such as the factual consistency score, but generation has stopped.","type":"object","properties":{"type":{"description":"Then end of generation will be denoted with an object with the type `generation_end`.","type":"string","default":"generation_end"}},"x-vectaraParents":["QueryStreamedResponse","ChatStreamedResponse","SummarizeDocumentStreamedResponse"],"title":"StreamGenerationEnd"},{"description":"Event containing the factual consistency score.","type":"object","properties":{"type":{"description":"When the streaming event contains the factual consistency score, the type will be `factual_consistency_score`.","type":"string","default":"factual_consistency_score"},"factual_consistency_score":{"description":"The probability that the summary is factually consistent with the results.","type":"number","format":"float"}},"x-vectaraParents":["QueryStreamedResponse","ChatStreamedResponse"],"title":"FactualConsistencyScore"},{"description":"The end of a query response stream.","type":"object","properties":{"type":{"description":"Then end of stream will be denoted with an object with the type `end`.","type":"string","default":"end"}},"x-vectaraParents":["QueryStreamedResponse","ChatStreamedResponse","SummarizeDocumentStreamedResponse"],"title":"StreamResponseEnd"},{"description":"Event containing information on how the generation was accomplished.","type":"object","properties":{"type":{"description":"When the streaming event contains the generation information type will be `generation_info`.","type":"string","default":"generation_info"},"rendered_prompt":{"description":"The rendered prompt sent to the LLM. Useful when creating customer `prompt_template` templates.","type":"string"},"rephrased_query":{"description":"View the actual query made to backend that was rephrased by the LLM from the input query.","type":"string"}},"x-vectaraParents":["QueryStreamedResponse","ChatStreamedResponse","SummarizeDocumentStreamedResponse"],"title":"GenerationInfo"},{"description":"Event signaling there was an error with the request.","properties":{"type":{"description":"If the stream errors, an event with type `error` will be sent.","type":"string","default":"error"},"messages":{"description":"The error messages.","type":"array","items":{"type":"string"}}},"x-vectaraParents":["QueryStreamedResponse","ChatStreamedResponse","SummarizeDocumentStreamedResponse"],"title":"StreamError"}],"title":"ChatStreamedResponse"}}}},"400":{"description":"Chat creation request was malformed.","content":{"application/json":{"schema":{"description":"Error returned when a request contains invalid parameters or violates schema validation.","type":"object","properties":{"field_errors":{"description":"The errors that relate to specific fields in the request.","type":"object","additionalProperties":{"type":"string"}},"messages":{"type":"array","items":{"title":"message","type":"string"}},"request_id":{"description":"The ID of the request that can be used to help Vectara support debug what went wrong.","type":"string"}},"title":"BadRequestError"}}}},"403":{"description":"Permissions do not allow creating a chat in the corpus.","content":{"application/json":{"schema":{"description":"A general error response with an error code and message.","type":"object","properties":{"messages":{"description":"The messages describing why the error occurred.","type":"array","items":{"title":"message","type":"string","example":"Internal server error."}},"request_id":{"description":"The ID of the request that can be used to help Vectara support debug what went wrong.","type":"string"}},"title":"Error"}}}},"404":{"description":"Corpus not found.","content":{"application/json":{"schema":{"description":"Error returned when a requested resource does not exist.","type":"object","properties":{"id":{"description":"The ID cannot be found.","type":"string"},"messages":{"type":"array","items":{"title":"message","type":"string"}},"request_id":{"description":"The ID of the request that can be used to help Vectara support debug what went wrong.","type":"string"}},"title":"NotFoundError"}}}}}}
>
  
</StatusCodes>


      