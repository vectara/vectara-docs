---
id: create-chat
title: "Start a chat"
description: "Create a chat while specifying the default retrieval parameters used by the prompt."
sidebar_label: "Start a chat"
hide_title: true
hide_table_of_contents: true
api: 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
sidebar_class_name: "post api-method"
info_path: docs/rest-api/vectara-rest-api-v-2
custom_edit_url: null
---

import ApiTabs from "@theme/ApiTabs";
import DiscriminatorTabs from "@theme/DiscriminatorTabs";
import MethodEndpoint from "@theme/ApiExplorer/MethodEndpoint";
import SecuritySchemes from "@theme/ApiExplorer/SecuritySchemes";
import MimeTabs from "@theme/MimeTabs";
import ParamsItem from "@theme/ParamsItem";
import ResponseSamples from "@theme/ResponseSamples";
import SchemaItem from "@theme/SchemaItem";
import SchemaTabs from "@theme/SchemaTabs";
import Heading from "@theme/Heading";
import OperationTabs from "@theme/OperationTabs";
import TabItem from "@theme/TabItem";

<h1 className={"openapi__heading"}>Start a chat</h1>

<MethodEndpoint method={"post"} path={"/v2/chats"}></MethodEndpoint>



Create a chat while specifying the default retrieval parameters used by the prompt.

## Request

<details style={{"marginBottom":"1rem"}} className={"openapi-markdown__details"} data-collapsed={false} open={true}><summary style={{}}><h3 className={"openapi-markdown__details-summary-header-params"}>Header Parameters</h3></summary><div><ul><ParamsItem className={"paramsItem"} param={{"in":"header","name":"Request-Timeout","description":"The API will make a best effort to complete the request in the specified seconds or time out.","schema":{"type":"integer","minimum":1},"required":false}}></ParamsItem><ParamsItem className={"paramsItem"} param={{"in":"header","name":"Request-Timeout-Millis","description":"The API will make a best effort to complete the request in the specified milliseconds or time out.","schema":{"type":"integer","minimum":1}}}></ParamsItem></ul></div></details><MimeTabs className={"openapi-tabs__mime"}><TabItem label={"application/json"} value={"application/json-schema"}><details style={{}} className={"openapi-markdown__details mime"} data-collapsed={false} open={true}><summary style={{}} className={"openapi-markdown__details-summary-mime"}><h3 className={"openapi-markdown__details-summary-header-body"}>Body</h3></summary><div style={{"textAlign":"left","marginLeft":"1rem"}}></div><ul style={{"marginLeft":"1rem"}}><SchemaItem collapsible={false} name={"query"} required={true} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"The chat message or question.","type":"string","example":"How can I use the Vectara platform?"}}></SchemaItem><SchemaItem collapsible={true} className={"schemaItem"}><details style={{}} className={"openapi-markdown__details"}><summary style={{}}><span className={"openapi-schema__container"}><strong className={"openapi-schema__property"}>search</strong><span className={"openapi-schema__name"}> object</span><span className={"openapi-schema__divider"}></span><span className={"openapi-schema__required"}>required</span></span></summary><div style={{"marginLeft":"1rem"}}><div style={{"marginTop":".5rem","marginBottom":".5rem"}}>

Search parameters to retrieve knowledge for the query.

</div><SchemaItem collapsible={true} className={"schemaItem"}><details style={{}} className={"openapi-markdown__details"}><summary style={{}}><span className={"openapi-schema__container"}><strong className={"openapi-schema__property"}>corpora</strong><span className={"openapi-schema__name"}> object[]</span></span></summary><div style={{"marginLeft":"1rem"}}><div style={{"marginTop":".5rem","marginBottom":".5rem"}}>

**Possible values:** `>= 1`

</div><div style={{"marginTop":".5rem","marginBottom":".5rem"}}>

The corpora that you want to search.

</div><li><div style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}>Array [</div></li><SchemaItem collapsible={true} className={"schemaItem"}><details style={{}} className={"openapi-markdown__details"}><summary style={{}}><span className={"openapi-schema__container"}><strong className={"openapi-schema__property"}>custom_dimensions</strong><span className={"openapi-schema__name"}> object</span></span></summary><div style={{"marginLeft":"1rem"}}><div style={{"marginTop":".5rem","marginBottom":".5rem"}}>

The custom dimensions as additional weights.

</div><SchemaItem name={"property name*"} required={false} schemaName={"double"} qualifierMessage={undefined} schema={{"type":"number","format":"double"}} collapsible={false} discriminator={false}></SchemaItem></div></details></SchemaItem><SchemaItem collapsible={false} name={"metadata_filter"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"The filter string to narrow the search to according to metadata attributes. The query against this\ncorpus will be confined to document parts that match the `metadata_filter`. Only metadata\nset as `filter_attributes` on the corpus can be filtered. Filter syntax is similiar to\na SQL where clause. See [metadata filters documentation](https://docs.vectara.com/docs/learn/metadata-search-filtering/filter-overview)\nfor more information.\n","type":"string","example":"doc.title = 'Charlotte''s Web'"}}></SchemaItem><SchemaItem collapsible={false} name={"lexical_interpolation"} required={false} schemaName={"float"} qualifierMessage={"**Possible values:** `<= 1`"} schema={{"description":"How much to weigh lexical scores compared to the embedding score. 0 means lexical search is not used at all, and 1 means only lexical search is used.","type":"number","format":"float","minimum":0,"maximum":1,"example":0.025}}></SchemaItem><SchemaItem collapsible={false} name={"semantics"} required={false} schemaName={"SearchSemantics (string)"} qualifierMessage={"**Possible values:** [`default`, `query`, `response`]"} schema={{"description":"Indicates whether to consider a query against this corpus as a query or a response.","type":"string","enum":["default","query","response"],"default":"default","title":"SearchSemantics"}}></SchemaItem><SchemaItem collapsible={false} name={"corpus_key"} required={true} schemaName={"CorpusKey (string)"} qualifierMessage={"**Possible values:** `<= 50 characters`, Value must match regular expression `[a-zA-Z0-9_\\=\\-]+$`"} schema={{"description":"A user-provided key for a corpus.","type":"string","example":"my-corpus","pattern":"[a-zA-Z0-9_\\=\\-]+$","maxLength":50,"title":"CorpusKey"}}></SchemaItem><li><div style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}>]</div></li></div></details></SchemaItem><SchemaItem collapsible={false} name={"offset"} required={false} schemaName={"int32"} qualifierMessage={undefined} schema={{"description":"Specifies how many results into the result to skip. This is useful for pagination.","type":"integer","format":"int32","default":0,"minimum":0}}></SchemaItem><SchemaItem collapsible={false} name={"limit"} required={false} schemaName={"int32"} qualifierMessage={"**Possible values:** `>= 1`"} schema={{"description":"The maximum number of results returned.","type":"integer","format":"int32","minimum":1,"default":10}}></SchemaItem><SchemaItem collapsible={true} className={"schemaItem"}><details style={{}} className={"openapi-markdown__details"}><summary style={{}}><span className={"openapi-schema__container"}><strong className={"openapi-schema__property"}>context_configuration</strong><span className={"openapi-schema__name"}> object</span></span></summary><div style={{"marginLeft":"1rem"}}><div style={{"marginTop":".5rem","marginBottom":".5rem"}}>

Configuration on the presentation of each document part in the result set.

</div><SchemaItem collapsible={false} name={"characters_before"} required={false} schemaName={"int32"} qualifierMessage={undefined} schema={{"description":"The number of characters that are shown before the matching document part.\nThis is useful to show the context of the document part in the wider document.\nIgnored if `sentences_before` is set.\nVectara will capture the full sentence that contains the captured characters,\nto not lose the meaning caused by a truncated word or sentence.\n","type":"integer","format":"int32","default":0,"minimum":0,"example":30}}></SchemaItem><SchemaItem collapsible={false} name={"characters_after"} required={false} schemaName={"int32"} qualifierMessage={undefined} schema={{"description":"The number of characters that are shown after the matching document part. \nThis is useful to show the context of the document part in the wider document.\nIgnored if `sentences_after` is set.\nVectara will capture the full sentence that contains the captured characters,\nto not lose the meaning caused by a truncated word or sentence.\n","type":"integer","format":"int32","default":0,"minimum":0,"example":30}}></SchemaItem><SchemaItem collapsible={false} name={"sentences_before"} required={false} schemaName={"int32"} qualifierMessage={undefined} schema={{"description":"The number of sentences that are shown before the matching document part.\nThis is useful to show the context of the document part in the wider document.\n","type":"integer","format":"int32","default":0,"minimum":0,"example":3}}></SchemaItem><SchemaItem collapsible={false} name={"sentences_after"} required={false} schemaName={"int32"} qualifierMessage={undefined} schema={{"description":"The number of sentences that are shown after the matching document part. \nThis is useful to show the context of the document part in the wider document.\n","type":"integer","format":"int32","default":0,"minimum":0,"example":3}}></SchemaItem><SchemaItem collapsible={false} name={"start_tag"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"The tag that wraps the document part at the start. This is often used to \nprovide a start HTML/XML tag or some other delimiter you can use in an \napplication to understand where to provide highlighting in your UI and \nunderstand where the context before ends and the document part begins.\n","type":"string","example":"<em>"}}></SchemaItem><SchemaItem collapsible={false} name={"end_tag"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"The tag that wraps the document part at the end. This is often used to \nprovide a start HTML/XML tag or some other delimiter you can use in an \napplication to understand where to provide highlighting in your UI and \nunderstand where the context before ends and the document part begins.\n","type":"string","example":"</em>"}}></SchemaItem></div></details></SchemaItem><SchemaItem collapsible={true} className={"schemaItem"}><details style={{}} className={"openapi-markdown__details"}><summary style={{}}><strong>reranker</strong><span style={{"opacity":"0.6"}}> object</span></summary><div style={{"marginLeft":"1rem"}}><div style={{"marginTop":".5rem","marginBottom":".5rem"}}>

Rerank results of the search. Rerankers are very powerful tools to better order search results.
By default the search will use the most powerful reranker available to the customer's plan.
To disable reranking set the reranker `type` to `"none"`.


</div></div><div><span className={"badge badge--info"}>oneOf</span><SchemaTabs><TabItem label={"CustomerSpecificReranker"} value={"0-item-properties"}><SchemaItem collapsible={false} name={"type"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"When type is `customer_reranker`, you can specify the `reranker_name` of a reranker. `reranker_id` is deprecated.\nThe retrieval engine will then rerank results using that reranker.\n","type":"string","default":"customer_reranker"}}></SchemaItem><SchemaItem collapsible={false} name={"reranker_id"} required={false} schemaName={"string"} qualifierMessage={"**Possible values:** Value must match regular expression `rnk_(?!272725718)\\d+`"} schema={{"description":"The ID of the reranker. The multilingual reranker that may be used by Scale customers is rnk_272725719.\nDo not specify the MMR reranker ID here, and instead, use the MMR reranker object type.\n**Deprecated**: Use `reranker_name` instead.\n","type":"string","pattern":"rnk_(?!272725718)\\d+","example":"rnk_272725719","deprecated":true}}></SchemaItem><SchemaItem collapsible={false} name={"reranker_name"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"The name of the reranker. Do not specify the MMR reranker name here. Instead, use the MMR reranker object type.\n","type":"string","example":"Rerank_Multilingual_v1"}}></SchemaItem><SchemaItem collapsible={false} name={"limit"} required={false} schemaName={"int32"} qualifierMessage={"**Possible values:** `>= 1`"} schema={{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. \nWhen a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, \neach reranker can have its own limit, potentially reducing the number of \nresults at each stage.\n","format":"int32","minimum":1}}></SchemaItem><SchemaItem collapsible={false} name={"cutoff"} required={false} schemaName={"float"} qualifierMessage={undefined} schema={{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process.\nWhen a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Applies the cutoff, removing any results with scores below the specified threshold.\n3. Returns the remaining results, sorted by their new scores.\n\nNote: This cutoff is applied per reranking stage. In a chain of rerankers,\neach reranker can have its own cutoff, potentially further reducing the number of\nresults at each stage. If both 'limit' and 'cutoff' are specified, the cutoff\nis applied first, followed by the limit.\n","format":"float"}}></SchemaItem></TabItem><TabItem label={"UserFunctionReranker"} value={"1-item-properties"}><SchemaItem collapsible={false} name={"type"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"When the type is `userfn`, you can define custom reranking functions using document-level metadata,\npart-level metadata, or scores generated from the request-level metadata.\n","type":"string","default":"userfn"}}></SchemaItem><SchemaItem collapsible={false} name={"user_function"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"The user defined function.","type":"string","example":"get('$.score') * get('$.document_metadata.boost')"}}></SchemaItem><SchemaItem collapsible={false} name={"limit"} required={false} schemaName={"int32"} qualifierMessage={"**Possible values:** `>= 1`"} schema={{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. \nWhen a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, \neach reranker can have its own limit, potentially reducing the number of \nresults at each stage.\n","format":"int32","minimum":1}}></SchemaItem><SchemaItem collapsible={false} name={"cutoff"} required={false} schemaName={"float"} qualifierMessage={undefined} schema={{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process.\nWhen a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Applies the cutoff, removing any results with scores below the specified threshold.\n3. Returns the remaining results, sorted by their new scores.\n\nNote: This cutoff is applied per reranking stage. In a chain of rerankers,\neach reranker can have its own cutoff, potentially further reducing the number of\nresults at each stage. If both 'limit' and 'cutoff' are specified, the cutoff\nis applied first, followed by the limit.\n","format":"float"}}></SchemaItem></TabItem><TabItem label={"MMRReranker"} value={"2-item-properties"}><SchemaItem collapsible={false} name={"type"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"When the type is `mmr`, you can specify the `diversity_bias`, and the\nthe retrieval engine will use the MMR reranker.\n","type":"string","default":"mmr"}}></SchemaItem><SchemaItem collapsible={false} name={"diversity_bias"} required={false} schemaName={"float"} qualifierMessage={undefined} schema={{"description":"The diversity bias. Higher values indicate more diversity.","type":"number","format":"float","example":0.3}}></SchemaItem><SchemaItem collapsible={false} name={"limit"} required={false} schemaName={"int32"} qualifierMessage={"**Possible values:** `>= 1`"} schema={{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. \nWhen a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, \neach reranker can have its own limit, potentially reducing the number of \nresults at each stage.\n","format":"int32","minimum":1}}></SchemaItem><SchemaItem collapsible={false} name={"cutoff"} required={false} schemaName={"float"} qualifierMessage={undefined} schema={{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process.\nWhen a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Applies the cutoff, removing any results with scores below the specified threshold.\n3. Returns the remaining results, sorted by their new scores.\n\nNote: This cutoff is applied per reranking stage. In a chain of rerankers,\neach reranker can have its own cutoff, potentially further reducing the number of\nresults at each stage. If both 'limit' and 'cutoff' are specified, the cutoff\nis applied first, followed by the limit.\n","format":"float"}}></SchemaItem></TabItem><TabItem label={"ChainReranker"} value={"3-item-properties"}><SchemaItem collapsible={false} name={"type"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"When the type is `chain`, you can then chain re-rankers together.\n","type":"string","default":"chain"}}></SchemaItem><SchemaItem collapsible={false} name={"rerankers"} required={true} schemaName={"array"} qualifierMessage={"**Possible values:** `<= 50`"} schema={{"type":"array","description":"Specify an array of rerankers to apply to search results consecutively.\n","maxItems":50}}></SchemaItem></TabItem><TabItem label={"NoneReranker"} value={"4-item-properties"}><SchemaItem collapsible={false} name={"type"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"When the type is `none`, no reranking will be done.\n","type":"string","default":"none"}}></SchemaItem><SchemaItem collapsible={false} name={"limit"} required={false} schemaName={"int32"} qualifierMessage={"**Possible values:** `>= 1`"} schema={{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. \nWhen a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, \neach reranker can have its own limit, potentially reducing the number of \nresults at each stage.\n","format":"int32","minimum":1}}></SchemaItem></TabItem></SchemaTabs></div></details></SchemaItem></div></details></SchemaItem><SchemaItem collapsible={true} className={"schemaItem"}><details style={{}} className={"openapi-markdown__details"}><summary style={{}}><span className={"openapi-schema__container"}><strong className={"openapi-schema__property"}>generation</strong><span className={"openapi-schema__name"}> object</span></span></summary><div style={{"marginLeft":"1rem"}}><div style={{"marginTop":".5rem","marginBottom":".5rem"}}>

The parameters to control generation.

</div><SchemaItem collapsible={false} name={"generation_preset_name"} required={false} schemaName={"string"} qualifierMessage={"**Possible values:** `non-empty`"} schema={{"description":"The preset values to use to feed the query results and other context to the model.\n\nA `generation_preset` is an object with a bundle of properties that specifies:\n  * The `prompt_template` that is rendered and then sent to the LLM.\n  * The LLM used.\n  * `model_parameter`s such as temperature.\n \nAll of these properties except the model can be overriden by setting them in this\nobject. Even when a `prompt_template` is set, the `generation_preset_name` is used to set \nthe model used.\n\nIf `generation_preset_name` is not set, the Vectara platform will use the default model and\nprompt.\n","type":"string","minLength":1,"example":"vectara-summary-ext-v1.2.0"}}></SchemaItem><SchemaItem collapsible={false} name={"prompt_name"} required={false} schemaName={"string"} qualifierMessage={"**Possible values:** `non-empty`"} schema={{"description":"Use `generation_preset_name` instead of `prompt_name`.\n","type":"string","minLength":1,"example":"vectara-summary-ext-v1.2.0","deprecated":true}}></SchemaItem><SchemaItem collapsible={false} name={"max_used_search_results"} required={false} schemaName={"int32"} qualifierMessage={undefined} schema={{"description":"The maximum number of search results to be available to the prompt.","type":"integer","format":"int32","minimum":0,"default":5}}></SchemaItem><SchemaItem collapsible={false} name={"prompt_template"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"Vectara manages both system and user roles and prompts for the generative\nLLM out of the box by default. However, Scale customers can override the\n`prompt_template` via this variable. The `prompt_template` is in the form of an\nApache Velocity template. For more details on how to configure the\n`prompt_template`, see the [long-form documentation](https://docs.vectara.com/docs/prompts/vectara-prompt-engine).\nSee [pricing](https://vectara.com/pricing/) for more details on becoming a Scale customer.\n","type":"string","example":"[\n  {\"role\": \"system\", \"content\": \"You are a helpful search assistant.\"},\n  #foreach ($qResult in $vectaraQueryResults)\n     {\"role\": \"user\", \"content\": \"Given the $vectaraIdxWord[$foreach.index] search result.\"},\n     {\"role\": \"assistant\", \"content\": \"${qResult.getText()}\" },\n  #end\n  {\"role\": \"user\", \"content\": \"Generate a summary for the query '${vectaraQuery}' based on the above results.\"}\n]\n"}}></SchemaItem><SchemaItem collapsible={false} name={"prompt_text"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"This property is deprecated in favor clearer naming. Use `prompt_template`. This property will be\nignored if `prompt_template` is set.\n","type":"string","example":"[\n  {\"role\": \"system\", \"content\": \"You are a helpful search assistant.\"},\n  #foreach ($qResult in $vectaraQueryResults)\n     {\"role\": \"user\", \"content\": \"Given the $vectaraIdxWord[$foreach.index] search result.\"},\n     {\"role\": \"assistant\", \"content\": \"${qResult.getText()}\" },\n  #end\n  {\"role\": \"user\", \"content\": \"Generate a summary for the query '${vectaraQuery}' based on the above results.\"}\n]\n","deprecated":true}}></SchemaItem><SchemaItem collapsible={false} name={"max_response_characters"} required={false} schemaName={"int32"} qualifierMessage={undefined} schema={{"description":"Controls the length of the generated output.\nThis is a rough estimate and not a hard limit: the end output can be longer or shorter\nthan this value. This is generally implemented by including the `max_response_characters` in the\nprompt, and the LLM's instruction following capability dictates how closely the generated output\nis limited.\n\nThis is currently a Scale-only feature.\nSee [pricing](https://vectara.com/pricing/) for more details on becoming a Scale customer.\n","type":"integer","format":"int32","example":300,"minimum":0}}></SchemaItem><SchemaItem collapsible={false} name={"response_language"} required={false} schemaName={"Language (string)"} qualifierMessage={"**Possible values:** [`auto`, `eng`, `deu`, `fra`, `zho`, `kor`, `ara`, `rus`, `tha`, `nld`, `ita`, `por`, `spa`, `jpn`, `pol`, `tur`, `vie`, `ind`, `ces`, `ukr`, `ell`, `heb`, `fas`, `hin`, `urd`, `swe`, `ben`, `msa`, `ron`]"} schema={{"description":"Languages that the Vectara platform supports.","type":"string","enum":["auto","eng","deu","fra","zho","kor","ara","rus","tha","nld","ita","por","spa","jpn","pol","tur","vie","ind","ces","ukr","ell","heb","fas","hin","urd","swe","ben","msa","ron"],"default":"auto","title":"Language"}}></SchemaItem><SchemaItem collapsible={true} className={"schemaItem"}><details style={{}} className={"openapi-markdown__details"}><summary style={{}}><span className={"openapi-schema__container"}><strong className={"openapi-schema__property"}>model_parameters</strong><span className={"openapi-schema__name"}> object</span></span></summary><div style={{"marginLeft":"1rem"}}><div style={{"marginTop":".5rem","marginBottom":".5rem"}}>

The parameters for the model.  These are currently a Scale-only feature.
See [pricing](https://vectara.com/pricing/) for more details on becoming a Scale customer.
WARNING: This is an experimental feature, and breakable at any point with virtually no
notice. It is meant for experimentation to converge on optimal parameters that can then
be set in the prompt definitions.


</div><SchemaItem collapsible={false} name={"max_tokens"} required={false} schemaName={"int32"} qualifierMessage={"**Possible values:** `>= 1`"} schema={{"description":"The maximum number of tokens to be returned by the model.","type":"integer","format":"int32","minimum":1}}></SchemaItem><SchemaItem collapsible={false} name={"temperature"} required={false} schemaName={"float"} qualifierMessage={undefined} schema={{"description":"The sampling temperature to use. Higher values make the output more random, while lower\nvalues make it more focused and deterministic.\n","type":"number","format":"float"}}></SchemaItem><SchemaItem collapsible={false} name={"frequency_penalty"} required={false} schemaName={"float"} qualifierMessage={undefined} schema={{"description":"Higher values penalize new tokens based on their existing frequency in the text so far,\ndecreasing the model's likelihood to repeat the same line verbatim.\n","type":"number","format":"float"}}></SchemaItem><SchemaItem collapsible={false} name={"presence_penalty"} required={false} schemaName={"float"} qualifierMessage={undefined} schema={{"description":"Higher values penalize new tokens based on whether they appear in the text so far,\nincreasing the model's likelihood to talk about new topics.\n","type":"number","format":"float"}}></SchemaItem></div></details></SchemaItem><SchemaItem collapsible={true} className={"schemaItem"}><details style={{}} className={"openapi-markdown__details"}><summary style={{}}><span className={"openapi-schema__container"}><strong className={"openapi-schema__property"}>citations</strong><span className={"openapi-schema__name"}> object</span></span></summary><div style={{"marginLeft":"1rem"}}><div style={{"marginTop":".5rem","marginBottom":".5rem"}}>

Style the generator should use when making citations.

</div><SchemaItem collapsible={false} name={"style"} required={false} schemaName={"string"} qualifierMessage={"**Possible values:** [`none`, `numeric`, `html`, `markdown`]"} schema={{"description":"The citation style to be used in summary.\nCan be one of:\n* `numeric` - Citations formatted as simple numerals: \\[1\\], \\[2\\] ...\n* `none` - Citations removed from text.\n* `html` - Citation formatted as a URL like `<a href=\"url_pattern\">text_pattern</a>`.\n* `markdown` - Formatted as `[text_pattern](url_pattern)`.\n","type":"string","enum":["none","numeric","html","markdown"]}}></SchemaItem><SchemaItem collapsible={false} name={"url_pattern"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"The URL pattern if the citation_style is set to `html` or `markdown`.\nThe pattern can access metadata attributes in the document or part.\ne.g. `https://my.doc/foo/{doc.id}/{part.id}`\n\nThe default `url_pattern` is an empty string.\n","type":"string","example":"https://vectara.com/documents/{doc.id}"}}></SchemaItem><SchemaItem collapsible={false} name={"text_pattern"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"The text pattern if the citation_style is set to `html` or `markdown`.\nThis pattern sets the href for HTML or the text within `[]` in markdown,\nand defaults to N being the index of result if it is not set.\n\nThe default citation style looks like `[N](<url_pattern>)` for markdown.\n\nYou can use metadata attributes in the `text_pattern`. For example,\nthe pattern `{doc.title}` with citation style `markdown` would result\nin final citation output like `[Title](<url_pattern>)` when\nthe document's metadata includes `{\"title\":\"Title\"}`.\n","type":"string","example":"{doc.title}"}}></SchemaItem></div></details></SchemaItem><SchemaItem collapsible={false} name={"enable_factual_consistency_score"} required={false} schemaName={"boolean"} qualifierMessage={undefined} schema={{"description":"Enable returning the factual consistency score with query results.","type":"boolean","default":true}}></SchemaItem></div></details></SchemaItem><SchemaItem collapsible={true} className={"schemaItem"}><details style={{}} className={"openapi-markdown__details"}><summary style={{}}><span className={"openapi-schema__container"}><strong className={"openapi-schema__property"}>chat</strong><span className={"openapi-schema__name"}> object</span></span></summary><div style={{"marginLeft":"1rem"}}><div style={{"marginTop":".5rem","marginBottom":".5rem"}}>

Parameters to control chat behavior.

</div><SchemaItem collapsible={false} name={"store"} required={false} schemaName={"boolean"} qualifierMessage={undefined} schema={{"description":"Indicates whether to store chat message and response message.","type":"boolean","default":true}}></SchemaItem></div></details></SchemaItem><SchemaItem collapsible={false} name={"stream_response"} required={false} schemaName={"boolean"} qualifierMessage={undefined} schema={{"description":"Indicates whether the response should be streamed or not.","type":"boolean","default":false}}></SchemaItem></ul></details></TabItem></MimeTabs><div><div><ApiTabs label={undefined} id={undefined}><TabItem label={"200"} value={"200"}><div>

A response to a chat request.

</div><div><MimeTabs className={"openapi-tabs__mime"} schemaType={"response"}><TabItem label={"application/json"} value={"application/json"}><SchemaTabs className={"openapi-tabs__schema"}><TabItem label={"Schema"} value={"Schema"}><details style={{}} className={"openapi-markdown__details response"} data-collapsed={false} open={true}><summary style={{}} className={"openapi-markdown__details-summary-response"}><strong>Schema</strong></summary><div style={{"textAlign":"left","marginLeft":"1rem"}}></div><ul style={{"marginLeft":"1rem"}}><SchemaItem collapsible={false} name={"chat_id"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"If the chat response was stored, the ID of the chat.","type":"string"}}></SchemaItem><SchemaItem collapsible={false} name={"turn_id"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"If the chat response was stored, the ID of the turn.","type":"string"}}></SchemaItem><SchemaItem collapsible={false} name={"answer"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"The message from the chat model for the chat message.","type":"string"}}></SchemaItem><SchemaItem collapsible={false} name={"response_language"} required={false} schemaName={"Language (string)"} qualifierMessage={"**Possible values:** [`auto`, `eng`, `deu`, `fra`, `zho`, `kor`, `ara`, `rus`, `tha`, `nld`, `ita`, `por`, `spa`, `jpn`, `pol`, `tur`, `vie`, `ind`, `ces`, `ukr`, `ell`, `heb`, `fas`, `hin`, `urd`, `swe`, `ben`, `msa`, `ron`]"} schema={{"description":"Languages that the Vectara platform supports.","type":"string","enum":["auto","eng","deu","fra","zho","kor","ara","rus","tha","nld","ita","por","spa","jpn","pol","tur","vie","ind","ces","ukr","ell","heb","fas","hin","urd","swe","ben","msa","ron"],"default":"auto","title":"Language"}}></SchemaItem><SchemaItem collapsible={true} className={"schemaItem"}><details style={{}} className={"openapi-markdown__details"}><summary style={{}}><span className={"openapi-schema__container"}><strong className={"openapi-schema__property"}>search_results</strong><span className={"openapi-schema__name"}> object[]</span></span></summary><div style={{"marginLeft":"1rem"}}><div style={{"marginTop":".5rem","marginBottom":".5rem"}}>

The ranked search results that the chat model used.

</div><li><div style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}>Array [</div></li><SchemaItem collapsible={false} name={"text"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"The document part altered by the context configuration that matches the query.","type":"string"}}></SchemaItem><SchemaItem collapsible={false} name={"score"} required={false} schemaName={"double"} qualifierMessage={undefined} schema={{"description":"The score of the individual result.","type":"number","format":"double"}}></SchemaItem><SchemaItem collapsible={true} className={"schemaItem"}><details style={{}} className={"openapi-markdown__details"}><summary style={{}}><span className={"openapi-schema__container"}><strong className={"openapi-schema__property"}>part_metadata</strong><span className={"openapi-schema__name"}> object</span></span></summary><div style={{"marginLeft":"1rem"}}><div style={{"marginTop":".5rem","marginBottom":".5rem"}}>

The metadata for the document part.

</div><SchemaItem name={"property name*"} required={false} schemaName={"any"} qualifierMessage={undefined} schema={{"description":"The metadata for the document part.","type":"object","additionalProperties":true}} collapsible={false} discriminator={false}></SchemaItem></div></details></SchemaItem><SchemaItem collapsible={true} className={"schemaItem"}><details style={{}} className={"openapi-markdown__details"}><summary style={{}}><span className={"openapi-schema__container"}><strong className={"openapi-schema__property"}>document_metadata</strong><span className={"openapi-schema__name"}> object</span></span></summary><div style={{"marginLeft":"1rem"}}><div style={{"marginTop":".5rem","marginBottom":".5rem"}}>

The metadata for the document that contains the document part.

</div><SchemaItem name={"property name*"} required={false} schemaName={"any"} qualifierMessage={undefined} schema={{"description":"The metadata for the document that contains the document part.","type":"object","additionalProperties":true}} collapsible={false} discriminator={false}></SchemaItem></div></details></SchemaItem><SchemaItem collapsible={false} name={"document_id"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"The ID of the document that contains the document part.","type":"string"}}></SchemaItem><SchemaItem collapsible={false} name={"request_corpora_index"} required={false} schemaName={"int32"} qualifierMessage={undefined} schema={{"description":"A query request can search over multiple corpora at a time. This property \nis set to the index in the list of corpora in the original search request that this\nsearch result originated from.\n\nIf the query request is only over one corpus, this property is 0.\n","type":"integer","format":"int32","example":0,"minimum":0}}></SchemaItem><li><div style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}>]</div></li></div></details></SchemaItem><SchemaItem collapsible={false} name={"factual_consistency_score"} required={false} schemaName={"float"} qualifierMessage={undefined} schema={{"description":"The probability that the summary is factually consistent with the results.\n","type":"number","format":"float"}}></SchemaItem><SchemaItem collapsible={false} name={"rendered_prompt"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"The rendered prompt sent to the LLM. Useful when creating customer `prompt_text` templates. Only available\nto Scale customers.\n","type":"string"}}></SchemaItem><SchemaItem collapsible={false} name={"rephrased_query"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"If you are on the Scale plan, you can view the actual query made to backend that was rephrased \nby the LLM from the input query.\n","type":"string"}}></SchemaItem></ul></details></TabItem><TabItem label={"Example (from schema)"} value={"Example (from schema)"}><ResponseSamples responseExample={"{\n  \"chat_id\": \"string\",\n  \"turn_id\": \"string\",\n  \"answer\": \"string\",\n  \"response_language\": \"auto\",\n  \"search_results\": [\n    {\n      \"text\": \"string\",\n      \"score\": 0,\n      \"part_metadata\": {},\n      \"document_metadata\": {},\n      \"document_id\": \"string\",\n      \"request_corpora_index\": 0\n    }\n  ],\n  \"factual_consistency_score\": 0,\n  \"rendered_prompt\": \"string\",\n  \"rephrased_query\": \"string\"\n}"} language={"json"}></ResponseSamples></TabItem></SchemaTabs></TabItem><TabItem label={"text/event-stream"} value={"text/event-stream"}><SchemaTabs className={"openapi-tabs__schema"}><TabItem label={"Schema"} value={"Schema"}><details style={{}} className={"openapi-markdown__details response"} data-collapsed={false} open={true}><summary style={{}} className={"openapi-markdown__details-summary-response"}><strong>Schema</strong></summary><div style={{"textAlign":"left","marginLeft":"1rem"}}></div><ul style={{"marginLeft":"1rem"}}><div><span className={"badge badge--info"}>oneOf</span><SchemaTabs><TabItem label={"StreamSearchResponse"} value={"0-item-properties"}><SchemaItem collapsible={false} name={"type"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"When the streaming event has the search results, the\ntype will be `search_results`.\n","type":"string","default":"search_results"}}></SchemaItem><SchemaItem collapsible={true} className={"schemaItem"}><details style={{}} className={"openapi-markdown__details"}><summary style={{}}><span className={"openapi-schema__container"}><strong className={"openapi-schema__property"}>search_results</strong><span className={"openapi-schema__name"}> object[]</span></span></summary><div style={{"marginLeft":"1rem"}}><div style={{"marginTop":".5rem","marginBottom":".5rem"}}>

The ranked search results.

</div><li><div style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}>Array [</div></li><SchemaItem collapsible={false} name={"text"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"The document part altered by the context configuration that matches the query.","type":"string"}}></SchemaItem><SchemaItem collapsible={false} name={"score"} required={false} schemaName={"double"} qualifierMessage={undefined} schema={{"description":"The score of the individual result.","type":"number","format":"double"}}></SchemaItem><SchemaItem collapsible={true} className={"schemaItem"}><details style={{}} className={"openapi-markdown__details"}><summary style={{}}><span className={"openapi-schema__container"}><strong className={"openapi-schema__property"}>part_metadata</strong><span className={"openapi-schema__name"}> object</span></span></summary><div style={{"marginLeft":"1rem"}}><div style={{"marginTop":".5rem","marginBottom":".5rem"}}>

The metadata for the document part.

</div><SchemaItem name={"property name*"} required={false} schemaName={"any"} qualifierMessage={undefined} schema={{"description":"The metadata for the document part.","type":"object","additionalProperties":true}} collapsible={false} discriminator={false}></SchemaItem></div></details></SchemaItem><SchemaItem collapsible={true} className={"schemaItem"}><details style={{}} className={"openapi-markdown__details"}><summary style={{}}><span className={"openapi-schema__container"}><strong className={"openapi-schema__property"}>document_metadata</strong><span className={"openapi-schema__name"}> object</span></span></summary><div style={{"marginLeft":"1rem"}}><div style={{"marginTop":".5rem","marginBottom":".5rem"}}>

The metadata for the document that contains the document part.

</div><SchemaItem name={"property name*"} required={false} schemaName={"any"} qualifierMessage={undefined} schema={{"description":"The metadata for the document that contains the document part.","type":"object","additionalProperties":true}} collapsible={false} discriminator={false}></SchemaItem></div></details></SchemaItem><SchemaItem collapsible={false} name={"document_id"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"The ID of the document that contains the document part.","type":"string"}}></SchemaItem><SchemaItem collapsible={false} name={"request_corpora_index"} required={false} schemaName={"int32"} qualifierMessage={undefined} schema={{"description":"A query request can search over multiple corpora at a time. This property \nis set to the index in the list of corpora in the original search request that this\nsearch result originated from.\n\nIf the query request is only over one corpus, this property is 0.\n","type":"integer","format":"int32","example":0,"minimum":0}}></SchemaItem><li><div style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}>]</div></li></div></details></SchemaItem></TabItem><TabItem label={"ChatInfoResponse"} value={"1-item-properties"}><SchemaItem collapsible={false} name={"type"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"This will be `chat_info` when the stream event contains information\nabout how the chat is stored.\n","type":"string","default":"chat_info"}}></SchemaItem><SchemaItem collapsible={false} name={"chat_id"} required={false} schemaName={"string"} qualifierMessage={"**Possible values:** Value must match regular expression `cht_.+$`"} schema={{"description":"ID of the chat.","type":"string","pattern":"cht_.+$"}}></SchemaItem><SchemaItem collapsible={false} name={"turn_id"} required={false} schemaName={"string"} qualifierMessage={"**Possible values:** Value must match regular expression `trn_.+$`"} schema={{"description":"ID of the turn.","type":"string","pattern":"trn_.+$"}}></SchemaItem></TabItem><TabItem label={"StreamGenerationChunk"} value={"2-item-properties"}><SchemaItem collapsible={false} name={"type"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"When the streaming event contains the next chunk of generator output, the\ntype will be `generation_chunk`.\n","type":"string","default":"generation_chunk"}}></SchemaItem><SchemaItem collapsible={false} name={"generation_chunk"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"Part of the message from the generator. All summary chunks must be appended together in order\nto get the full summary.\n","type":"string"}}></SchemaItem></TabItem><TabItem label={"StreamGenerationEnd"} value={"3-item-properties"}><SchemaItem collapsible={false} name={"type"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"Then end of generation will be denoted with an object\nwith the type `generation_end`.\n","type":"string","default":"generation_end"}}></SchemaItem></TabItem><TabItem label={"FactualConsistencyScore"} value={"4-item-properties"}><SchemaItem collapsible={false} name={"type"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"When the streaming event contains the factual consistency score, the\ntype will be `factual_consistency_score`.\n","type":"string","default":"factual_consistency_score"}}></SchemaItem><SchemaItem collapsible={false} name={"factual_consistency_score"} required={false} schemaName={"float"} qualifierMessage={undefined} schema={{"description":"The probability that the summary is factually consistent with the results.","type":"number","format":"float"}}></SchemaItem></TabItem><TabItem label={"StreamResponseEnd"} value={"5-item-properties"}><SchemaItem collapsible={false} name={"type"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"Then end of stream will be denoted with an object\nwith the type `end`.\n","type":"string","default":"end"}}></SchemaItem></TabItem><TabItem label={"GenerationInfo"} value={"6-item-properties"}><SchemaItem collapsible={false} name={"type"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"When the streaming event contains the generation information\ntype will be `generation_info`.\n","type":"string","default":"generation_info"}}></SchemaItem><SchemaItem collapsible={false} name={"rendered_prompt"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"The rendered prompt sent to the LLM. Useful when creating customer `prompt_text` templates. Only available\nto Scale customers.\n","type":"string"}}></SchemaItem><SchemaItem collapsible={false} name={"rephrased_query"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"If you are on the Scale plan, you can view the actual query made to backend that was rephrased \nby the LLM from the input query.\n","type":"string"}}></SchemaItem></TabItem><TabItem label={"StreamError"} value={"7-item-properties"}><SchemaItem collapsible={false} name={"type"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"If the stream errors, an event with type `error` will\nbe sent.\n","type":"string","default":"error"}}></SchemaItem><SchemaItem collapsible={false} name={"messages"} required={false} schemaName={"string[]"} qualifierMessage={undefined} schema={{"description":"The error messages.","type":"array","items":{"type":"string"}}}></SchemaItem></TabItem></SchemaTabs></div></ul></details></TabItem><TabItem label={"Example (from schema)"} value={"Example (from schema)"}><ResponseSamples responseExample={"{}"} language={"json"}></ResponseSamples></TabItem></SchemaTabs></TabItem></MimeTabs></div></TabItem><TabItem label={"400"} value={"400"}><div>

Chat creation request was malformed.

</div><div><MimeTabs className={"openapi-tabs__mime"} schemaType={"response"}><TabItem label={"application/json"} value={"application/json"}><SchemaTabs className={"openapi-tabs__schema"}><TabItem label={"Schema"} value={"Schema"}><details style={{}} className={"openapi-markdown__details response"} data-collapsed={false} open={true}><summary style={{}} className={"openapi-markdown__details-summary-response"}><strong>Schema</strong></summary><div style={{"textAlign":"left","marginLeft":"1rem"}}></div><ul style={{"marginLeft":"1rem"}}><SchemaItem collapsible={true} className={"schemaItem"}><details style={{}} className={"openapi-markdown__details"}><summary style={{}}><span className={"openapi-schema__container"}><strong className={"openapi-schema__property"}>field_errors</strong><span className={"openapi-schema__name"}> object</span></span></summary><div style={{"marginLeft":"1rem"}}><div style={{"marginTop":".5rem","marginBottom":".5rem"}}>

The errors that relate to specific fields in the request.

</div><SchemaItem name={"property name*"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"type":"string"}} collapsible={false} discriminator={false}></SchemaItem></div></details></SchemaItem><SchemaItem collapsible={false} name={"messages"} required={false} schemaName={"message (string)[]"} qualifierMessage={undefined} schema={{"type":"array","items":{"title":"message","type":"string"}}}></SchemaItem><SchemaItem collapsible={false} name={"request_id"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"The ID of the request that can be used to help Vectara support debug what went wrong.","type":"string"}}></SchemaItem></ul></details></TabItem><TabItem label={"Example (from schema)"} value={"Example (from schema)"}><ResponseSamples responseExample={"{\n  \"field_errors\": {},\n  \"messages\": [\n    \"string\"\n  ],\n  \"request_id\": \"string\"\n}"} language={"json"}></ResponseSamples></TabItem></SchemaTabs></TabItem></MimeTabs></div></TabItem><TabItem label={"403"} value={"403"}><div>

Permissions do not allow creating a chat in the corpus.

</div><div><MimeTabs className={"openapi-tabs__mime"} schemaType={"response"}><TabItem label={"application/json"} value={"application/json"}><SchemaTabs className={"openapi-tabs__schema"}><TabItem label={"Schema"} value={"Schema"}><details style={{}} className={"openapi-markdown__details response"} data-collapsed={false} open={true}><summary style={{}} className={"openapi-markdown__details-summary-response"}><strong>Schema</strong></summary><div style={{"textAlign":"left","marginLeft":"1rem"}}></div><ul style={{"marginLeft":"1rem"}}><SchemaItem collapsible={false} name={"messages"} required={false} schemaName={"message (string)[]"} qualifierMessage={undefined} schema={{"description":"The messages describing why the error occurred.","type":"array","items":{"title":"message","type":"string","example":"Internal server error."}}}></SchemaItem><SchemaItem collapsible={false} name={"request_id"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"The ID of the request that can be used to help Vectara support debug what went wrong.","type":"string"}}></SchemaItem></ul></details></TabItem><TabItem label={"Example (from schema)"} value={"Example (from schema)"}><ResponseSamples responseExample={"{\n  \"messages\": [\n    \"Internal server error.\"\n  ],\n  \"request_id\": \"string\"\n}"} language={"json"}></ResponseSamples></TabItem></SchemaTabs></TabItem></MimeTabs></div></TabItem><TabItem label={"404"} value={"404"}><div>

Corpus not found.

</div><div><MimeTabs className={"openapi-tabs__mime"} schemaType={"response"}><TabItem label={"application/json"} value={"application/json"}><SchemaTabs className={"openapi-tabs__schema"}><TabItem label={"Schema"} value={"Schema"}><details style={{}} className={"openapi-markdown__details response"} data-collapsed={false} open={true}><summary style={{}} className={"openapi-markdown__details-summary-response"}><strong>Schema</strong></summary><div style={{"textAlign":"left","marginLeft":"1rem"}}></div><ul style={{"marginLeft":"1rem"}}><SchemaItem collapsible={false} name={"id"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"The ID cannot be found.","type":"string"}}></SchemaItem><SchemaItem collapsible={false} name={"messages"} required={false} schemaName={"message (string)[]"} qualifierMessage={undefined} schema={{"type":"array","items":{"title":"message","type":"string"}}}></SchemaItem><SchemaItem collapsible={false} name={"request_id"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"ID of the request that can be used to help Vectara support debug what went wrong.","type":"string"}}></SchemaItem></ul></details></TabItem><TabItem label={"Example (from schema)"} value={"Example (from schema)"}><ResponseSamples responseExample={"{\n  \"id\": \"string\",\n  \"messages\": [\n    \"string\"\n  ],\n  \"request_id\": \"string\"\n}"} language={"json"}></ResponseSamples></TabItem></SchemaTabs></TabItem></MimeTabs></div></TabItem></ApiTabs></div></div>
      