---
id: list-generation-presets
title: "List generation presets used for query or chat requests. Generation presets are
the build of properties used to configure generation for a request. This includes
the template that renders the prompt, and various generation settings like
`temperature`.
"
description: "List generation presets"
sidebar_label: "List generation presets used for query or chat requests. Generation presets are
the build of properties used to configure generation for a request. This includes
the template that renders the prompt, and various generation settings like
`temperature`.
"
hide_title: true
hide_table_of_contents: true
api: eJzNWFtz47YV/isYvjS7o4vr9MlPdbLbraebrrPrNNOxdmSIhETEJMAAoGTVs/+93zkARepir5PmoU8SSeDcz3c+4DELcuWzi9vsnTLKyaCtEddOeRV89nmUFcrnTjf0OrvI3msfxKpf2KSFo8w26d1VgXUV1vXyrnerGulkrYJypPExM3ig1VU957+jTJOWX1vlttmh7r/pChs7lWKxFaFU4v37HwTtnWC9U7+22ikYsJSVV6PM56WqZXbxmIVtQ5p8cNqssi9fRr1yXevwvOYb6Knlg67bWpi2XsAKuxSwo61gSLD4G1pnhDZsEjn/MnO0CWqlHNYuratliK++PceLWhvSl138Gf+jbvw/OyPblhKK6WnoRyNXan6vts+78pNXBVlMdsJqp9Va8YNRD0GQDHLtOMNCLin40T0ETJQSKVDKQIqEW8VkZm5K7cUuwwIPxgYIVgV0wkHevdTO94pSDLH5t6XvM632jTVeefp+fnZGPyeKFUqOC5uyk1sE3wTaJpum0jmvmP7iae/jsW67+EXlVCiNo1oPOmruQzXvmuFJQ47DSoYk+dI5yckLqj4h47vWFBXHLOVfrGXVKi9ayuimRCZyWVUIz0DNRFxWVbdQPeSqCTNT20JV3DPYYZBEYdfKOV1AhNzr7qDRV5ya52MQK/DQ4n+SBthLWT/ynGoQmqPxOpQC6VjqVesOHOh1d7k/qOhDrW/6pyeVn5S6A6FnHYnBCyUChUev+v5wA29OKkDM6ibMkd6mkuGEnusUmbQgimN0MUXqvShDeBQufflKoIAbcxIy90q6vJynbntS8zHGxY1DqEPS5FrqSi5QjQlIolUDE16Ea8nAYO+V+S02xQ3Jloi8iFMaBycj8lJzKPK0u3UnskNDwEukhip0sJIMQZAn4u96VcLC1G21vI/AatvQtPDDYqmTprD1CO2qEb3KbpSbmeEGnRYubc7Zx3r0O9CU7PRB53vtGGMydGtZWfzClSWBqTL5dt4oI6uwPXZo315epv9Dg2DThXghyQbLU007AAiZAO93wruJF2h4eCuW0o1mKNYcQ8FznLqW+ZPH3LhXlS6tTUXdqNhEFFWaKkYJ4NACyatf6iU3n8nVH+IkMDSUsc+2AiMBpX/aP21e4F+Q1b2QC2Q/KWt07l/qF8xEexXH7lyZggYVXBlY26ECBm7aOKj9hbWVkibiZiIOT0vVhHI0xXcSSX43cdLbHrQTATuljtpJh4reHRJB/giOIAsZTk7YE40X0AnSFaLb1mWmYwEEDJKZl9gx0cnRoNpxpKMQ/FwylUFZxxI/okQcFpI/in+J3URmAyIkBbOtnvycgONBQIgP/ND5f/jhiDZ/TC5iJa39y9m3J8CSEMJ7PHhRWOZdIAN2wxbvj9Qh9fiDOFCtvEeYToA4M+f0VcRPCzJnU0a4Bu8AL7R53jq3V7ZHbKgLUZJ2FF80zQOhs+J6RgrQ6RhfDpAStUw40inFc32iucjYqzfdpE8r46xPRKmbyKWqGvEvhAL5Fr5tGusC3Fu05BmWb2g+b5yFp89XwluyjBMbW6K0dHpaKY6xDCUepuvz6QmSCXbMzsWDVOsqLC1DaPzFdCobPVlH6ybaZsSWvUKINSEkVl82+h9qe9mS/NvPdIb4QA/n/DRY/InyH9PaLehLQfKLw2aN64TMc+SJQpWiRDCHemRZeaURn++RcPxoUH0WS2j8074bEDXwYxpVTnkl+Z+jBmlvjN7QqZ2Vkl92R6JSyYIRNx2ZHsb4PiY8IAHaLO2w0rr8fnz76UZcXl+J9bG73Rr0wxoEGkhggMHFONgxfgTxOEJ3Pv3Q0OBeRIdfXtGWos0DEXh6OTOoJE0FnAgFqcS8mJl/25br79brlRFtw8LwjBjb1oTP33TxQjd7oO8uZLmtp7SnbV4xkZiZQCi31phHHuc+hw65Jcc+qlwjlL2kwmJWDcXQCyqrsYtLX0X8Ty3H6AcsICfI690RMI5d9oKaq4sW6byu5Hbl4EAhKuLPW3ipHgAqOHNQ85B4jjzi2FjQNQ/aYWuowEonFg7FBJwVn1QFqSnuvJDixz7qQJizBHOibI0wMvKqLTp0n5nuvCkIgjijCEisET8SC1tsR7v5ghfkmo/+IiQ1Hv1EfDCdMBANcAQUAQEInYl7g2iGjJgfiNt34LTfW9e0CHcMK1QEKkR0eRjn/OnViOMBHS1gfAvxiiBNsOsUPRQ1Wc3dJr4DU8HHG+qLkbgDcwy2Vg4Ydxet5rRLsx36TO71mYrshV25iyZcvbkD4i2JjIJi7aJGyqMUWM2Jvbi4wLhR9PcAEdH/G4s617XEbIzo5nlQt2RRSOPmgoWiCz0bG32amfPJGRNlBJLOVmk+pVMHotIXxkT8yNM3BWZwFqNOIWtlMbYGceQpTa7sOILvyDg4kHroRaSGptuNyMI3AETKc0S2iaB6jqbC0IG8oXMqlrHcyxBqU6aa6fdHSCSI6DBRrHBYCBP0Jtcybbh9/brfAYwmfa9ff61rQcecme6HPELp+PxVYqgzU9rN4EAZK4GBNlJWGjQR8aB7ckYzDYzDf1h+whDSuRqg9tCASq1kNeWlY7sc+7h4iu0P48quGG73R9eRD7pedSLnG+sK1NL9pOGBD8Z/A4rWwzCR3IcxeOL9/yJ9XlErP6eDaJPMmTaBH2nSsAQXXMj8/q8D6TxVGusD+ri/JnnqDrWv2MglaWIQl0i9hpJ7d+JWzilGdbFodVVQb/XMbMdWuquVvZsQHiKdcCpn4rQMkMpHkbt7iBDNoEsIPzhvRGxZS6dt64eiYRnNuYgpM3M3OCzfxXI6uMHZ0dBn7pfTQKeT2BRmaT7RcHYfE1O6zXhAn+BKoDQl0kBLHh/pvAee8eULvY6XpMSJCu3TmStdPj5p49fvoU/ayseO4VU3D0e8yoiAvVz977yMfs6mdAP+Ow36f75SfsbrwX157/hnenCaPI/UuOOMVCJx32VO16iDXUcnJ5Ky4/Lv3t4AB/4LZm4DUw==
sidebar_class_name: "get api-method"
info_path: docs/rest-api/vectara-rest-api-v-2
custom_edit_url: null
---

import ApiTabs from "@theme/ApiTabs";
import DiscriminatorTabs from "@theme/DiscriminatorTabs";
import MethodEndpoint from "@theme/ApiExplorer/MethodEndpoint";
import SecuritySchemes from "@theme/ApiExplorer/SecuritySchemes";
import MimeTabs from "@theme/MimeTabs";
import ParamsItem from "@theme/ParamsItem";
import ResponseSamples from "@theme/ResponseSamples";
import SchemaItem from "@theme/SchemaItem";
import SchemaTabs from "@theme/SchemaTabs";
import TabItem from "@theme/TabItem";

<h1 className={"openapi__heading"}>List generation presets used for query or chat requests. Generation presets are
the build of properties used to configure generation for a request. This includes
the template that renders the prompt, and various generation settings like
`temperature`.
</h1>

<MethodEndpoint method={"get"} path={"/v2/generation_presets"}></MethodEndpoint>



List generation presets

## Request

<details style={{"marginBottom":"1rem"}} className={"openapi-markdown__details"} data-collapsed={false} open={true}><summary style={{}}><h3 className={"openapi-markdown__details-summary-header-params"}>Query Parameters</h3></summary><div><ul><ParamsItem className={"paramsItem"} param={{"name":"llm_name","in":"query","description":"Filter presets by the LLM name.","required":false,"schema":{"type":"string"}}}></ParamsItem><ParamsItem className={"paramsItem"} param={{"name":"limit","in":"query","description":"The maximum number of results to return in the list.","required":false,"schema":{"type":"integer","format":"int32","minimum":1,"maximum":100,"default":10}}}></ParamsItem><ParamsItem className={"paramsItem"} param={{"name":"page_key","in":"query","description":"Used to the retrieve the next page of generation presets after the limit has been reached.\nThis parameter is not needed for the first page of results.\n","required":false,"schema":{"type":"string"}}}></ParamsItem></ul></div></details><div><div><ApiTabs><TabItem label={"200"} value={"200"}><div>

List of Generation Presets.

</div><div><MimeTabs className={"openapi-tabs__mime"} schemaType={"response"}><TabItem label={"application/json"} value={"application/json"}><SchemaTabs className={"openapi-tabs__schema"}><TabItem label={"Schema"} value={"Schema"}><details style={{}} className={"openapi-markdown__details response"} data-collapsed={false} open={true}><summary style={{}} className={"openapi-markdown__details-summary-response"}><strong>Schema</strong></summary><div style={{"textAlign":"left","marginLeft":"1rem"}}></div><ul style={{"marginLeft":"1rem"}}><SchemaItem collapsible={true} className={"schemaItem"}><details style={{}} className={"openapi-markdown__details"}><summary style={{}}><span className={"openapi-schema__container"}><strong className={"openapi-schema__property"}>generation_presets</strong><span className={"openapi-schema__name"}> object[]</span></span></summary><div style={{"marginLeft":"1rem"}}><div style={{"marginTop":".5rem","marginBottom":".5rem"}}>

List of generation presets.

</div><li><div style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem","paddingBottom":".5rem"}}>Array [</div></li><SchemaItem collapsible={false} name={"name"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"Name of the generation preset to be used with configuring generation.","type":"string"}}></SchemaItem><SchemaItem collapsible={false} name={"description"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"Description of the generation preset.","type":"string"}}></SchemaItem><SchemaItem collapsible={false} name={"llm_name"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"Name of the model that these presets are used with.","type":"string"}}></SchemaItem><SchemaItem collapsible={false} name={"prompt_template"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"Preset template used to render the prompt sent to generation.","type":"string"}}></SchemaItem><SchemaItem collapsible={false} name={"max_used_search_results"} required={false} schemaName={"int32"} qualifierMessage={"**Possible values:** `>= 1`"} schema={{"description":"Preset maximum number of search results to be available to the prompt.","type":"integer","format":"int32","minimum":1}}></SchemaItem><SchemaItem collapsible={false} name={"max_tokens"} required={false} schemaName={"int32"} qualifierMessage={"**Possible values:** `>= 1`"} schema={{"description":"Preset maximum number of tokens to be returned by the generation.","type":"integer","format":"int32","minimum":1}}></SchemaItem><SchemaItem collapsible={false} name={"temperature"} required={false} schemaName={"float"} qualifierMessage={undefined} schema={{"description":"The sampling temperature to use. Higher values make the output more random, while lower\nvalues make it more focused and deterministic.\n","type":"number","format":"float"}}></SchemaItem><SchemaItem collapsible={false} name={"frequency_penalty"} required={false} schemaName={"float"} qualifierMessage={undefined} schema={{"description":"Higher values penalize new tokens based on their existing frequency in the text so far,\ndecreasing the model's likelihood to repeat the same line verbatim.\n","type":"number","format":"float"}}></SchemaItem><SchemaItem collapsible={false} name={"presence_penalty"} required={false} schemaName={"float"} qualifierMessage={undefined} schema={{"description":"Higher values penalize new tokens based on whether they appear in the text so far,\nincreasing the model's likelihood to talk about new topics.\n","type":"number","format":"float"}}></SchemaItem><SchemaItem collapsible={false} name={"enabled"} required={false} schemaName={"boolean"} qualifierMessage={undefined} schema={{"description":"Indicates whether the prompt is enabled.","type":"boolean"}}></SchemaItem><SchemaItem collapsible={false} name={"default"} required={false} schemaName={"boolean"} qualifierMessage={undefined} schema={{"description":"Indicates if this prompt is the default prompt used with the LLM.","type":"boolean"}}></SchemaItem><li><div style={{"fontSize":"var(--ifm-code-font-size)","opacity":"0.6","marginLeft":"-.5rem"}}>]</div></li></div></details></SchemaItem><SchemaItem collapsible={true} className={"schemaItem"}><details style={{}} className={"openapi-markdown__details"}><summary style={{}}><span className={"openapi-schema__container"}><strong className={"openapi-schema__property"}>metadata</strong><span className={"openapi-schema__name"}> object</span></span></summary><div style={{"marginLeft":"1rem"}}><div style={{"marginTop":".5rem","marginBottom":".5rem"}}>

The standard metadata in the response of a list operation.

</div><SchemaItem collapsible={false} name={"page_key"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"When requesting the next page of this list, this is needed as a query parameter.","type":"string"}}></SchemaItem></div></details></SchemaItem></ul></details></TabItem><TabItem label={"Example (from schema)"} value={"Example (from schema)"}><ResponseSamples responseExample={"{\n  \"generation_presets\": [\n    {\n      \"name\": \"string\",\n      \"description\": \"string\",\n      \"llm_name\": \"string\",\n      \"prompt_template\": \"string\",\n      \"max_used_search_results\": 0,\n      \"max_tokens\": 0,\n      \"temperature\": 0,\n      \"frequency_penalty\": 0,\n      \"presence_penalty\": 0,\n      \"enabled\": true,\n      \"default\": true\n    }\n  ],\n  \"metadata\": {\n    \"page_key\": \"string\"\n  }\n}"} language={"json"}></ResponseSamples></TabItem></SchemaTabs></TabItem></MimeTabs></div></TabItem><TabItem label={"403"} value={"403"}><div>

Permissions do not allow listing generation presets.

</div><div><MimeTabs className={"openapi-tabs__mime"} schemaType={"response"}><TabItem label={"application/json"} value={"application/json"}><SchemaTabs className={"openapi-tabs__schema"}><TabItem label={"Schema"} value={"Schema"}><details style={{}} className={"openapi-markdown__details response"} data-collapsed={false} open={true}><summary style={{}} className={"openapi-markdown__details-summary-response"}><strong>Schema</strong></summary><div style={{"textAlign":"left","marginLeft":"1rem"}}></div><ul style={{"marginLeft":"1rem"}}><SchemaItem collapsible={false} name={"messages"} required={false} schemaName={"message[]"} qualifierMessage={undefined} schema={{"description":"The messages describing why the error occurred.","type":"array","items":{"title":"message","type":"string","example":"Internal server error."}}}></SchemaItem><SchemaItem collapsible={false} name={"request_id"} required={false} schemaName={"string"} qualifierMessage={undefined} schema={{"description":"The ID of the request that can be used to help Vectara support debug what went wrong .","type":"string"}}></SchemaItem></ul></details></TabItem><TabItem label={"Example (from schema)"} value={"Example (from schema)"}><ResponseSamples responseExample={"{\n  \"messages\": [\n    \"Internal server error.\"\n  ],\n  \"request_id\": \"string\"\n}"} language={"json"}></ResponseSamples></TabItem></SchemaTabs></TabItem></MimeTabs></div></TabItem></ApiTabs></div></div>
      