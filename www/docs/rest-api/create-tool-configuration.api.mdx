---
id: create-tool-configuration
title: "Create tool configuration"
description: "Create a new reusable tool configuration that stores user-defined argument overrides and settings for a specific tool."
sidebar_label: "Create tool configuration"
hide_title: true
hide_table_of_contents: true
api: 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
sidebar_class_name: "post api-method"
info_path: docs/rest-api/vectara-rest-api-v-2
custom_edit_url: null
---

import MethodEndpoint from "@theme/ApiExplorer/MethodEndpoint";
import ParamsDetails from "@theme/ParamsDetails";
import RequestSchema from "@theme/RequestSchema";
import StatusCodes from "@theme/StatusCodes";
import OperationTabs from "@theme/OperationTabs";
import TabItem from "@theme/TabItem";
import Heading from "@theme/Heading";

<Heading
  as={"h1"}
  className={"openapi__heading"}
  children={"Create tool configuration"}
>
</Heading>

<MethodEndpoint
  method={"post"}
  path={"/v2/tools/{tool_id}/configurations"}
  context={"endpoint"}
>
  
</MethodEndpoint>



Create a new reusable tool configuration that stores user-defined argument overrides and settings for a specific tool.

<Heading
  id={"request"}
  as={"h2"}
  className={"openapi-tabs__heading"}
  children={"Request"}
>
</Heading>

<ParamsDetails
  parameters={[{"in":"header","name":"Request-Timeout","description":"The API will make a best effort to complete the request in the specified seconds or time out.","schema":{"type":"integer","minimum":1},"required":false},{"in":"header","name":"Request-Timeout-Millis","description":"The API will make a best effort to complete the request in the specified milliseconds or time out.","schema":{"type":"integer","minimum":1}},{"in":"path","name":"tool_id","description":"The unique identifier of the tool.","required":true,"schema":{"type":"string","pattern":"tol_[0-9a-zA-Z_-]+$","example":"tol_rag_search"}}]}
>
  
</ParamsDetails>

<RequestSchema
  title={"Body"}
  body={{"required":true,"content":{"application/json":{"schema":{"description":"Request to create a new reusable tool configuration that stores user-defined argument overrides and settings for a specific tool. These configurations can later be selected and reused when creating agents.","type":"object","discriminator":{"propertyName":"type","mapping":{"mcp":{"description":"Request to create a reusable configuration for an MCP tool with predefined argument overrides that can be applied to agents.","type":"object","properties":{"name":{"description":"Human-readable name for the tool configuration.","type":"string","example":"Customer Support Search Config"},"description":{"description":"A detailed description of what this tool configuration is for and how it should be used.","type":"string","example":"Configuration for searching customer support documentation with optimized parameters"},"type":{"description":"This should always be `mcp`.","type":"string","default":"mcp","example":"mcp"},"enabled":{"description":"Whether the tool configuration should be enabled upon creation.","type":"boolean","default":true},"argument_override":{"description":"Optional hardcoded arguments for tool calls. When specified, these values will be used instead of allowing the LLM to fill in those parameters.","type":"object","additionalProperties":true,"example":{"custom_param":"value","max_results":10}},"metadata":{"description":"Optional metadata associated with this tool configuration.","type":"object","additionalProperties":true,"example":{"tags":["production","v2"],"owner":"team-search"}}},"required":["name","type"],"x-vectaraParents":["CreateToolConfigurationRequest"],"title":"CreateMcpToolConfigurationRequest"},"corpora_search":{"description":"Request to create a reusable configuration for a corpora search tool with predefined search parameters that can be applied to agents.","type":"object","properties":{"name":{"description":"Human-readable name for the tool configuration.","type":"string","example":"Customer Support Search Config"},"description":{"description":"A detailed description of what this tool configuration is for and how it should be used.","type":"string","example":"Configuration for searching customer support documentation with optimized parameters"},"type":{"description":"This should always be `corpora_search`.","type":"string","default":"corpora_search","example":"corpora_search"},"enabled":{"description":"Whether the tool configuration should be enabled upon creation.","type":"boolean","default":true},"argument_override":{"description":"Optional hardcoded arguments for the corpus search call such as the query. When specified, these values will be used instead of allowing the LLM to fill in those parameters.","type":"object","properties":{"query":{"description":"The search query string, which is the question the user is asking. If not provided, will be filled in by the LLM.","type":"string","maxLength":5000,"example":"Am I allowed to bring pets to work?"}},"additionalProperties":false,"title":"CorporaSearchToolParameters"},"query_configuration":{"description":"User-configurable settings for the search that are not exposed to the LLM.","type":"object","properties":{"search":{"description":"The parameters to search one or more corpora.","allOf":[{"type":"object","properties":{"corpora":{"description":"The corpora that you want to search.","type":"array","items":{"description":"A corpus with its identifying key for use in search operations within a customer account.","allOf":[{"description":"Configuration for search parameters specific to a single corpus within a customer account, including filters and semantics.","type":"object","properties":{"custom_dimensions":{"description":"The custom dimensions as additional weights.","type":"object","additionalProperties":{"type":"number","format":"double","nullable":false},"title":"CustomDimensions"},"metadata_filter":{"description":"The filter string used to narrow the search based on metadata attributes. The query against this corpus will be confined to document parts that match the `metadata_filter`. Only metadata fields set as `filter_attributes` on the corpus can be filtered. Filter syntax is similar to a SQL WHERE clause. See [metadata filters documentation](https://docs.vectara.com/docs/learn/metadata-search-filtering/filter-overview) for more information.","type":"string","maxLength":8000,"example":"doc.title = 'Annual Report'"},"lexical_interpolation":{"description":"How much to weigh lexical scores compared to the embedding score. 0 means lexical search is not used at all, and 1 means only lexical search is used.","type":"number","format":"float","minimum":0,"maximum":1,"example":0.005},"semantics":{"description":"Indicates whether to consider a query against this corpus as a query or a response.","type":"string","enum":["default","query","response"],"default":"default","title":"SearchSemantics"}},"title":"SearchCorpus"},{"type":"object","properties":{"corpus_key":{"description":"A user-provided key for a corpus.","type":"string","example":"my-corpus","pattern":"[a-zA-Z0-9_\\=\\-]+$","maxLength":50,"title":"CorpusKey"},"query":{"description":"Query for a particular corpus that will override the overall query if present.","type":"string","maxLength":5000,"example":"What are some important facts in my-corpus?"}}}],"required":["corpus_key"],"title":"KeyedSearchCorpus"},"minItems":1}}},{"type":"object","description":"Search parameters to retrieve knowledge for the query.","properties":{"offset":{"description":"Specifies how many results into the result to skip. This is useful for pagination.","type":"integer","format":"int32","default":0,"minimum":0},"limit":{"description":"The maximum number of results returned.","type":"integer","format":"int32","minimum":1,"default":10},"context_configuration":{"type":"object","description":"Configuration on the presentation of each document part in the result set. You can only use characters_before/after or sentences_before/after, but not both. If you specify both in the query, sentences_before/after takes precedence","properties":{"characters_before":{"description":"The number of characters that are shown before the matching document part. This is useful to show the context of the document part in the wider document. Ignored if `sentences_before` is set. Vectara will capture the full sentence that contains the captured characters, to not lose the meaning caused by a truncated word or sentence.","type":"integer","format":"int32"},"characters_after":{"description":"The number of characters that are shown after the matching document part. This is useful to show the context of the document part in the wider document. Ignored if `sentences_after` is set. Vectara will capture the full sentence that contains the captured characters, to not lose the meaning caused by a truncated word or sentence.","type":"integer","format":"int32"},"sentences_before":{"description":"The number of sentences that are shown before the matching document part. This is useful to show the context of the document part in the wider document.","type":"integer","format":"int32","default":0,"minimum":0,"example":2},"sentences_after":{"description":"The number of sentences that are shown after the matching document part. This is useful to show the context of the document part in the wider document.","type":"integer","format":"int32","default":0,"minimum":0,"example":2},"start_tag":{"description":"The tag that wraps the document part at the start. This is often used to provide a start HTML/XML tag or some other delimiter you can use in an application to understand where to provide highlighting in your UI and understand where the context before ends and the document part begins.","type":"string","example":"<em>"},"end_tag":{"description":"The tag that wraps the document part at the end. This is often used to provide a start HTML/XML tag or some other delimiter you can use in an application to understand where to provide highlighting in your UI and understand where the document part ends and the context after begins.","type":"string","example":"</em>"}},"example":{"sentences_before":2,"sentences_after":2,"start_tag":"<em>","end_tag":"</em>"},"title":"ContextConfiguration"},"reranker":{"type":"object","description":"Rerank results of the search. Rerankers are very powerful tools to improve the order of search results. By default the search will use the most powerful reranker available to the customer's plan. To disable reranking, set the reranker `type` to `\"none\"`.","discriminator":{"propertyName":"type","mapping":{"customer_reranker":{"description":"Reranker that is specific to the customer.","type":"object","properties":{"type":{"description":"When the type is `customer_reranker`, you can specify the `reranker_name` of a reranker. `reranker_id` is deprecated. The retrieval engine will then rerank results using that reranker.","type":"string","default":"customer_reranker"},"reranker_id":{"description":"The ID of the reranker. The multilingual reranker that may be specified is rnk_272725719. Do not specify the MMR reranker ID here, and instead, use the MMR reranker object type. **Deprecated**: Use `reranker_name` instead.","type":"string","pattern":"rnk_(?!272725718)\\d+","example":"rnk_272725719","deprecated":true},"reranker_name":{"description":"The name of the reranker. Do not specify the MMR reranker name here. Instead, use the MMR reranker object type.","type":"string","example":"Rerank_Multilingual_v1"},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. When a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1},"cutoff":{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process. When a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm. 2. Applies the cutoff, removing any results with scores below the specified threshold. 3. Returns the remaining results, sorted by their new scores.\nNote: This cutoff is applied per reranking stage. In a chain of rerankers, each reranker can have its own cutoff, potentially further reducing the number of results at each stage. If both 'limit' and 'cutoff' are specified, the cutoff is applied first, followed by the limit.","format":"float"},"include_context":{"type":"boolean","default":true,"description":"If true, the reranker will use text with context (see \"context_configuration\") for scoring."}},"x-vectaraParents":["SearchReranker"],"title":"CustomerSpecificReranker"},"userfn":{"description":"A reranker that uses user-defined functions to reorder search results.","type":"object","properties":{"type":{"description":"When the type is `userfn`, you can define custom reranking functions using document-level metadata, part-level metadata, or scores generated from the request-level metadata.","type":"string","default":"userfn"},"user_function":{"description":"The user defined function.","type":"string","example":"get('$.score') * get('$.document_metadata.boost')"},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. \nWhen a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1},"cutoff":{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process. When a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm. 2. Applies the cutoff, removing any results with scores below the specified threshold. 3. Returns the remaining results, sorted by their new scores.\nNote: This cutoff is applied per reranking stage. In a chain of rerankers, each reranker can have its own cutoff, potentially further reducing the number of results at each stage. If both 'limit' and 'cutoff' are specified, the cutoff is applied first, followed by the limit.","format":"float"}},"x-vectaraParents":["SearchReranker"],"title":"UserFunctionReranker"},"mmr":{"description":"A reranker that uses Maximal Marginal Relevance to balance relevance and diversity in search results.","type":"object","properties":{"type":{"description":"When the type is `mmr`, you can specify the `diversity_bias`, and the retrieval engine will use the MMR reranker.","type":"string","default":"mmr"},"diversity_bias":{"description":"The diversity bias. Higher values indicate more diversity.","type":"number","format":"float","example":0.3},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. \nWhen a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1},"cutoff":{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process. When a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm. 2. Applies the cutoff, removing any results with scores below the specified threshold. 3. Returns the remaining results, sorted by their new scores.\nNote: This cutoff is applied per reranking stage. In a chain of rerankers, each reranker can have its own cutoff, potentially further reducing the number of results at each stage. If both 'limit' and 'cutoff' are specified, the cutoff is applied first, followed by the limit.","format":"float"}},"x-vectaraParents":["SearchReranker"],"title":"MMRReranker"},"chain":{"description":"A reranker that applies multiple rerankers in sequence to produce the final search results.","type":"object","properties":{"type":{"description":"When the type is `chain`, you can then chain re-rankers together.","type":"string","default":"chain"},"rerankers":{"type":"array","description":"Specify an array of rerankers to apply to search results consecutively.","items":"circular(SearchReranker)","maxItems":50}},"required":["rerankers"],"x-vectaraParents":["SearchReranker"],"title":"ChainReranker"},"none":{"description":"A placeholder reranker that does not modify the original search results ordering.","type":"object","properties":{"type":{"description":"When the type is `none`, no reranking will be done.","type":"string","default":"none"},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. When a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1}},"x-vectaraParents":["SearchReranker"],"title":"NoneReranker"}}},"oneOf":[{"description":"Reranker that is specific to the customer.","type":"object","properties":{"type":{"description":"When the type is `customer_reranker`, you can specify the `reranker_name` of a reranker. `reranker_id` is deprecated. The retrieval engine will then rerank results using that reranker.","type":"string","default":"customer_reranker"},"reranker_id":{"description":"The ID of the reranker. The multilingual reranker that may be specified is rnk_272725719. Do not specify the MMR reranker ID here, and instead, use the MMR reranker object type. **Deprecated**: Use `reranker_name` instead.","type":"string","pattern":"rnk_(?!272725718)\\d+","example":"rnk_272725719","deprecated":true},"reranker_name":{"description":"The name of the reranker. Do not specify the MMR reranker name here. Instead, use the MMR reranker object type.","type":"string","example":"Rerank_Multilingual_v1"},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. When a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1},"cutoff":{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process. When a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm. 2. Applies the cutoff, removing any results with scores below the specified threshold. 3. Returns the remaining results, sorted by their new scores.\nNote: This cutoff is applied per reranking stage. In a chain of rerankers, each reranker can have its own cutoff, potentially further reducing the number of results at each stage. If both 'limit' and 'cutoff' are specified, the cutoff is applied first, followed by the limit.","format":"float"},"include_context":{"type":"boolean","default":true,"description":"If true, the reranker will use text with context (see \"context_configuration\") for scoring."}},"x-vectaraParents":["SearchReranker"],"title":"CustomerSpecificReranker"},{"description":"A reranker that uses user-defined functions to reorder search results.","type":"object","properties":{"type":{"description":"When the type is `userfn`, you can define custom reranking functions using document-level metadata, part-level metadata, or scores generated from the request-level metadata.","type":"string","default":"userfn"},"user_function":{"description":"The user defined function.","type":"string","example":"get('$.score') * get('$.document_metadata.boost')"},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. \nWhen a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1},"cutoff":{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process. When a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm. 2. Applies the cutoff, removing any results with scores below the specified threshold. 3. Returns the remaining results, sorted by their new scores.\nNote: This cutoff is applied per reranking stage. In a chain of rerankers, each reranker can have its own cutoff, potentially further reducing the number of results at each stage. If both 'limit' and 'cutoff' are specified, the cutoff is applied first, followed by the limit.","format":"float"}},"x-vectaraParents":["SearchReranker"],"title":"UserFunctionReranker"},{"description":"A reranker that uses Maximal Marginal Relevance to balance relevance and diversity in search results.","type":"object","properties":{"type":{"description":"When the type is `mmr`, you can specify the `diversity_bias`, and the retrieval engine will use the MMR reranker.","type":"string","default":"mmr"},"diversity_bias":{"description":"The diversity bias. Higher values indicate more diversity.","type":"number","format":"float","example":0.3},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. \nWhen a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1},"cutoff":{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process. When a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm. 2. Applies the cutoff, removing any results with scores below the specified threshold. 3. Returns the remaining results, sorted by their new scores.\nNote: This cutoff is applied per reranking stage. In a chain of rerankers, each reranker can have its own cutoff, potentially further reducing the number of results at each stage. If both 'limit' and 'cutoff' are specified, the cutoff is applied first, followed by the limit.","format":"float"}},"x-vectaraParents":["SearchReranker"],"title":"MMRReranker"},{"description":"A reranker that applies multiple rerankers in sequence to produce the final search results.","type":"object","properties":{"type":{"description":"When the type is `chain`, you can then chain re-rankers together.","type":"string","default":"chain"},"rerankers":{"type":"array","description":"Specify an array of rerankers to apply to search results consecutively.","items":"circular(SearchReranker)","maxItems":50}},"required":["rerankers"],"x-vectaraParents":["SearchReranker"],"title":"ChainReranker"},{"description":"A placeholder reranker that does not modify the original search results ordering.","type":"object","properties":{"type":{"description":"When the type is `none`, no reranking will be done.","type":"string","default":"none"},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. When a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1}},"x-vectaraParents":["SearchReranker"],"title":"NoneReranker"}],"title":"SearchReranker"}},"example":{"limit":50},"title":"SearchParameters"}],"required":["corpora"],"title":"SearchCorporaParameters"},"generation":{"description":"The parameters to control generation.","type":"object","properties":{"generation_preset_name":{"description":"The preset values to use to feed the query results and other context to the model.  \n\nA `generation_preset` is an object with a bundle of properties that specifies: \n* The `prompt_template` that is rendered and then sent to the LLM. \n* The LLM used. * `model_parameter`s such as temperature.\n\nAll of these properties except the model can be overridden by setting them in this object. Even when a `prompt_template` is set, the `generation_preset_name` is used to set the model used. See `model_parameters.model` if you want to set the model explicitly.\n\nIf `generation_preset_name` is not set, the Vectara platform will use the default model and prompt.'\n","type":"string","minLength":1,"example":"mockingbird-2.0"},"prompt_name":{"description":"Use `generation_preset_name` instead of `prompt_name`.","type":"string","minLength":1,"example":"mockingbird-2.0","deprecated":true},"max_used_search_results":{"description":"The maximum number of search results to be available to the prompt.","type":"integer","format":"int32","minimum":0,"default":5},"prompt_template":{"description":"Vectara manages both system and user roles and prompts for the generative LLM out of the box by default. However, users can override the `prompt_template` via this variable. The `prompt_template` is in the form of an Apache Velocity template. For more details on how to configure the `prompt_template`, see the [long-form documentation](https://docs.vectara.com/docs/prompts/vectara-prompt-engine).","type":"string","example":"[\n  {\"role\": \"system\", \"content\": \"You are a helpful search assistant.\"},\n  #foreach ($qResult in $vectaraQueryResults)\n     {\"role\": \"user\", \"content\": \"Given the $vectaraIdxWord[$foreach.index] search result.\"},\n     {\"role\": \"assistant\", \"content\": \"${qResult.getText()}\" },\n  #end\n  {\"role\": \"user\", \"content\": \"Generate a summary for the query '${vectaraQuery}' based on the above results.\"}\n]\n"},"prompt_text":{"description":"This property is deprecated in favor of clearer naming. Use `prompt_template`. This property will be ignored if `prompt_template` is set.","type":"string","example":"[\n  {\"role\": \"system\", \"content\": \"You are a helpful search assistant.\"},\n  #foreach ($qResult in $vectaraQueryResults)\n     {\"role\": \"user\", \"content\": \"Given the $vectaraIdxWord[$foreach.index] search result.\"},\n     {\"role\": \"assistant\", \"content\": \"${qResult.getText()}\" },\n  #end\n  {\"role\": \"user\", \"content\": \"Generate a summary for the query '${vectaraQuery}' based on the above results.\"}\n]\n","deprecated":true},"max_response_characters":{"description":"Controls the length of the generated output. This is a rough estimate and not a hard limit: the end output can be longer or shorter than this value. This is generally implemented by including the `max_response_characters` in the prompt, and the LLM's instruction following capability dictates how closely the generated output is limited.","type":"integer","format":"int32","example":300,"minimum":0},"response_language":{"description":"Languages that the Vectara platform supports.","type":"string","enum":["auto","eng","deu","fra","zho","kor","ara","rus","tha","nld","ita","por","spa","jpn","pol","tur","vie","ind","ces","ukr","ell","heb","fas","hin","urd","swe","ben","msa","ron"],"default":"auto","title":"Language"},"model_parameters":{"title":"ModelParameters","description":"The parameters for the model. WARNING: This is an experimental feature, and breakable at any point with virtually no notice. It is meant for experimentation to converge on optimal parameters that can then be set in the prompt definitions.","type":"object","properties":{"llm_name":{"description":"The model (e.g., `gpt-4`) to use for summarization. If specified, it will override the model behind `generation_preset_name`.","type":"string","example":"gpt4"},"max_tokens":{"description":"The maximum number of tokens to be returned by the model.","type":"integer","format":"int32","minimum":1},"temperature":{"description":"The sampling temperature to use. Higher values make the output more random, while lower values make it more focused and deterministic.","type":"number","format":"float"},"frequency_penalty":{"description":"Higher values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.","type":"number","format":"float"},"presence_penalty":{"description":"Higher values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.","type":"number","format":"float"}}},"citations":{"description":"Style the generator should use when making citations.","type":"object","properties":{"style":{"description":"The citation style to be used in summary. Can be one of: * `numeric` - Citations formatted as simple numerals: \\[1\\], \\[2\\] ... * `none` - Citations removed from text. * `html` - Citation formatted as a URL like `<a href=\"url_pattern\">text_pattern</a>`. * `markdown` - Formatted as `[text_pattern](url_pattern)`.","type":"string","enum":["none","numeric","html","markdown"]},"url_pattern":{"description":"The URL pattern if the citation_style is set to `html` or `markdown`. The pattern can access metadata attributes in the document or part. e.g. `https://my.doc/foo/{doc.id}/{part.id}` The default `url_pattern` is an empty string.","type":"string","example":"https://vectara.com/documents/{doc.id}"},"text_pattern":{"description":"The text pattern if the citation_style is set to `html` or `markdown`. This pattern sets the href for HTML or the text within `[]` in markdown, and defaults to N being the index of result if it is not set. The default citation style looks like `[N](<url_pattern>)` for markdown. You can use metadata attributes in the `text_pattern`. For example, the pattern `{doc.title}` with citation style `markdown` would result in final citation output like `[Title](<url_pattern>)` when the document's metadata includes `{\"title\":\"Title\"}`.","type":"string","example":"{doc.title}"}},"title":"CitationParameters"},"enable_factual_consistency_score":{"description":"Enable returning the factual consistency score with query results.","type":"boolean","default":true}},"title":"GenerationParameters"},"save_history":{"description":"Indicates whether to save the query to query history.","type":"boolean"}},"required":["search"],"title":"CorporaSearchQueryConfiguration"},"metadata":{"description":"Optional metadata associated with this tool configuration.","type":"object","additionalProperties":true,"example":{"tags":["production","v2"],"owner":"team-search"}}},"required":["name","type","query_configuration"],"x-vectaraParents":["CreateToolConfigurationRequest"],"title":"CreateCorporaSearchToolConfigurationRequest"},"web_search":{"description":"Request to create a reusable configuration for a web search tool with predefined search parameters that can be applied to agents.","type":"object","properties":{"name":{"description":"Human-readable name for the tool configuration.","type":"string","example":"Customer Support Search Config"},"description":{"description":"A detailed description of what this tool configuration is for and how it should be used.","type":"string","example":"Configuration for searching customer support documentation with optimized parameters"},"type":{"description":"This should always be `web_search`.","type":"string","default":"web_search","example":"web_search"},"enabled":{"description":"Whether the tool configuration should be enabled upon creation.","type":"boolean","default":true},"argument_override":{"description":"Optional hardcoded arguments for the web search tool call such as limit etc. When specified, these values will be used instead of allowing the LLM to fill in those parameters.","type":"object","properties":{"query":{"description":"The search query to execute.","type":"string","example":"latest AI developments 2024"},"limit":{"description":"Maximum number of results to return.","type":"integer","minimum":1,"example":10},"provider":{"description":"Search provider to use.","type":"string","enum":["tavily"],"example":"tavily"}},"additionalProperties":false,"title":"WebSearchToolParameters"},"metadata":{"description":"Optional metadata associated with this tool configuration.","type":"object","additionalProperties":true,"example":{"tags":["production","v2"],"owner":"team-search"}}},"required":["name","type"],"x-vectaraParents":["CreateToolConfigurationRequest"],"title":"CreateWebSearchToolConfigurationRequest"}}},"oneOf":[{"description":"Request to create a reusable configuration for an MCP tool with predefined argument overrides that can be applied to agents.","type":"object","properties":{"name":{"description":"Human-readable name for the tool configuration.","type":"string","example":"Customer Support Search Config"},"description":{"description":"A detailed description of what this tool configuration is for and how it should be used.","type":"string","example":"Configuration for searching customer support documentation with optimized parameters"},"type":{"description":"This should always be `mcp`.","type":"string","default":"mcp","example":"mcp"},"enabled":{"description":"Whether the tool configuration should be enabled upon creation.","type":"boolean","default":true},"argument_override":{"description":"Optional hardcoded arguments for tool calls. When specified, these values will be used instead of allowing the LLM to fill in those parameters.","type":"object","additionalProperties":true,"example":{"custom_param":"value","max_results":10}},"metadata":{"description":"Optional metadata associated with this tool configuration.","type":"object","additionalProperties":true,"example":{"tags":["production","v2"],"owner":"team-search"}}},"required":["name","type"],"x-vectaraParents":["CreateToolConfigurationRequest"],"title":"CreateMcpToolConfigurationRequest"},{"description":"Request to create a reusable configuration for a corpora search tool with predefined search parameters that can be applied to agents.","type":"object","properties":{"name":{"description":"Human-readable name for the tool configuration.","type":"string","example":"Customer Support Search Config"},"description":{"description":"A detailed description of what this tool configuration is for and how it should be used.","type":"string","example":"Configuration for searching customer support documentation with optimized parameters"},"type":{"description":"This should always be `corpora_search`.","type":"string","default":"corpora_search","example":"corpora_search"},"enabled":{"description":"Whether the tool configuration should be enabled upon creation.","type":"boolean","default":true},"argument_override":{"description":"Optional hardcoded arguments for the corpus search call such as the query. When specified, these values will be used instead of allowing the LLM to fill in those parameters.","type":"object","properties":{"query":{"description":"The search query string, which is the question the user is asking. If not provided, will be filled in by the LLM.","type":"string","maxLength":5000,"example":"Am I allowed to bring pets to work?"}},"additionalProperties":false,"title":"CorporaSearchToolParameters"},"query_configuration":{"description":"User-configurable settings for the search that are not exposed to the LLM.","type":"object","properties":{"search":{"description":"The parameters to search one or more corpora.","allOf":[{"type":"object","properties":{"corpora":{"description":"The corpora that you want to search.","type":"array","items":{"description":"A corpus with its identifying key for use in search operations within a customer account.","allOf":[{"description":"Configuration for search parameters specific to a single corpus within a customer account, including filters and semantics.","type":"object","properties":{"custom_dimensions":{"description":"The custom dimensions as additional weights.","type":"object","additionalProperties":{"type":"number","format":"double","nullable":false},"title":"CustomDimensions"},"metadata_filter":{"description":"The filter string used to narrow the search based on metadata attributes. The query against this corpus will be confined to document parts that match the `metadata_filter`. Only metadata fields set as `filter_attributes` on the corpus can be filtered. Filter syntax is similar to a SQL WHERE clause. See [metadata filters documentation](https://docs.vectara.com/docs/learn/metadata-search-filtering/filter-overview) for more information.","type":"string","maxLength":8000,"example":"doc.title = 'Annual Report'"},"lexical_interpolation":{"description":"How much to weigh lexical scores compared to the embedding score. 0 means lexical search is not used at all, and 1 means only lexical search is used.","type":"number","format":"float","minimum":0,"maximum":1,"example":0.005},"semantics":{"description":"Indicates whether to consider a query against this corpus as a query or a response.","type":"string","enum":["default","query","response"],"default":"default","title":"SearchSemantics"}},"title":"SearchCorpus"},{"type":"object","properties":{"corpus_key":{"description":"A user-provided key for a corpus.","type":"string","example":"my-corpus","pattern":"[a-zA-Z0-9_\\=\\-]+$","maxLength":50,"title":"CorpusKey"},"query":{"description":"Query for a particular corpus that will override the overall query if present.","type":"string","maxLength":5000,"example":"What are some important facts in my-corpus?"}}}],"required":["corpus_key"],"title":"KeyedSearchCorpus"},"minItems":1}}},{"type":"object","description":"Search parameters to retrieve knowledge for the query.","properties":{"offset":{"description":"Specifies how many results into the result to skip. This is useful for pagination.","type":"integer","format":"int32","default":0,"minimum":0},"limit":{"description":"The maximum number of results returned.","type":"integer","format":"int32","minimum":1,"default":10},"context_configuration":{"type":"object","description":"Configuration on the presentation of each document part in the result set. You can only use characters_before/after or sentences_before/after, but not both. If you specify both in the query, sentences_before/after takes precedence","properties":{"characters_before":{"description":"The number of characters that are shown before the matching document part. This is useful to show the context of the document part in the wider document. Ignored if `sentences_before` is set. Vectara will capture the full sentence that contains the captured characters, to not lose the meaning caused by a truncated word or sentence.","type":"integer","format":"int32"},"characters_after":{"description":"The number of characters that are shown after the matching document part. This is useful to show the context of the document part in the wider document. Ignored if `sentences_after` is set. Vectara will capture the full sentence that contains the captured characters, to not lose the meaning caused by a truncated word or sentence.","type":"integer","format":"int32"},"sentences_before":{"description":"The number of sentences that are shown before the matching document part. This is useful to show the context of the document part in the wider document.","type":"integer","format":"int32","default":0,"minimum":0,"example":2},"sentences_after":{"description":"The number of sentences that are shown after the matching document part. This is useful to show the context of the document part in the wider document.","type":"integer","format":"int32","default":0,"minimum":0,"example":2},"start_tag":{"description":"The tag that wraps the document part at the start. This is often used to provide a start HTML/XML tag or some other delimiter you can use in an application to understand where to provide highlighting in your UI and understand where the context before ends and the document part begins.","type":"string","example":"<em>"},"end_tag":{"description":"The tag that wraps the document part at the end. This is often used to provide a start HTML/XML tag or some other delimiter you can use in an application to understand where to provide highlighting in your UI and understand where the document part ends and the context after begins.","type":"string","example":"</em>"}},"example":{"sentences_before":2,"sentences_after":2,"start_tag":"<em>","end_tag":"</em>"},"title":"ContextConfiguration"},"reranker":{"type":"object","description":"Rerank results of the search. Rerankers are very powerful tools to improve the order of search results. By default the search will use the most powerful reranker available to the customer's plan. To disable reranking, set the reranker `type` to `\"none\"`.","discriminator":{"propertyName":"type","mapping":{"customer_reranker":{"description":"Reranker that is specific to the customer.","type":"object","properties":{"type":{"description":"When the type is `customer_reranker`, you can specify the `reranker_name` of a reranker. `reranker_id` is deprecated. The retrieval engine will then rerank results using that reranker.","type":"string","default":"customer_reranker"},"reranker_id":{"description":"The ID of the reranker. The multilingual reranker that may be specified is rnk_272725719. Do not specify the MMR reranker ID here, and instead, use the MMR reranker object type. **Deprecated**: Use `reranker_name` instead.","type":"string","pattern":"rnk_(?!272725718)\\d+","example":"rnk_272725719","deprecated":true},"reranker_name":{"description":"The name of the reranker. Do not specify the MMR reranker name here. Instead, use the MMR reranker object type.","type":"string","example":"Rerank_Multilingual_v1"},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. When a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1},"cutoff":{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process. When a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm. 2. Applies the cutoff, removing any results with scores below the specified threshold. 3. Returns the remaining results, sorted by their new scores.\nNote: This cutoff is applied per reranking stage. In a chain of rerankers, each reranker can have its own cutoff, potentially further reducing the number of results at each stage. If both 'limit' and 'cutoff' are specified, the cutoff is applied first, followed by the limit.","format":"float"},"include_context":{"type":"boolean","default":true,"description":"If true, the reranker will use text with context (see \"context_configuration\") for scoring."}},"x-vectaraParents":["SearchReranker"],"title":"CustomerSpecificReranker"},"userfn":{"description":"A reranker that uses user-defined functions to reorder search results.","type":"object","properties":{"type":{"description":"When the type is `userfn`, you can define custom reranking functions using document-level metadata, part-level metadata, or scores generated from the request-level metadata.","type":"string","default":"userfn"},"user_function":{"description":"The user defined function.","type":"string","example":"get('$.score') * get('$.document_metadata.boost')"},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. \nWhen a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1},"cutoff":{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process. When a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm. 2. Applies the cutoff, removing any results with scores below the specified threshold. 3. Returns the remaining results, sorted by their new scores.\nNote: This cutoff is applied per reranking stage. In a chain of rerankers, each reranker can have its own cutoff, potentially further reducing the number of results at each stage. If both 'limit' and 'cutoff' are specified, the cutoff is applied first, followed by the limit.","format":"float"}},"x-vectaraParents":["SearchReranker"],"title":"UserFunctionReranker"},"mmr":{"description":"A reranker that uses Maximal Marginal Relevance to balance relevance and diversity in search results.","type":"object","properties":{"type":{"description":"When the type is `mmr`, you can specify the `diversity_bias`, and the retrieval engine will use the MMR reranker.","type":"string","default":"mmr"},"diversity_bias":{"description":"The diversity bias. Higher values indicate more diversity.","type":"number","format":"float","example":0.3},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. \nWhen a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1},"cutoff":{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process. When a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm. 2. Applies the cutoff, removing any results with scores below the specified threshold. 3. Returns the remaining results, sorted by their new scores.\nNote: This cutoff is applied per reranking stage. In a chain of rerankers, each reranker can have its own cutoff, potentially further reducing the number of results at each stage. If both 'limit' and 'cutoff' are specified, the cutoff is applied first, followed by the limit.","format":"float"}},"x-vectaraParents":["SearchReranker"],"title":"MMRReranker"},"chain":{"description":"A reranker that applies multiple rerankers in sequence to produce the final search results.","type":"object","properties":{"type":{"description":"When the type is `chain`, you can then chain re-rankers together.","type":"string","default":"chain"},"rerankers":{"type":"array","description":"Specify an array of rerankers to apply to search results consecutively.","items":"circular(SearchReranker)","maxItems":50}},"required":["rerankers"],"x-vectaraParents":["SearchReranker"],"title":"ChainReranker"},"none":{"description":"A placeholder reranker that does not modify the original search results ordering.","type":"object","properties":{"type":{"description":"When the type is `none`, no reranking will be done.","type":"string","default":"none"},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. When a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1}},"x-vectaraParents":["SearchReranker"],"title":"NoneReranker"}}},"oneOf":[{"description":"Reranker that is specific to the customer.","type":"object","properties":{"type":{"description":"When the type is `customer_reranker`, you can specify the `reranker_name` of a reranker. `reranker_id` is deprecated. The retrieval engine will then rerank results using that reranker.","type":"string","default":"customer_reranker"},"reranker_id":{"description":"The ID of the reranker. The multilingual reranker that may be specified is rnk_272725719. Do not specify the MMR reranker ID here, and instead, use the MMR reranker object type. **Deprecated**: Use `reranker_name` instead.","type":"string","pattern":"rnk_(?!272725718)\\d+","example":"rnk_272725719","deprecated":true},"reranker_name":{"description":"The name of the reranker. Do not specify the MMR reranker name here. Instead, use the MMR reranker object type.","type":"string","example":"Rerank_Multilingual_v1"},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. When a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1},"cutoff":{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process. When a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm. 2. Applies the cutoff, removing any results with scores below the specified threshold. 3. Returns the remaining results, sorted by their new scores.\nNote: This cutoff is applied per reranking stage. In a chain of rerankers, each reranker can have its own cutoff, potentially further reducing the number of results at each stage. If both 'limit' and 'cutoff' are specified, the cutoff is applied first, followed by the limit.","format":"float"},"include_context":{"type":"boolean","default":true,"description":"If true, the reranker will use text with context (see \"context_configuration\") for scoring."}},"x-vectaraParents":["SearchReranker"],"title":"CustomerSpecificReranker"},{"description":"A reranker that uses user-defined functions to reorder search results.","type":"object","properties":{"type":{"description":"When the type is `userfn`, you can define custom reranking functions using document-level metadata, part-level metadata, or scores generated from the request-level metadata.","type":"string","default":"userfn"},"user_function":{"description":"The user defined function.","type":"string","example":"get('$.score') * get('$.document_metadata.boost')"},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. \nWhen a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1},"cutoff":{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process. When a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm. 2. Applies the cutoff, removing any results with scores below the specified threshold. 3. Returns the remaining results, sorted by their new scores.\nNote: This cutoff is applied per reranking stage. In a chain of rerankers, each reranker can have its own cutoff, potentially further reducing the number of results at each stage. If both 'limit' and 'cutoff' are specified, the cutoff is applied first, followed by the limit.","format":"float"}},"x-vectaraParents":["SearchReranker"],"title":"UserFunctionReranker"},{"description":"A reranker that uses Maximal Marginal Relevance to balance relevance and diversity in search results.","type":"object","properties":{"type":{"description":"When the type is `mmr`, you can specify the `diversity_bias`, and the retrieval engine will use the MMR reranker.","type":"string","default":"mmr"},"diversity_bias":{"description":"The diversity bias. Higher values indicate more diversity.","type":"number","format":"float","example":0.3},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. \nWhen a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1},"cutoff":{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process. When a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm. 2. Applies the cutoff, removing any results with scores below the specified threshold. 3. Returns the remaining results, sorted by their new scores.\nNote: This cutoff is applied per reranking stage. In a chain of rerankers, each reranker can have its own cutoff, potentially further reducing the number of results at each stage. If both 'limit' and 'cutoff' are specified, the cutoff is applied first, followed by the limit.","format":"float"}},"x-vectaraParents":["SearchReranker"],"title":"MMRReranker"},{"description":"A reranker that applies multiple rerankers in sequence to produce the final search results.","type":"object","properties":{"type":{"description":"When the type is `chain`, you can then chain re-rankers together.","type":"string","default":"chain"},"rerankers":{"type":"array","description":"Specify an array of rerankers to apply to search results consecutively.","items":"circular(SearchReranker)","maxItems":50}},"required":["rerankers"],"x-vectaraParents":["SearchReranker"],"title":"ChainReranker"},{"description":"A placeholder reranker that does not modify the original search results ordering.","type":"object","properties":{"type":{"description":"When the type is `none`, no reranking will be done.","type":"string","default":"none"},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. When a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1}},"x-vectaraParents":["SearchReranker"],"title":"NoneReranker"}],"title":"SearchReranker"}},"example":{"limit":50},"title":"SearchParameters"}],"required":["corpora"],"title":"SearchCorporaParameters"},"generation":{"description":"The parameters to control generation.","type":"object","properties":{"generation_preset_name":{"description":"The preset values to use to feed the query results and other context to the model.  \n\nA `generation_preset` is an object with a bundle of properties that specifies: \n* The `prompt_template` that is rendered and then sent to the LLM. \n* The LLM used. * `model_parameter`s such as temperature.\n\nAll of these properties except the model can be overridden by setting them in this object. Even when a `prompt_template` is set, the `generation_preset_name` is used to set the model used. See `model_parameters.model` if you want to set the model explicitly.\n\nIf `generation_preset_name` is not set, the Vectara platform will use the default model and prompt.'\n","type":"string","minLength":1,"example":"mockingbird-2.0"},"prompt_name":{"description":"Use `generation_preset_name` instead of `prompt_name`.","type":"string","minLength":1,"example":"mockingbird-2.0","deprecated":true},"max_used_search_results":{"description":"The maximum number of search results to be available to the prompt.","type":"integer","format":"int32","minimum":0,"default":5},"prompt_template":{"description":"Vectara manages both system and user roles and prompts for the generative LLM out of the box by default. However, users can override the `prompt_template` via this variable. The `prompt_template` is in the form of an Apache Velocity template. For more details on how to configure the `prompt_template`, see the [long-form documentation](https://docs.vectara.com/docs/prompts/vectara-prompt-engine).","type":"string","example":"[\n  {\"role\": \"system\", \"content\": \"You are a helpful search assistant.\"},\n  #foreach ($qResult in $vectaraQueryResults)\n     {\"role\": \"user\", \"content\": \"Given the $vectaraIdxWord[$foreach.index] search result.\"},\n     {\"role\": \"assistant\", \"content\": \"${qResult.getText()}\" },\n  #end\n  {\"role\": \"user\", \"content\": \"Generate a summary for the query '${vectaraQuery}' based on the above results.\"}\n]\n"},"prompt_text":{"description":"This property is deprecated in favor of clearer naming. Use `prompt_template`. This property will be ignored if `prompt_template` is set.","type":"string","example":"[\n  {\"role\": \"system\", \"content\": \"You are a helpful search assistant.\"},\n  #foreach ($qResult in $vectaraQueryResults)\n     {\"role\": \"user\", \"content\": \"Given the $vectaraIdxWord[$foreach.index] search result.\"},\n     {\"role\": \"assistant\", \"content\": \"${qResult.getText()}\" },\n  #end\n  {\"role\": \"user\", \"content\": \"Generate a summary for the query '${vectaraQuery}' based on the above results.\"}\n]\n","deprecated":true},"max_response_characters":{"description":"Controls the length of the generated output. This is a rough estimate and not a hard limit: the end output can be longer or shorter than this value. This is generally implemented by including the `max_response_characters` in the prompt, and the LLM's instruction following capability dictates how closely the generated output is limited.","type":"integer","format":"int32","example":300,"minimum":0},"response_language":{"description":"Languages that the Vectara platform supports.","type":"string","enum":["auto","eng","deu","fra","zho","kor","ara","rus","tha","nld","ita","por","spa","jpn","pol","tur","vie","ind","ces","ukr","ell","heb","fas","hin","urd","swe","ben","msa","ron"],"default":"auto","title":"Language"},"model_parameters":{"title":"ModelParameters","description":"The parameters for the model. WARNING: This is an experimental feature, and breakable at any point with virtually no notice. It is meant for experimentation to converge on optimal parameters that can then be set in the prompt definitions.","type":"object","properties":{"llm_name":{"description":"The model (e.g., `gpt-4`) to use for summarization. If specified, it will override the model behind `generation_preset_name`.","type":"string","example":"gpt4"},"max_tokens":{"description":"The maximum number of tokens to be returned by the model.","type":"integer","format":"int32","minimum":1},"temperature":{"description":"The sampling temperature to use. Higher values make the output more random, while lower values make it more focused and deterministic.","type":"number","format":"float"},"frequency_penalty":{"description":"Higher values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.","type":"number","format":"float"},"presence_penalty":{"description":"Higher values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.","type":"number","format":"float"}}},"citations":{"description":"Style the generator should use when making citations.","type":"object","properties":{"style":{"description":"The citation style to be used in summary. Can be one of: * `numeric` - Citations formatted as simple numerals: \\[1\\], \\[2\\] ... * `none` - Citations removed from text. * `html` - Citation formatted as a URL like `<a href=\"url_pattern\">text_pattern</a>`. * `markdown` - Formatted as `[text_pattern](url_pattern)`.","type":"string","enum":["none","numeric","html","markdown"]},"url_pattern":{"description":"The URL pattern if the citation_style is set to `html` or `markdown`. The pattern can access metadata attributes in the document or part. e.g. `https://my.doc/foo/{doc.id}/{part.id}` The default `url_pattern` is an empty string.","type":"string","example":"https://vectara.com/documents/{doc.id}"},"text_pattern":{"description":"The text pattern if the citation_style is set to `html` or `markdown`. This pattern sets the href for HTML or the text within `[]` in markdown, and defaults to N being the index of result if it is not set. The default citation style looks like `[N](<url_pattern>)` for markdown. You can use metadata attributes in the `text_pattern`. For example, the pattern `{doc.title}` with citation style `markdown` would result in final citation output like `[Title](<url_pattern>)` when the document's metadata includes `{\"title\":\"Title\"}`.","type":"string","example":"{doc.title}"}},"title":"CitationParameters"},"enable_factual_consistency_score":{"description":"Enable returning the factual consistency score with query results.","type":"boolean","default":true}},"title":"GenerationParameters"},"save_history":{"description":"Indicates whether to save the query to query history.","type":"boolean"}},"required":["search"],"title":"CorporaSearchQueryConfiguration"},"metadata":{"description":"Optional metadata associated with this tool configuration.","type":"object","additionalProperties":true,"example":{"tags":["production","v2"],"owner":"team-search"}}},"required":["name","type","query_configuration"],"x-vectaraParents":["CreateToolConfigurationRequest"],"title":"CreateCorporaSearchToolConfigurationRequest"},{"description":"Request to create a reusable configuration for a web search tool with predefined search parameters that can be applied to agents.","type":"object","properties":{"name":{"description":"Human-readable name for the tool configuration.","type":"string","example":"Customer Support Search Config"},"description":{"description":"A detailed description of what this tool configuration is for and how it should be used.","type":"string","example":"Configuration for searching customer support documentation with optimized parameters"},"type":{"description":"This should always be `web_search`.","type":"string","default":"web_search","example":"web_search"},"enabled":{"description":"Whether the tool configuration should be enabled upon creation.","type":"boolean","default":true},"argument_override":{"description":"Optional hardcoded arguments for the web search tool call such as limit etc. When specified, these values will be used instead of allowing the LLM to fill in those parameters.","type":"object","properties":{"query":{"description":"The search query to execute.","type":"string","example":"latest AI developments 2024"},"limit":{"description":"Maximum number of results to return.","type":"integer","minimum":1,"example":10},"provider":{"description":"Search provider to use.","type":"string","enum":["tavily"],"example":"tavily"}},"additionalProperties":false,"title":"WebSearchToolParameters"},"metadata":{"description":"Optional metadata associated with this tool configuration.","type":"object","additionalProperties":true,"example":{"tags":["production","v2"],"owner":"team-search"}}},"required":["name","type"],"x-vectaraParents":["CreateToolConfigurationRequest"],"title":"CreateWebSearchToolConfigurationRequest"}],"title":"CreateToolConfigurationRequest"}}}}}
>
  
</RequestSchema>

<StatusCodes
  id={undefined}
  label={undefined}
  responses={{"201":{"description":"The tool configuration has been created successfully.","content":{"application/json":{"schema":{"description":"A reusable tool configuration that stores user-defined argument overrides and settings for a specific tool.","type":"object","discriminator":{"propertyName":"type","mapping":{"mcp":{"description":"A reusable configuration for an MCP tool that stores predefined argument overrides and settings.","type":"object","properties":{"id":{"description":"Unique identifier for a tool configuration.","type":"string","pattern":"^tcf_.*","example":"tcf_123e4567-e89b-12d3-a456-426614174000","title":"ToolConfigurationId"},"name":{"description":"Human-readable name for the tool configuration.","type":"string","example":"Customer Support Search Config"},"description":{"description":"A detailed description of what this tool configuration is for and how it should be used.","type":"string","example":"Configuration for searching customer support documentation with optimized parameters"},"version":{"description":"The version identifier for this tool configuration. This is automatically incremented when the configuration is updated.","type":"integer","minimum":1,"example":1},"type":{"description":"This should always be `mcp`.","type":"string","default":"mcp","example":"mcp"},"enabled":{"description":"Whether the tool configuration is currently enabled and available for use.","type":"boolean","default":true},"argument_override":{"description":"Optional hardcoded arguments for tool calls. When specified, these values will be used instead of allowing the LLM to fill in those parameters.","type":"object","additionalProperties":true,"example":{"custom_param":"value","max_results":10}},"metadata":{"description":"Optional metadata associated with this tool configuration.","type":"object","additionalProperties":true,"example":{"tags":["production","v2"],"owner":"team-search"}},"created_at":{"description":"Timestamp when the tool configuration was created.","type":"string","format":"date-time"},"updated_at":{"description":"Timestamp when the tool configuration was last updated.","type":"string","format":"date-time"}},"required":["id","version","type"],"x-vectaraParents":["ToolConfiguration"],"title":"McpToolConfiguration"},"corpora_search":{"description":"A reusable configuration for a corpora search tool that stores predefined search parameters and overrides.","type":"object","properties":{"id":{"description":"Unique identifier for a tool configuration.","type":"string","pattern":"^tcf_.*","example":"tcf_123e4567-e89b-12d3-a456-426614174000","title":"ToolConfigurationId"},"name":{"description":"Human-readable name for the tool configuration.","type":"string","example":"Customer Support Search Config"},"description":{"description":"A detailed description of what this tool configuration is for and how it should be used.","type":"string","example":"Configuration for searching customer support documentation with optimized parameters"},"version":{"description":"The version identifier for this tool configuration. This is automatically incremented when the configuration is updated.","type":"integer","minimum":1,"example":1},"type":{"description":"This should always be `corpora_search`.","type":"string","default":"corpora_search","example":"corpora_search"},"enabled":{"description":"Whether the tool configuration is currently enabled and available for use.","type":"boolean","default":true},"argument_override":{"description":"Optional hardcoded arguments for tool calls. When specified, these values will be used instead of allowing the LLM to fill in those parameters.","type":"object","properties":{"query":{"description":"The search query string, which is the question the user is asking. If not provided, will be filled in by the LLM.","type":"string","maxLength":5000,"example":"Am I allowed to bring pets to work?"}},"additionalProperties":false,"title":"CorporaSearchToolParameters"},"query_configuration":{"description":"User-configurable settings for the search that are not exposed to the LLM.","type":"object","properties":{"search":{"description":"The parameters to search one or more corpora.","allOf":[{"type":"object","properties":{"corpora":{"description":"The corpora that you want to search.","type":"array","items":{"description":"A corpus with its identifying key for use in search operations within a customer account.","allOf":[{"description":"Configuration for search parameters specific to a single corpus within a customer account, including filters and semantics.","type":"object","properties":{"custom_dimensions":{"description":"The custom dimensions as additional weights.","type":"object","additionalProperties":{"type":"number","format":"double","nullable":false},"title":"CustomDimensions"},"metadata_filter":{"description":"The filter string used to narrow the search based on metadata attributes. The query against this corpus will be confined to document parts that match the `metadata_filter`. Only metadata fields set as `filter_attributes` on the corpus can be filtered. Filter syntax is similar to a SQL WHERE clause. See [metadata filters documentation](https://docs.vectara.com/docs/learn/metadata-search-filtering/filter-overview) for more information.","type":"string","maxLength":8000,"example":"doc.title = 'Annual Report'"},"lexical_interpolation":{"description":"How much to weigh lexical scores compared to the embedding score. 0 means lexical search is not used at all, and 1 means only lexical search is used.","type":"number","format":"float","minimum":0,"maximum":1,"example":0.005},"semantics":{"description":"Indicates whether to consider a query against this corpus as a query or a response.","type":"string","enum":["default","query","response"],"default":"default","title":"SearchSemantics"}},"title":"SearchCorpus"},{"type":"object","properties":{"corpus_key":{"description":"A user-provided key for a corpus.","type":"string","example":"my-corpus","pattern":"[a-zA-Z0-9_\\=\\-]+$","maxLength":50,"title":"CorpusKey"},"query":{"description":"Query for a particular corpus that will override the overall query if present.","type":"string","maxLength":5000,"example":"What are some important facts in my-corpus?"}}}],"required":["corpus_key"],"title":"KeyedSearchCorpus"},"minItems":1}}},{"type":"object","description":"Search parameters to retrieve knowledge for the query.","properties":{"offset":{"description":"Specifies how many results into the result to skip. This is useful for pagination.","type":"integer","format":"int32","default":0,"minimum":0},"limit":{"description":"The maximum number of results returned.","type":"integer","format":"int32","minimum":1,"default":10},"context_configuration":{"type":"object","description":"Configuration on the presentation of each document part in the result set. You can only use characters_before/after or sentences_before/after, but not both. If you specify both in the query, sentences_before/after takes precedence","properties":{"characters_before":{"description":"The number of characters that are shown before the matching document part. This is useful to show the context of the document part in the wider document. Ignored if `sentences_before` is set. Vectara will capture the full sentence that contains the captured characters, to not lose the meaning caused by a truncated word or sentence.","type":"integer","format":"int32"},"characters_after":{"description":"The number of characters that are shown after the matching document part. This is useful to show the context of the document part in the wider document. Ignored if `sentences_after` is set. Vectara will capture the full sentence that contains the captured characters, to not lose the meaning caused by a truncated word or sentence.","type":"integer","format":"int32"},"sentences_before":{"description":"The number of sentences that are shown before the matching document part. This is useful to show the context of the document part in the wider document.","type":"integer","format":"int32","default":0,"minimum":0,"example":2},"sentences_after":{"description":"The number of sentences that are shown after the matching document part. This is useful to show the context of the document part in the wider document.","type":"integer","format":"int32","default":0,"minimum":0,"example":2},"start_tag":{"description":"The tag that wraps the document part at the start. This is often used to provide a start HTML/XML tag or some other delimiter you can use in an application to understand where to provide highlighting in your UI and understand where the context before ends and the document part begins.","type":"string","example":"<em>"},"end_tag":{"description":"The tag that wraps the document part at the end. This is often used to provide a start HTML/XML tag or some other delimiter you can use in an application to understand where to provide highlighting in your UI and understand where the document part ends and the context after begins.","type":"string","example":"</em>"}},"example":{"sentences_before":2,"sentences_after":2,"start_tag":"<em>","end_tag":"</em>"},"title":"ContextConfiguration"},"reranker":{"type":"object","description":"Rerank results of the search. Rerankers are very powerful tools to improve the order of search results. By default the search will use the most powerful reranker available to the customer's plan. To disable reranking, set the reranker `type` to `\"none\"`.","discriminator":{"propertyName":"type","mapping":{"customer_reranker":{"description":"Reranker that is specific to the customer.","type":"object","properties":{"type":{"description":"When the type is `customer_reranker`, you can specify the `reranker_name` of a reranker. `reranker_id` is deprecated. The retrieval engine will then rerank results using that reranker.","type":"string","default":"customer_reranker"},"reranker_id":{"description":"The ID of the reranker. The multilingual reranker that may be specified is rnk_272725719. Do not specify the MMR reranker ID here, and instead, use the MMR reranker object type. **Deprecated**: Use `reranker_name` instead.","type":"string","pattern":"rnk_(?!272725718)\\d+","example":"rnk_272725719","deprecated":true},"reranker_name":{"description":"The name of the reranker. Do not specify the MMR reranker name here. Instead, use the MMR reranker object type.","type":"string","example":"Rerank_Multilingual_v1"},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. When a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1},"cutoff":{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process. When a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm. 2. Applies the cutoff, removing any results with scores below the specified threshold. 3. Returns the remaining results, sorted by their new scores.\nNote: This cutoff is applied per reranking stage. In a chain of rerankers, each reranker can have its own cutoff, potentially further reducing the number of results at each stage. If both 'limit' and 'cutoff' are specified, the cutoff is applied first, followed by the limit.","format":"float"},"include_context":{"type":"boolean","default":true,"description":"If true, the reranker will use text with context (see \"context_configuration\") for scoring."}},"x-vectaraParents":["SearchReranker"],"title":"CustomerSpecificReranker"},"userfn":{"description":"A reranker that uses user-defined functions to reorder search results.","type":"object","properties":{"type":{"description":"When the type is `userfn`, you can define custom reranking functions using document-level metadata, part-level metadata, or scores generated from the request-level metadata.","type":"string","default":"userfn"},"user_function":{"description":"The user defined function.","type":"string","example":"get('$.score') * get('$.document_metadata.boost')"},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. \nWhen a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1},"cutoff":{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process. When a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm. 2. Applies the cutoff, removing any results with scores below the specified threshold. 3. Returns the remaining results, sorted by their new scores.\nNote: This cutoff is applied per reranking stage. In a chain of rerankers, each reranker can have its own cutoff, potentially further reducing the number of results at each stage. If both 'limit' and 'cutoff' are specified, the cutoff is applied first, followed by the limit.","format":"float"}},"x-vectaraParents":["SearchReranker"],"title":"UserFunctionReranker"},"mmr":{"description":"A reranker that uses Maximal Marginal Relevance to balance relevance and diversity in search results.","type":"object","properties":{"type":{"description":"When the type is `mmr`, you can specify the `diversity_bias`, and the retrieval engine will use the MMR reranker.","type":"string","default":"mmr"},"diversity_bias":{"description":"The diversity bias. Higher values indicate more diversity.","type":"number","format":"float","example":0.3},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. \nWhen a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1},"cutoff":{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process. When a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm. 2. Applies the cutoff, removing any results with scores below the specified threshold. 3. Returns the remaining results, sorted by their new scores.\nNote: This cutoff is applied per reranking stage. In a chain of rerankers, each reranker can have its own cutoff, potentially further reducing the number of results at each stage. If both 'limit' and 'cutoff' are specified, the cutoff is applied first, followed by the limit.","format":"float"}},"x-vectaraParents":["SearchReranker"],"title":"MMRReranker"},"chain":{"description":"A reranker that applies multiple rerankers in sequence to produce the final search results.","type":"object","properties":{"type":{"description":"When the type is `chain`, you can then chain re-rankers together.","type":"string","default":"chain"},"rerankers":{"type":"array","description":"Specify an array of rerankers to apply to search results consecutively.","items":"circular(SearchReranker)","maxItems":50}},"required":["rerankers"],"x-vectaraParents":["SearchReranker"],"title":"ChainReranker"},"none":{"description":"A placeholder reranker that does not modify the original search results ordering.","type":"object","properties":{"type":{"description":"When the type is `none`, no reranking will be done.","type":"string","default":"none"},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. When a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1}},"x-vectaraParents":["SearchReranker"],"title":"NoneReranker"}}},"oneOf":[{"description":"Reranker that is specific to the customer.","type":"object","properties":{"type":{"description":"When the type is `customer_reranker`, you can specify the `reranker_name` of a reranker. `reranker_id` is deprecated. The retrieval engine will then rerank results using that reranker.","type":"string","default":"customer_reranker"},"reranker_id":{"description":"The ID of the reranker. The multilingual reranker that may be specified is rnk_272725719. Do not specify the MMR reranker ID here, and instead, use the MMR reranker object type. **Deprecated**: Use `reranker_name` instead.","type":"string","pattern":"rnk_(?!272725718)\\d+","example":"rnk_272725719","deprecated":true},"reranker_name":{"description":"The name of the reranker. Do not specify the MMR reranker name here. Instead, use the MMR reranker object type.","type":"string","example":"Rerank_Multilingual_v1"},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. When a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1},"cutoff":{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process. When a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm. 2. Applies the cutoff, removing any results with scores below the specified threshold. 3. Returns the remaining results, sorted by their new scores.\nNote: This cutoff is applied per reranking stage. In a chain of rerankers, each reranker can have its own cutoff, potentially further reducing the number of results at each stage. If both 'limit' and 'cutoff' are specified, the cutoff is applied first, followed by the limit.","format":"float"},"include_context":{"type":"boolean","default":true,"description":"If true, the reranker will use text with context (see \"context_configuration\") for scoring."}},"x-vectaraParents":["SearchReranker"],"title":"CustomerSpecificReranker"},{"description":"A reranker that uses user-defined functions to reorder search results.","type":"object","properties":{"type":{"description":"When the type is `userfn`, you can define custom reranking functions using document-level metadata, part-level metadata, or scores generated from the request-level metadata.","type":"string","default":"userfn"},"user_function":{"description":"The user defined function.","type":"string","example":"get('$.score') * get('$.document_metadata.boost')"},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. \nWhen a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1},"cutoff":{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process. When a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm. 2. Applies the cutoff, removing any results with scores below the specified threshold. 3. Returns the remaining results, sorted by their new scores.\nNote: This cutoff is applied per reranking stage. In a chain of rerankers, each reranker can have its own cutoff, potentially further reducing the number of results at each stage. If both 'limit' and 'cutoff' are specified, the cutoff is applied first, followed by the limit.","format":"float"}},"x-vectaraParents":["SearchReranker"],"title":"UserFunctionReranker"},{"description":"A reranker that uses Maximal Marginal Relevance to balance relevance and diversity in search results.","type":"object","properties":{"type":{"description":"When the type is `mmr`, you can specify the `diversity_bias`, and the retrieval engine will use the MMR reranker.","type":"string","default":"mmr"},"diversity_bias":{"description":"The diversity bias. Higher values indicate more diversity.","type":"number","format":"float","example":0.3},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. \nWhen a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1},"cutoff":{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process. When a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm. 2. Applies the cutoff, removing any results with scores below the specified threshold. 3. Returns the remaining results, sorted by their new scores.\nNote: This cutoff is applied per reranking stage. In a chain of rerankers, each reranker can have its own cutoff, potentially further reducing the number of results at each stage. If both 'limit' and 'cutoff' are specified, the cutoff is applied first, followed by the limit.","format":"float"}},"x-vectaraParents":["SearchReranker"],"title":"MMRReranker"},{"description":"A reranker that applies multiple rerankers in sequence to produce the final search results.","type":"object","properties":{"type":{"description":"When the type is `chain`, you can then chain re-rankers together.","type":"string","default":"chain"},"rerankers":{"type":"array","description":"Specify an array of rerankers to apply to search results consecutively.","items":"circular(SearchReranker)","maxItems":50}},"required":["rerankers"],"x-vectaraParents":["SearchReranker"],"title":"ChainReranker"},{"description":"A placeholder reranker that does not modify the original search results ordering.","type":"object","properties":{"type":{"description":"When the type is `none`, no reranking will be done.","type":"string","default":"none"},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. When a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1}},"x-vectaraParents":["SearchReranker"],"title":"NoneReranker"}],"title":"SearchReranker"}},"example":{"limit":50},"title":"SearchParameters"}],"required":["corpora"],"title":"SearchCorporaParameters"},"generation":{"description":"The parameters to control generation.","type":"object","properties":{"generation_preset_name":{"description":"The preset values to use to feed the query results and other context to the model.  \n\nA `generation_preset` is an object with a bundle of properties that specifies: \n* The `prompt_template` that is rendered and then sent to the LLM. \n* The LLM used. * `model_parameter`s such as temperature.\n\nAll of these properties except the model can be overridden by setting them in this object. Even when a `prompt_template` is set, the `generation_preset_name` is used to set the model used. See `model_parameters.model` if you want to set the model explicitly.\n\nIf `generation_preset_name` is not set, the Vectara platform will use the default model and prompt.'\n","type":"string","minLength":1,"example":"mockingbird-2.0"},"prompt_name":{"description":"Use `generation_preset_name` instead of `prompt_name`.","type":"string","minLength":1,"example":"mockingbird-2.0","deprecated":true},"max_used_search_results":{"description":"The maximum number of search results to be available to the prompt.","type":"integer","format":"int32","minimum":0,"default":5},"prompt_template":{"description":"Vectara manages both system and user roles and prompts for the generative LLM out of the box by default. However, users can override the `prompt_template` via this variable. The `prompt_template` is in the form of an Apache Velocity template. For more details on how to configure the `prompt_template`, see the [long-form documentation](https://docs.vectara.com/docs/prompts/vectara-prompt-engine).","type":"string","example":"[\n  {\"role\": \"system\", \"content\": \"You are a helpful search assistant.\"},\n  #foreach ($qResult in $vectaraQueryResults)\n     {\"role\": \"user\", \"content\": \"Given the $vectaraIdxWord[$foreach.index] search result.\"},\n     {\"role\": \"assistant\", \"content\": \"${qResult.getText()}\" },\n  #end\n  {\"role\": \"user\", \"content\": \"Generate a summary for the query '${vectaraQuery}' based on the above results.\"}\n]\n"},"prompt_text":{"description":"This property is deprecated in favor of clearer naming. Use `prompt_template`. This property will be ignored if `prompt_template` is set.","type":"string","example":"[\n  {\"role\": \"system\", \"content\": \"You are a helpful search assistant.\"},\n  #foreach ($qResult in $vectaraQueryResults)\n     {\"role\": \"user\", \"content\": \"Given the $vectaraIdxWord[$foreach.index] search result.\"},\n     {\"role\": \"assistant\", \"content\": \"${qResult.getText()}\" },\n  #end\n  {\"role\": \"user\", \"content\": \"Generate a summary for the query '${vectaraQuery}' based on the above results.\"}\n]\n","deprecated":true},"max_response_characters":{"description":"Controls the length of the generated output. This is a rough estimate and not a hard limit: the end output can be longer or shorter than this value. This is generally implemented by including the `max_response_characters` in the prompt, and the LLM's instruction following capability dictates how closely the generated output is limited.","type":"integer","format":"int32","example":300,"minimum":0},"response_language":{"description":"Languages that the Vectara platform supports.","type":"string","enum":["auto","eng","deu","fra","zho","kor","ara","rus","tha","nld","ita","por","spa","jpn","pol","tur","vie","ind","ces","ukr","ell","heb","fas","hin","urd","swe","ben","msa","ron"],"default":"auto","title":"Language"},"model_parameters":{"title":"ModelParameters","description":"The parameters for the model. WARNING: This is an experimental feature, and breakable at any point with virtually no notice. It is meant for experimentation to converge on optimal parameters that can then be set in the prompt definitions.","type":"object","properties":{"llm_name":{"description":"The model (e.g., `gpt-4`) to use for summarization. If specified, it will override the model behind `generation_preset_name`.","type":"string","example":"gpt4"},"max_tokens":{"description":"The maximum number of tokens to be returned by the model.","type":"integer","format":"int32","minimum":1},"temperature":{"description":"The sampling temperature to use. Higher values make the output more random, while lower values make it more focused and deterministic.","type":"number","format":"float"},"frequency_penalty":{"description":"Higher values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.","type":"number","format":"float"},"presence_penalty":{"description":"Higher values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.","type":"number","format":"float"}}},"citations":{"description":"Style the generator should use when making citations.","type":"object","properties":{"style":{"description":"The citation style to be used in summary. Can be one of: * `numeric` - Citations formatted as simple numerals: \\[1\\], \\[2\\] ... * `none` - Citations removed from text. * `html` - Citation formatted as a URL like `<a href=\"url_pattern\">text_pattern</a>`. * `markdown` - Formatted as `[text_pattern](url_pattern)`.","type":"string","enum":["none","numeric","html","markdown"]},"url_pattern":{"description":"The URL pattern if the citation_style is set to `html` or `markdown`. The pattern can access metadata attributes in the document or part. e.g. `https://my.doc/foo/{doc.id}/{part.id}` The default `url_pattern` is an empty string.","type":"string","example":"https://vectara.com/documents/{doc.id}"},"text_pattern":{"description":"The text pattern if the citation_style is set to `html` or `markdown`. This pattern sets the href for HTML or the text within `[]` in markdown, and defaults to N being the index of result if it is not set. The default citation style looks like `[N](<url_pattern>)` for markdown. You can use metadata attributes in the `text_pattern`. For example, the pattern `{doc.title}` with citation style `markdown` would result in final citation output like `[Title](<url_pattern>)` when the document's metadata includes `{\"title\":\"Title\"}`.","type":"string","example":"{doc.title}"}},"title":"CitationParameters"},"enable_factual_consistency_score":{"description":"Enable returning the factual consistency score with query results.","type":"boolean","default":true}},"title":"GenerationParameters"},"save_history":{"description":"Indicates whether to save the query to query history.","type":"boolean"}},"required":["search"],"title":"CorporaSearchQueryConfiguration"},"metadata":{"description":"Optional metadata associated with this tool configuration.","type":"object","additionalProperties":true,"example":{"tags":["production","v2"],"owner":"team-search"}},"created_at":{"description":"Timestamp when the tool configuration was created.","type":"string","format":"date-time"},"updated_at":{"description":"Timestamp when the tool configuration was last updated.","type":"string","format":"date-time"}},"required":["id","version","type","query_configuration"],"x-vectaraParents":["ToolConfiguration"],"title":"CorporaSearchToolConfiguration"},"web_search":{"description":"A reusable configuration for a web search tool that stores predefined search parameters and settings.","type":"object","properties":{"id":{"description":"Unique identifier for a tool configuration.","type":"string","pattern":"^tcf_.*","example":"tcf_123e4567-e89b-12d3-a456-426614174000","title":"ToolConfigurationId"},"name":{"description":"Human-readable name for the tool configuration.","type":"string","example":"Customer Support Search Config"},"description":{"description":"A detailed description of what this tool configuration is for and how it should be used.","type":"string","example":"Configuration for searching customer support documentation with optimized parameters"},"version":{"description":"The version identifier for this tool configuration. This is automatically incremented when the configuration is updated.","type":"integer","minimum":1,"example":1},"type":{"description":"This should always be `web_search`.","type":"string","default":"web_search","example":"web_search"},"enabled":{"description":"Whether the tool configuration is currently enabled and available for use.","type":"boolean","default":true},"argument_override":{"description":"Optional hardcoded arguments for tool calls. When specified, these values will be used instead of allowing the LLM to fill in those parameters.","type":"object","properties":{"query":{"description":"The search query to execute.","type":"string","example":"latest AI developments 2024"},"limit":{"description":"Maximum number of results to return.","type":"integer","minimum":1,"example":10},"provider":{"description":"Search provider to use.","type":"string","enum":["tavily"],"example":"tavily"}},"additionalProperties":false,"title":"WebSearchToolParameters"},"metadata":{"description":"Optional metadata associated with this tool configuration.","type":"object","additionalProperties":true,"example":{"tags":["production","v2"],"owner":"team-search"}},"created_at":{"description":"Timestamp when the tool configuration was created.","type":"string","format":"date-time"},"updated_at":{"description":"Timestamp when the tool configuration was last updated.","type":"string","format":"date-time"}},"required":["id","version","type"],"x-vectaraParents":["ToolConfiguration"],"title":"WebSearchToolConfiguration"}}},"oneOf":[{"description":"A reusable configuration for an MCP tool that stores predefined argument overrides and settings.","type":"object","properties":{"id":{"description":"Unique identifier for a tool configuration.","type":"string","pattern":"^tcf_.*","example":"tcf_123e4567-e89b-12d3-a456-426614174000","title":"ToolConfigurationId"},"name":{"description":"Human-readable name for the tool configuration.","type":"string","example":"Customer Support Search Config"},"description":{"description":"A detailed description of what this tool configuration is for and how it should be used.","type":"string","example":"Configuration for searching customer support documentation with optimized parameters"},"version":{"description":"The version identifier for this tool configuration. This is automatically incremented when the configuration is updated.","type":"integer","minimum":1,"example":1},"type":{"description":"This should always be `mcp`.","type":"string","default":"mcp","example":"mcp"},"enabled":{"description":"Whether the tool configuration is currently enabled and available for use.","type":"boolean","default":true},"argument_override":{"description":"Optional hardcoded arguments for tool calls. When specified, these values will be used instead of allowing the LLM to fill in those parameters.","type":"object","additionalProperties":true,"example":{"custom_param":"value","max_results":10}},"metadata":{"description":"Optional metadata associated with this tool configuration.","type":"object","additionalProperties":true,"example":{"tags":["production","v2"],"owner":"team-search"}},"created_at":{"description":"Timestamp when the tool configuration was created.","type":"string","format":"date-time"},"updated_at":{"description":"Timestamp when the tool configuration was last updated.","type":"string","format":"date-time"}},"required":["id","version","type"],"x-vectaraParents":["ToolConfiguration"],"title":"McpToolConfiguration"},{"description":"A reusable configuration for a corpora search tool that stores predefined search parameters and overrides.","type":"object","properties":{"id":{"description":"Unique identifier for a tool configuration.","type":"string","pattern":"^tcf_.*","example":"tcf_123e4567-e89b-12d3-a456-426614174000","title":"ToolConfigurationId"},"name":{"description":"Human-readable name for the tool configuration.","type":"string","example":"Customer Support Search Config"},"description":{"description":"A detailed description of what this tool configuration is for and how it should be used.","type":"string","example":"Configuration for searching customer support documentation with optimized parameters"},"version":{"description":"The version identifier for this tool configuration. This is automatically incremented when the configuration is updated.","type":"integer","minimum":1,"example":1},"type":{"description":"This should always be `corpora_search`.","type":"string","default":"corpora_search","example":"corpora_search"},"enabled":{"description":"Whether the tool configuration is currently enabled and available for use.","type":"boolean","default":true},"argument_override":{"description":"Optional hardcoded arguments for tool calls. When specified, these values will be used instead of allowing the LLM to fill in those parameters.","type":"object","properties":{"query":{"description":"The search query string, which is the question the user is asking. If not provided, will be filled in by the LLM.","type":"string","maxLength":5000,"example":"Am I allowed to bring pets to work?"}},"additionalProperties":false,"title":"CorporaSearchToolParameters"},"query_configuration":{"description":"User-configurable settings for the search that are not exposed to the LLM.","type":"object","properties":{"search":{"description":"The parameters to search one or more corpora.","allOf":[{"type":"object","properties":{"corpora":{"description":"The corpora that you want to search.","type":"array","items":{"description":"A corpus with its identifying key for use in search operations within a customer account.","allOf":[{"description":"Configuration for search parameters specific to a single corpus within a customer account, including filters and semantics.","type":"object","properties":{"custom_dimensions":{"description":"The custom dimensions as additional weights.","type":"object","additionalProperties":{"type":"number","format":"double","nullable":false},"title":"CustomDimensions"},"metadata_filter":{"description":"The filter string used to narrow the search based on metadata attributes. The query against this corpus will be confined to document parts that match the `metadata_filter`. Only metadata fields set as `filter_attributes` on the corpus can be filtered. Filter syntax is similar to a SQL WHERE clause. See [metadata filters documentation](https://docs.vectara.com/docs/learn/metadata-search-filtering/filter-overview) for more information.","type":"string","maxLength":8000,"example":"doc.title = 'Annual Report'"},"lexical_interpolation":{"description":"How much to weigh lexical scores compared to the embedding score. 0 means lexical search is not used at all, and 1 means only lexical search is used.","type":"number","format":"float","minimum":0,"maximum":1,"example":0.005},"semantics":{"description":"Indicates whether to consider a query against this corpus as a query or a response.","type":"string","enum":["default","query","response"],"default":"default","title":"SearchSemantics"}},"title":"SearchCorpus"},{"type":"object","properties":{"corpus_key":{"description":"A user-provided key for a corpus.","type":"string","example":"my-corpus","pattern":"[a-zA-Z0-9_\\=\\-]+$","maxLength":50,"title":"CorpusKey"},"query":{"description":"Query for a particular corpus that will override the overall query if present.","type":"string","maxLength":5000,"example":"What are some important facts in my-corpus?"}}}],"required":["corpus_key"],"title":"KeyedSearchCorpus"},"minItems":1}}},{"type":"object","description":"Search parameters to retrieve knowledge for the query.","properties":{"offset":{"description":"Specifies how many results into the result to skip. This is useful for pagination.","type":"integer","format":"int32","default":0,"minimum":0},"limit":{"description":"The maximum number of results returned.","type":"integer","format":"int32","minimum":1,"default":10},"context_configuration":{"type":"object","description":"Configuration on the presentation of each document part in the result set. You can only use characters_before/after or sentences_before/after, but not both. If you specify both in the query, sentences_before/after takes precedence","properties":{"characters_before":{"description":"The number of characters that are shown before the matching document part. This is useful to show the context of the document part in the wider document. Ignored if `sentences_before` is set. Vectara will capture the full sentence that contains the captured characters, to not lose the meaning caused by a truncated word or sentence.","type":"integer","format":"int32"},"characters_after":{"description":"The number of characters that are shown after the matching document part. This is useful to show the context of the document part in the wider document. Ignored if `sentences_after` is set. Vectara will capture the full sentence that contains the captured characters, to not lose the meaning caused by a truncated word or sentence.","type":"integer","format":"int32"},"sentences_before":{"description":"The number of sentences that are shown before the matching document part. This is useful to show the context of the document part in the wider document.","type":"integer","format":"int32","default":0,"minimum":0,"example":2},"sentences_after":{"description":"The number of sentences that are shown after the matching document part. This is useful to show the context of the document part in the wider document.","type":"integer","format":"int32","default":0,"minimum":0,"example":2},"start_tag":{"description":"The tag that wraps the document part at the start. This is often used to provide a start HTML/XML tag or some other delimiter you can use in an application to understand where to provide highlighting in your UI and understand where the context before ends and the document part begins.","type":"string","example":"<em>"},"end_tag":{"description":"The tag that wraps the document part at the end. This is often used to provide a start HTML/XML tag or some other delimiter you can use in an application to understand where to provide highlighting in your UI and understand where the document part ends and the context after begins.","type":"string","example":"</em>"}},"example":{"sentences_before":2,"sentences_after":2,"start_tag":"<em>","end_tag":"</em>"},"title":"ContextConfiguration"},"reranker":{"type":"object","description":"Rerank results of the search. Rerankers are very powerful tools to improve the order of search results. By default the search will use the most powerful reranker available to the customer's plan. To disable reranking, set the reranker `type` to `\"none\"`.","discriminator":{"propertyName":"type","mapping":{"customer_reranker":{"description":"Reranker that is specific to the customer.","type":"object","properties":{"type":{"description":"When the type is `customer_reranker`, you can specify the `reranker_name` of a reranker. `reranker_id` is deprecated. The retrieval engine will then rerank results using that reranker.","type":"string","default":"customer_reranker"},"reranker_id":{"description":"The ID of the reranker. The multilingual reranker that may be specified is rnk_272725719. Do not specify the MMR reranker ID here, and instead, use the MMR reranker object type. **Deprecated**: Use `reranker_name` instead.","type":"string","pattern":"rnk_(?!272725718)\\d+","example":"rnk_272725719","deprecated":true},"reranker_name":{"description":"The name of the reranker. Do not specify the MMR reranker name here. Instead, use the MMR reranker object type.","type":"string","example":"Rerank_Multilingual_v1"},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. When a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1},"cutoff":{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process. When a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm. 2. Applies the cutoff, removing any results with scores below the specified threshold. 3. Returns the remaining results, sorted by their new scores.\nNote: This cutoff is applied per reranking stage. In a chain of rerankers, each reranker can have its own cutoff, potentially further reducing the number of results at each stage. If both 'limit' and 'cutoff' are specified, the cutoff is applied first, followed by the limit.","format":"float"},"include_context":{"type":"boolean","default":true,"description":"If true, the reranker will use text with context (see \"context_configuration\") for scoring."}},"x-vectaraParents":["SearchReranker"],"title":"CustomerSpecificReranker"},"userfn":{"description":"A reranker that uses user-defined functions to reorder search results.","type":"object","properties":{"type":{"description":"When the type is `userfn`, you can define custom reranking functions using document-level metadata, part-level metadata, or scores generated from the request-level metadata.","type":"string","default":"userfn"},"user_function":{"description":"The user defined function.","type":"string","example":"get('$.score') * get('$.document_metadata.boost')"},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. \nWhen a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1},"cutoff":{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process. When a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm. 2. Applies the cutoff, removing any results with scores below the specified threshold. 3. Returns the remaining results, sorted by their new scores.\nNote: This cutoff is applied per reranking stage. In a chain of rerankers, each reranker can have its own cutoff, potentially further reducing the number of results at each stage. If both 'limit' and 'cutoff' are specified, the cutoff is applied first, followed by the limit.","format":"float"}},"x-vectaraParents":["SearchReranker"],"title":"UserFunctionReranker"},"mmr":{"description":"A reranker that uses Maximal Marginal Relevance to balance relevance and diversity in search results.","type":"object","properties":{"type":{"description":"When the type is `mmr`, you can specify the `diversity_bias`, and the retrieval engine will use the MMR reranker.","type":"string","default":"mmr"},"diversity_bias":{"description":"The diversity bias. Higher values indicate more diversity.","type":"number","format":"float","example":0.3},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. \nWhen a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1},"cutoff":{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process. When a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm. 2. Applies the cutoff, removing any results with scores below the specified threshold. 3. Returns the remaining results, sorted by their new scores.\nNote: This cutoff is applied per reranking stage. In a chain of rerankers, each reranker can have its own cutoff, potentially further reducing the number of results at each stage. If both 'limit' and 'cutoff' are specified, the cutoff is applied first, followed by the limit.","format":"float"}},"x-vectaraParents":["SearchReranker"],"title":"MMRReranker"},"chain":{"description":"A reranker that applies multiple rerankers in sequence to produce the final search results.","type":"object","properties":{"type":{"description":"When the type is `chain`, you can then chain re-rankers together.","type":"string","default":"chain"},"rerankers":{"type":"array","description":"Specify an array of rerankers to apply to search results consecutively.","items":"circular(SearchReranker)","maxItems":50}},"required":["rerankers"],"x-vectaraParents":["SearchReranker"],"title":"ChainReranker"},"none":{"description":"A placeholder reranker that does not modify the original search results ordering.","type":"object","properties":{"type":{"description":"When the type is `none`, no reranking will be done.","type":"string","default":"none"},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. When a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1}},"x-vectaraParents":["SearchReranker"],"title":"NoneReranker"}}},"oneOf":[{"description":"Reranker that is specific to the customer.","type":"object","properties":{"type":{"description":"When the type is `customer_reranker`, you can specify the `reranker_name` of a reranker. `reranker_id` is deprecated. The retrieval engine will then rerank results using that reranker.","type":"string","default":"customer_reranker"},"reranker_id":{"description":"The ID of the reranker. The multilingual reranker that may be specified is rnk_272725719. Do not specify the MMR reranker ID here, and instead, use the MMR reranker object type. **Deprecated**: Use `reranker_name` instead.","type":"string","pattern":"rnk_(?!272725718)\\d+","example":"rnk_272725719","deprecated":true},"reranker_name":{"description":"The name of the reranker. Do not specify the MMR reranker name here. Instead, use the MMR reranker object type.","type":"string","example":"Rerank_Multilingual_v1"},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. When a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1},"cutoff":{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process. When a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm. 2. Applies the cutoff, removing any results with scores below the specified threshold. 3. Returns the remaining results, sorted by their new scores.\nNote: This cutoff is applied per reranking stage. In a chain of rerankers, each reranker can have its own cutoff, potentially further reducing the number of results at each stage. If both 'limit' and 'cutoff' are specified, the cutoff is applied first, followed by the limit.","format":"float"},"include_context":{"type":"boolean","default":true,"description":"If true, the reranker will use text with context (see \"context_configuration\") for scoring."}},"x-vectaraParents":["SearchReranker"],"title":"CustomerSpecificReranker"},{"description":"A reranker that uses user-defined functions to reorder search results.","type":"object","properties":{"type":{"description":"When the type is `userfn`, you can define custom reranking functions using document-level metadata, part-level metadata, or scores generated from the request-level metadata.","type":"string","default":"userfn"},"user_function":{"description":"The user defined function.","type":"string","example":"get('$.score') * get('$.document_metadata.boost')"},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. \nWhen a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1},"cutoff":{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process. When a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm. 2. Applies the cutoff, removing any results with scores below the specified threshold. 3. Returns the remaining results, sorted by their new scores.\nNote: This cutoff is applied per reranking stage. In a chain of rerankers, each reranker can have its own cutoff, potentially further reducing the number of results at each stage. If both 'limit' and 'cutoff' are specified, the cutoff is applied first, followed by the limit.","format":"float"}},"x-vectaraParents":["SearchReranker"],"title":"UserFunctionReranker"},{"description":"A reranker that uses Maximal Marginal Relevance to balance relevance and diversity in search results.","type":"object","properties":{"type":{"description":"When the type is `mmr`, you can specify the `diversity_bias`, and the retrieval engine will use the MMR reranker.","type":"string","default":"mmr"},"diversity_bias":{"description":"The diversity bias. Higher values indicate more diversity.","type":"number","format":"float","example":0.3},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. \nWhen a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\n\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1},"cutoff":{"type":"number","description":"Specifies the minimum score threshold for results to be included after the reranking process. When a reranker is applied with a cutoff, it performs the following steps:\n1. Reranks all input results according to its algorithm. 2. Applies the cutoff, removing any results with scores below the specified threshold. 3. Returns the remaining results, sorted by their new scores.\nNote: This cutoff is applied per reranking stage. In a chain of rerankers, each reranker can have its own cutoff, potentially further reducing the number of results at each stage. If both 'limit' and 'cutoff' are specified, the cutoff is applied first, followed by the limit.","format":"float"}},"x-vectaraParents":["SearchReranker"],"title":"MMRReranker"},{"description":"A reranker that applies multiple rerankers in sequence to produce the final search results.","type":"object","properties":{"type":{"description":"When the type is `chain`, you can then chain re-rankers together.","type":"string","default":"chain"},"rerankers":{"type":"array","description":"Specify an array of rerankers to apply to search results consecutively.","items":"circular(SearchReranker)","maxItems":50}},"required":["rerankers"],"x-vectaraParents":["SearchReranker"],"title":"ChainReranker"},{"description":"A placeholder reranker that does not modify the original search results ordering.","type":"object","properties":{"type":{"description":"When the type is `none`, no reranking will be done.","type":"string","default":"none"},"limit":{"type":"integer","description":"Specifies the maximum number of results to be returned after the reranking process. When a reranker is applied, it performs the following steps:\n1. Reranks all input results according to its algorithm.\n2. Sorts the reranked results based on their new scores.\n3. Returns the top N results, where N is the value specified by this limit.\nNote: This limit is applied per reranking stage. In a chain of rerankers, each reranker can have its own limit, potentially reducing the number of results at each stage.","format":"int32","minimum":1}},"x-vectaraParents":["SearchReranker"],"title":"NoneReranker"}],"title":"SearchReranker"}},"example":{"limit":50},"title":"SearchParameters"}],"required":["corpora"],"title":"SearchCorporaParameters"},"generation":{"description":"The parameters to control generation.","type":"object","properties":{"generation_preset_name":{"description":"The preset values to use to feed the query results and other context to the model.  \n\nA `generation_preset` is an object with a bundle of properties that specifies: \n* The `prompt_template` that is rendered and then sent to the LLM. \n* The LLM used. * `model_parameter`s such as temperature.\n\nAll of these properties except the model can be overridden by setting them in this object. Even when a `prompt_template` is set, the `generation_preset_name` is used to set the model used. See `model_parameters.model` if you want to set the model explicitly.\n\nIf `generation_preset_name` is not set, the Vectara platform will use the default model and prompt.'\n","type":"string","minLength":1,"example":"mockingbird-2.0"},"prompt_name":{"description":"Use `generation_preset_name` instead of `prompt_name`.","type":"string","minLength":1,"example":"mockingbird-2.0","deprecated":true},"max_used_search_results":{"description":"The maximum number of search results to be available to the prompt.","type":"integer","format":"int32","minimum":0,"default":5},"prompt_template":{"description":"Vectara manages both system and user roles and prompts for the generative LLM out of the box by default. However, users can override the `prompt_template` via this variable. The `prompt_template` is in the form of an Apache Velocity template. For more details on how to configure the `prompt_template`, see the [long-form documentation](https://docs.vectara.com/docs/prompts/vectara-prompt-engine).","type":"string","example":"[\n  {\"role\": \"system\", \"content\": \"You are a helpful search assistant.\"},\n  #foreach ($qResult in $vectaraQueryResults)\n     {\"role\": \"user\", \"content\": \"Given the $vectaraIdxWord[$foreach.index] search result.\"},\n     {\"role\": \"assistant\", \"content\": \"${qResult.getText()}\" },\n  #end\n  {\"role\": \"user\", \"content\": \"Generate a summary for the query '${vectaraQuery}' based on the above results.\"}\n]\n"},"prompt_text":{"description":"This property is deprecated in favor of clearer naming. Use `prompt_template`. This property will be ignored if `prompt_template` is set.","type":"string","example":"[\n  {\"role\": \"system\", \"content\": \"You are a helpful search assistant.\"},\n  #foreach ($qResult in $vectaraQueryResults)\n     {\"role\": \"user\", \"content\": \"Given the $vectaraIdxWord[$foreach.index] search result.\"},\n     {\"role\": \"assistant\", \"content\": \"${qResult.getText()}\" },\n  #end\n  {\"role\": \"user\", \"content\": \"Generate a summary for the query '${vectaraQuery}' based on the above results.\"}\n]\n","deprecated":true},"max_response_characters":{"description":"Controls the length of the generated output. This is a rough estimate and not a hard limit: the end output can be longer or shorter than this value. This is generally implemented by including the `max_response_characters` in the prompt, and the LLM's instruction following capability dictates how closely the generated output is limited.","type":"integer","format":"int32","example":300,"minimum":0},"response_language":{"description":"Languages that the Vectara platform supports.","type":"string","enum":["auto","eng","deu","fra","zho","kor","ara","rus","tha","nld","ita","por","spa","jpn","pol","tur","vie","ind","ces","ukr","ell","heb","fas","hin","urd","swe","ben","msa","ron"],"default":"auto","title":"Language"},"model_parameters":{"title":"ModelParameters","description":"The parameters for the model. WARNING: This is an experimental feature, and breakable at any point with virtually no notice. It is meant for experimentation to converge on optimal parameters that can then be set in the prompt definitions.","type":"object","properties":{"llm_name":{"description":"The model (e.g., `gpt-4`) to use for summarization. If specified, it will override the model behind `generation_preset_name`.","type":"string","example":"gpt4"},"max_tokens":{"description":"The maximum number of tokens to be returned by the model.","type":"integer","format":"int32","minimum":1},"temperature":{"description":"The sampling temperature to use. Higher values make the output more random, while lower values make it more focused and deterministic.","type":"number","format":"float"},"frequency_penalty":{"description":"Higher values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.","type":"number","format":"float"},"presence_penalty":{"description":"Higher values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.","type":"number","format":"float"}}},"citations":{"description":"Style the generator should use when making citations.","type":"object","properties":{"style":{"description":"The citation style to be used in summary. Can be one of: * `numeric` - Citations formatted as simple numerals: \\[1\\], \\[2\\] ... * `none` - Citations removed from text. * `html` - Citation formatted as a URL like `<a href=\"url_pattern\">text_pattern</a>`. * `markdown` - Formatted as `[text_pattern](url_pattern)`.","type":"string","enum":["none","numeric","html","markdown"]},"url_pattern":{"description":"The URL pattern if the citation_style is set to `html` or `markdown`. The pattern can access metadata attributes in the document or part. e.g. `https://my.doc/foo/{doc.id}/{part.id}` The default `url_pattern` is an empty string.","type":"string","example":"https://vectara.com/documents/{doc.id}"},"text_pattern":{"description":"The text pattern if the citation_style is set to `html` or `markdown`. This pattern sets the href for HTML or the text within `[]` in markdown, and defaults to N being the index of result if it is not set. The default citation style looks like `[N](<url_pattern>)` for markdown. You can use metadata attributes in the `text_pattern`. For example, the pattern `{doc.title}` with citation style `markdown` would result in final citation output like `[Title](<url_pattern>)` when the document's metadata includes `{\"title\":\"Title\"}`.","type":"string","example":"{doc.title}"}},"title":"CitationParameters"},"enable_factual_consistency_score":{"description":"Enable returning the factual consistency score with query results.","type":"boolean","default":true}},"title":"GenerationParameters"},"save_history":{"description":"Indicates whether to save the query to query history.","type":"boolean"}},"required":["search"],"title":"CorporaSearchQueryConfiguration"},"metadata":{"description":"Optional metadata associated with this tool configuration.","type":"object","additionalProperties":true,"example":{"tags":["production","v2"],"owner":"team-search"}},"created_at":{"description":"Timestamp when the tool configuration was created.","type":"string","format":"date-time"},"updated_at":{"description":"Timestamp when the tool configuration was last updated.","type":"string","format":"date-time"}},"required":["id","version","type","query_configuration"],"x-vectaraParents":["ToolConfiguration"],"title":"CorporaSearchToolConfiguration"},{"description":"A reusable configuration for a web search tool that stores predefined search parameters and settings.","type":"object","properties":{"id":{"description":"Unique identifier for a tool configuration.","type":"string","pattern":"^tcf_.*","example":"tcf_123e4567-e89b-12d3-a456-426614174000","title":"ToolConfigurationId"},"name":{"description":"Human-readable name for the tool configuration.","type":"string","example":"Customer Support Search Config"},"description":{"description":"A detailed description of what this tool configuration is for and how it should be used.","type":"string","example":"Configuration for searching customer support documentation with optimized parameters"},"version":{"description":"The version identifier for this tool configuration. This is automatically incremented when the configuration is updated.","type":"integer","minimum":1,"example":1},"type":{"description":"This should always be `web_search`.","type":"string","default":"web_search","example":"web_search"},"enabled":{"description":"Whether the tool configuration is currently enabled and available for use.","type":"boolean","default":true},"argument_override":{"description":"Optional hardcoded arguments for tool calls. When specified, these values will be used instead of allowing the LLM to fill in those parameters.","type":"object","properties":{"query":{"description":"The search query to execute.","type":"string","example":"latest AI developments 2024"},"limit":{"description":"Maximum number of results to return.","type":"integer","minimum":1,"example":10},"provider":{"description":"Search provider to use.","type":"string","enum":["tavily"],"example":"tavily"}},"additionalProperties":false,"title":"WebSearchToolParameters"},"metadata":{"description":"Optional metadata associated with this tool configuration.","type":"object","additionalProperties":true,"example":{"tags":["production","v2"],"owner":"team-search"}},"created_at":{"description":"Timestamp when the tool configuration was created.","type":"string","format":"date-time"},"updated_at":{"description":"Timestamp when the tool configuration was last updated.","type":"string","format":"date-time"}},"required":["id","version","type"],"x-vectaraParents":["ToolConfiguration"],"title":"WebSearchToolConfiguration"}],"title":"ToolConfiguration"}}}},"400":{"description":"Tool configuration creation request was malformed or contains invalid references.","content":{"application/json":{"schema":{"description":"Error returned when a request contains invalid parameters or violates schema validation.","type":"object","properties":{"field_errors":{"description":"The errors that relate to specific fields in the request.","type":"object","additionalProperties":{"type":"string"}},"messages":{"type":"array","items":{"title":"message","type":"string"}},"request_id":{"description":"The ID of the request that can be used to help Vectara support debug what went wrong.","type":"string"}},"title":"BadRequestError"}}}},"403":{"description":"Permissions do not allow creating tool configurations.","content":{"application/json":{"schema":{"description":"A general error response with an error code and message.","type":"object","properties":{"messages":{"description":"The messages describing why the error occurred.","type":"array","items":{"title":"message","type":"string","example":"Internal server error."}},"request_id":{"description":"The ID of the request that can be used to help Vectara support debug what went wrong.","type":"string"}},"title":"Error"}}}},"404":{"description":"Tool not found.","content":{"application/json":{"schema":{"description":"Error returned when a requested resource does not exist.","type":"object","properties":{"id":{"description":"The ID cannot be found.","type":"string"},"messages":{"type":"array","items":{"title":"message","type":"string"}},"request_id":{"description":"The ID of the request that can be used to help Vectara support debug what went wrong.","type":"string"}},"title":"NotFoundError"}}}}}}
>
  
</StatusCodes>


      