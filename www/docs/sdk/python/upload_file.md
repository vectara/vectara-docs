---
id: upload
title: Upload Files
hide_table_of_contents: true
---

import CodePanel from '@site/src/theme/CodePanel';
import { Spacer } from "@site/src/components/ui/Spacer";

This guide demonstrates how to upload files (PDFs, DOCX, and more) to a 
Vectara corpus using the Python SDK. Uploaded files are automatically parsed, 
chunked, and indexed—making their contents instantly available for search 
and Retrieval Augmented Generation (RAG).

Use file upload for:
- Bulk onboarding of policy docs, technical manuals, invoices, contracts, or research papers
- Ingesting new content as soon as it is generated by your business
- Processing documents with tables, charts, and structured data

## Prerequisites

<CodePanel
  title="Install Vectara SDK"
  snippets={[
    { language: 'bash', code: `pip install vectara` }
  ]}
  customWidth="50%"
/>

**Setup Requirements:**
1. **Install the SDK** with `pip install vectara`
2. **Get an API key** from the [Vectara Console](https://console.vectara.com)
3. **Create a corpus** with `client.corpora.create()` (see [Corpus Management](https://docs.vectara.com/docs/api-reference/indexing-apis/corpus))
4. **Prepare files** on disk or as file objects (PDFs, DOCX, etc.)

<Spacer size="l" />

## Initialize the Vectara Client

<CodePanel
  title="Initialize Vectara Client"
  snippets={[
    {
      language: 'python',
      code: `from vectara import Vectara
from vectara.core.api_error import ApiError

# Initialize client with API key
client = Vectara(api_key="YOUR_API_KEY")`
    }
  ]}
  annotations={{
    python: [
      { line: 4, text: 'Use an API key with indexing permissions for file uploads' }
    ]
  }}
  customWidth="50%"
/>

Set up authentication to securely access file upload capabilities. Ensure your 
API key has indexing (write) permissions for the target corpus.

---

## Upload a basic file

<CodePanel
  title="Upload an HR policy document"
  snippets={[
    {
      language: 'python',
      code: `try:
    # Read and upload file
    filename = "Employee_Benefits_2025.pdf"
    with open(filename, "rb") as f:
        file_content = f.read()
    
    response = client.upload.file(
        corpus_key="hr-policies",
        file=file_content,
        filename=filename,
        metadata={
            "department": "hr",
            "policy_type": "benefits", 
            "year": "2025",
            "document_category": "employee_handbook"
        }
    )
    
    print(f"File uploaded successfully: {response}")
    
except ApiError as e:
    print(f"Upload failed: {e.status_code} - {e.body}")
except FileNotFoundError:
    print("File not found - check the file path")`
    }
  ]}
  annotations={{
    python: [
      { line: 2, text: 'Open file in binary mode for upload' },
      { line: 6, text: 'Upload to specified corpus' },
      { line: 9, text: 'Include descriptive metadata for filtering and search' },
      { line: 18, text: 'Handle API errors with status codes' }
    ]
  }}
  customWidth="50%"
/>

Upload a document (HR policy or compliance guide) to a corpus. Vectara automatically 
parses, chunks, and indexes the content for semantic search—no manual processing required.

**Key Parameters:**
- `corpus_key`: Target corpus identifier where the file will be stored
- `file`: Binary content of the file (read with `"rb"` mode)
- `filename`: Name of the file being uploaded
- `metadata`: Optional key-value pairs for filtering and categorization

**Supported File Types:** PDF, DOCX, DOC, TXT, HTML, Markdown

---

## Upload with table extraction

<CodePanel
  title="Upload financial document with table extraction"
  snippets={[
    {
      language: 'python',
      code: `try:
    # Upload document with table extraction enabled
    filename = "Q4_Financial_Report_2025.pdf"
    with open(filename, "rb") as f:
        file_content = f.read()
    
    response = client.upload.file(
        corpus_key="financial-docs",
        file=file_content,
        filename=filename,
        metadata={
            "document_type": "financial_report",
            "quarter": "Q4",
            "year": "2025", 
            "contains_tables": True,
            "company": "Example Corp"
        },
        table_extraction_config={"extract_tables": True},
        chunking_strategy={"type": "sentence_chunking_strategy"}
    )
    
    print(f"Financial document with tables uploaded: {response}")
    
except ApiError as e:
    print(f"Table extraction upload failed: {e.status_code} - {e.body}")`
    }
  ]}
  annotations={{
    python: [
      { line: 16, text: 'Enable table extraction for structured data processing' },
      { line: 17, text: 'Configure chunking strategy for optimal text segmentation' },
      { line: 13, text: 'Mark documents that contain tabular data' }
    ]
  }}
  customWidth="50%"
/>

Upload documents containing tables, charts, or structured data with enhanced extraction 
capabilities. Perfect for financial reports, invoices, research papers, or any document 
with tabular information.

**Table Extraction Benefits:**
- Automatically extracts and indexes table content
- Makes tabular data searchable alongside text content
- Preserves table structure and relationships
- Enables queries about specific data points within tables

**Use Cases:**
- Financial statements and reports
- Invoices with line items
- Research papers with data tables
- Technical specifications with parameter tables

---

## Upload from file object

<CodePanel
  title="Upload from file object (streaming)"
  snippets={[
    {
      language: 'python',
      code: `try:
    # Upload directly from file object (useful for streaming)
    filename = "research_paper_2025.pdf"
    
    with open(filename, "rb") as file_obj:
        file_content = file_obj.read()
        
        response = client.upload.file(
            corpus_key="research-papers",
            file=file_content,
            filename=filename,
            metadata={
                "document_type": "research_paper",
                "field": "artificial_intelligence",
                "publication_year": "2025",
                "peer_reviewed": True
            }
        )
    
    print(f"Research paper uploaded: {response}")
    
except ApiError as e:
    print(f"File object upload failed: {e.status_code} - {e.body}")`
    }
  ]}
  annotations={{
    python: [
      { line: 5, text: 'Process file object directly without intermediate storage' },
      { line: 15, text: 'Boolean metadata values for precise filtering' }
    ]
  }}
  customWidth="50%"
/>

Upload files directly from file objects, perfect for streaming scenarios where files 
come from cloud storage, APIs, or other dynamic sources without local file storage.

**Streaming Use Cases:**
- Files downloaded from cloud storage (S3, Google Cloud, etc.)
- Content received through APIs or webhooks
- Temporary files that don't need local persistence
- Batch processing from external systems

---

## Batch file upload

<CodePanel
  title="Batch upload multiple files"
  snippets={[
    {
      language: 'python',
      code: `def batch_upload_files(client, corpus_key, file_paths):
    """Upload multiple files with error handling"""
    results = []
    
    for file_path in file_paths:
        try:
            with open(file_path, "rb") as f:
                content = f.read()
            
            # Extract file info for metadata
            filename = file_path.split('/')[-1]
            doc_type = "contract" if "contract" in filename else "invoice"
            
            response = client.upload.file(
                corpus_key=corpus_key,
                file=content,
                filename=filename,
                metadata={
                    "document_type": doc_type,
                    "upload_batch": "batch_001",
                    "file_size": len(content)
                },
                table_extraction_config={"extract_tables": True}
            )
            
            results.append({"file": file_path, "success": True})
            print(f"✓ Uploaded: {file_path}")
            
        except Exception as e:
            results.append({"file": file_path, "success": False, "error": str(e)})
            print(f"✗ Failed: {file_path} - {e}")
    
    return results

# Usage example
file_paths = ["contract_001.pdf", "contract_002.pdf", "invoice_001.pdf"]
results = batch_upload_files(client, "legal-docs", file_paths)`
    }
  ]}
  annotations={{
    python: [
      { line: 11, text: 'Automatically categorize files based on filename patterns' },
      { line: 20, text: 'Enable table extraction for all uploads in batch' },
      { line: 16, text: 'Include batch identifier for tracking related uploads' }
    ]
  }}
  customWidth="50%"
/>

Efficiently upload multiple files with automatic categorization, error handling, 
and progress tracking. Ideal for bulk document processing and migration scenarios.

**Batch Processing Benefits:**
- Parallel processing capability for faster uploads
- Consistent metadata application across files
- Individual error handling per file
- Progress tracking and reporting
- Automatic file categorization based on naming patterns

---

## Advanced table extraction for invoices

<CodePanel
  title="Invoice upload with enhanced table processing"
  snippets={[
    {
      language: 'python',
      code: `try:
    # Upload invoice with optimized table extraction
    filename = "AcmeCorp_Invoice_2025_Q4.pdf" 
    with open(filename, "rb") as f:
        file_content = f.read()
    
    response = client.upload.file(
        corpus_key="financial-docs",
        file=file_content,
        filename=filename,
        metadata={
            "document_type": "invoice",
            "customer": "AcmeCorp",
            "quarter": "Q4", 
            "year": "2025",
            "amount": "150000.00",
            "currency": "USD",
            "contains_line_items": True,
            "payment_terms": "NET_30"
        },
        table_extraction_config={"extract_tables": True},
        chunking_strategy={
            "type": "max_chars_chunking_strategy",
            "max_chars_per_chunk": 256
        }
    )
    
    print(f"Invoice with line items uploaded: {response}")
    
except ApiError as e:
    print(f"Invoice upload failed: {e.status_code} - {e.body}")`
    }
  ]}
  annotations={{
    python: [
      { line: 19, text: 'Flag documents containing itemized data' },
      { line: 21, text: 'Enable extraction of invoice line items and totals' },
      { line: 23, text: 'Use smaller chunks for precise table data retrieval' }
    ]
  }}
  customWidth="50%"
/>

Upload invoices with enhanced table extraction to capture line items, amounts, 
and financial details. The system automatically processes itemized data for 
precise financial queries and analysis.

**Invoice-Specific Features:**
- Extracts line items, quantities, and prices
- Captures customer and vendor information
- Processes payment terms and due dates
- Enables queries about specific invoice components
- Supports financial analytics and reporting

**Financial Document Benefits:**
- Query specific line items: "What services were billed in Q4?"
- Analyze spending patterns: "Show all invoices over $100k"
- Track payment terms: "Which invoices have NET_30 terms?"
- Vendor analysis: "Total billing from AcmeCorp in 2025"

---

## Best practices and error handling

**File Upload Best Practices:**

<CodePanel
  title="Production-ready upload patterns"
  snippets={[
    {
      language: 'python',
      code: `def safe_file_upload(client, corpus_key, file_path, metadata=None):
    """Production-ready file upload with comprehensive error handling"""
    try:
        # Validate file exists and is readable
        with open(file_path, "rb") as f:
            content = f.read()
        
        # Ensure file is not empty
        if len(content) == 0:
            return {"success": False, "error": "File is empty"}
        
        # Prepare metadata with defaults
        upload_metadata = {
            "upload_timestamp": "2025-07-03T12:00:00Z",
            "file_size_bytes": len(content),
            "original_filename": file_path.split('/')[-1]
        }
        upload_metadata.update(metadata or {})
        
        # Upload with appropriate configuration
        response = client.upload.file(
            corpus_key=corpus_key,
            file=content,
            filename=file_path.split('/')[-1],
            metadata=upload_metadata,
            table_extraction_config={"extract_tables": True}
        )
        
        return {"success": True, "response": response}
        
    except FileNotFoundError:
        return {"success": False, "error": "File not found"}
    except PermissionError:
        return {"success": False, "error": "Permission denied"}
    except ApiError as e:
        return {"success": False, "error": f"API Error {e.status_code}: {e.body}"}
    except Exception as e:
        return {"success": False, "error": f"Unexpected error: {str(e)}"}`
    }
  ]}
  customWidth="50%"
/>

**Production Guidelines:**
- Always validate file existence and readability before upload
- Include comprehensive metadata for better searchability
- Use appropriate chunking strategies based on content type
- Enable table extraction for documents with structured data
- Implement retry logic for transient failures
- Monitor upload success rates and file processing times

**Error Handling:**
- **File Issues**: Validate file existence, permissions, and size
- **API Errors**: Check corpus permissions and file format support
- **Network Issues**: Implement retry logic with exponential backoff
- **Large Files**: Consider chunked uploads for very large documents

**Metadata Recommendations:**
- Include document type, department, and date information
- Add file size and upload timestamp for tracking
- Use consistent naming conventions across your organization
- Include business-specific fields for filtering and analytics

---

## Next steps

After mastering file uploads:

- **Query Uploaded Content**: Use the [Query API](https://docs.vectara.com/docs/api-reference/search-apis/search) to search uploaded documents
- **Document Management**: Use the [Documents API](https://docs.vectara.com/docs/api-reference/indexing-apis/indexing) to manage uploaded content
- **Chat Integration**: Build conversational interfaces with uploaded documents using [Chat API](https://docs.vectara.com/docs/api-reference/chat-apis/chat)
- **Analytics**: Track upload success rates and content usage patterns